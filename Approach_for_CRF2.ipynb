{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "692bd02d",
   "metadata": {},
   "source": [
    "### Approch CRF -2\n",
    "#### since i got a really accurate score with CRF approach now trying to look for potential data leaks.\n",
    "#### In this method: No label was used for sentence splitting, Each sentence is kept intact, Train/Val/Test sets do not share sentence boundaries.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "604eab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "077891fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Drop unwanted columns (like 'id' if it exists)\n",
    "df = df.drop(columns=[col for col in df.columns if col.lower() in ['id', 'Unnamed: 0']], errors='ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb859ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>اس</td>\n",
       "      <td>یہ</td>\n",
       "      <td>DET</td>\n",
       "      <td>DEM</td>\n",
       "      <td>2</td>\n",
       "      <td>det</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>سلسلے</td>\n",
       "      <td>سلسلہ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>5</td>\n",
       "      <td>nmod</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کی</td>\n",
       "      <td>کا</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PSP</td>\n",
       "      <td>2</td>\n",
       "      <td>case</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>دیگر</td>\n",
       "      <td>دیگر</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>5</td>\n",
       "      <td>amod</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اقساط</td>\n",
       "      <td>اقساط</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>7</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>یہاں</td>\n",
       "      <td>یہاں</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>7</td>\n",
       "      <td>obl</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>پڑھیے</td>\n",
       "      <td>پڑھ</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VM</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>۔</td>\n",
       "      <td>۔</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>SYM</td>\n",
       "      <td>7</td>\n",
       "      <td>punct</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>یہ</td>\n",
       "      <td>یہ</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>3</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>کیسے</td>\n",
       "      <td>کیسا</td>\n",
       "      <td>PRON</td>\n",
       "      <td>WQ</td>\n",
       "      <td>3</td>\n",
       "      <td>advmod</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text  lemma   upos xpos  head  deprel  start_char  end_char\n",
       "0     اس     یہ    DET  DEM     2     det           0         2\n",
       "1  سلسلے  سلسلہ   NOUN   NN     5    nmod           3         8\n",
       "2     کی     کا    ADP  PSP     2    case           9        11\n",
       "3   دیگر   دیگر    ADJ   JJ     5    amod          12        16\n",
       "4  اقساط  اقساط   NOUN   NN     7   nsubj          17        22\n",
       "5   یہاں   یہاں   PRON  PRP     7     obl          23        27\n",
       "6  پڑھیے    پڑھ   VERB   VM     0    root          28        33\n",
       "7      ۔      ۔  PUNCT  SYM     7   punct          33        34\n",
       "8     یہ     یہ   PRON  PRP     3   nsubj          36        38\n",
       "9   کیسے   کیسا   PRON   WQ     3  advmod          39        43"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65d91d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: Preprocess the data\n",
    "# Split into Sentences Using Punctuation (۔)\n",
    "sentences = []\n",
    "current_sentence = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    current_sentence.append(row)\n",
    "    \n",
    "    if str(row['text']).strip() == '۔':\n",
    "        sentences.append(pd.DataFrame(current_sentence))\n",
    "        current_sentence = []\n",
    "\n",
    "# Append last sentence if it didn't end in punctuation\n",
    "if current_sentence:\n",
    "    sentences.append(pd.DataFrame(current_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6f91af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    text  lemma   upos xpos  head deprel  start_char  end_char\n",
      "0     اس     یہ    DET  DEM     2    det           0         2\n",
      "1  سلسلے  سلسلہ   NOUN   NN     5   nmod           3         8\n",
      "2     کی     کا    ADP  PSP     2   case           9        11\n",
      "3   دیگر   دیگر    ADJ   JJ     5   amod          12        16\n",
      "4  اقساط  اقساط   NOUN   NN     7  nsubj          17        22\n",
      "5   یہاں   یہاں   PRON  PRP     7    obl          23        27\n",
      "6  پڑھیے    پڑھ   VERB   VM     0   root          28        33\n",
      "7      ۔      ۔  PUNCT  SYM     7  punct          33        34\n",
      "-----\n",
      "       text    lemma   upos xpos  head  deprel  start_char  end_char\n",
      "8        یہ       یہ   PRON  PRP     3   nsubj          36        38\n",
      "9      کیسے     کیسا   PRON   WQ     3  advmod          39        43\n",
      "10     ممکن     ممکن    ADJ   JJ     0    root          44        48\n",
      "11       ہے       ہے    AUX   VM     3     cop          49        51\n",
      "12       کہ       کہ  SCONJ   CC    12    mark          52        54\n",
      "13      کسی     کوئی   PRON  PRP     9    nmod          55        58\n",
      "14       کا       کا    ADP  PSP     6    case          59        61\n",
      "15  مُستقبل  مُستقبل    ADJ   JJ     9    amod          62        69\n",
      "16     ماضی     ماضی   NOUN   NN    12   xcomp          70        74\n",
      "17       کے       کا    ADP  PSP     9    case          75        77\n",
      "-----\n",
      "    text lemma  upos  xpos  head deprel  start_char  end_char\n",
      "33    جس    جو   DET   DEM     2    det         130       132\n",
      "34   طرح   طرح  NOUN    NN     9    obl         133       136\n",
      "35    ہم    ہم  PRON   PRP     9  nsubj         137       139\n",
      "36  گزرے   گزر  VERB    VM     5   amod         140       144\n",
      "37    دن    دن  NOUN    NN     9    obl         145       147\n",
      "38    کو    کو   ADP   PSP     5   case         148       150\n",
      "39   بھی   بھی  PART    RP     5    dep         151       154\n",
      "40    کل    کل  NOUN    NN     9    obl         155       157\n",
      "41  کہتے   کہہ  VERB    VM    14   amod         158       162\n",
      "42   ہیں    ہے   AUX  VAUX     9    aux         163       166\n",
      "-----\n",
      "      text   lemma   upos  xpos  head deprel  start_char  end_char\n",
      "77      تو      تو  SCONJ    CC    11   mark         292       294\n",
      "78      ہم      ہم   PRON   PRP    11  nsubj         295       297\n",
      "79     اگر     اگر  SCONJ    CC    11   mark         298       301\n",
      "80    کبھی    کبھی   PRON   PRP    11    obl         302       306\n",
      "81  تنہائی  تنہائی   NOUN    NN    11    obl         307       313\n",
      "82     میں     میں    ADP   PSP     5   case         314       317\n",
      "83     کچھ     کچھ    DET    QF     8    det         318       321\n",
      "84      پل      پل   NOUN    NN     9    obj         322       324\n",
      "85    نکال    نکال   VERB    VM    11  advcl         325       329\n",
      "86      کر      کر    AUX  VAUX     9    aux         330       332\n",
      "-----\n",
      "        text  lemma   upos xpos  head deprel  start_char  end_char\n",
      "130      اگر    اگر  SCONJ   CC    11   mark         499       502\n",
      "131    لوگوں    لوگ   NOUN   NN    11  nsubj         503       508\n",
      "132        ،      ،  PUNCT  SYM     4  punct         508       509\n",
      "133    قوموں    قوم   NOUN   NN     2   conj         510       515\n",
      "134      اور    اور  CCONJ   CC     6     cc         516       519\n",
      "135  تہذیبوں  تہذیب   NOUN   NN     2   conj         520       527\n",
      "136       سے     سے    ADP  PSP     6   case         528       530\n",
      "137      اُن     وہ   PRON  PRP    10   nmod         531       534\n",
      "138       کا     کا    ADP  PSP     8   case         535       537\n",
      "139     ماضی   ماضی   NOUN   NN    11    obj         538       542\n",
      "-----\n",
      "       text lemma   upos  xpos  head    deprel  start_char  end_char\n",
      "154     اُن    وہ   PRON   PRP     4       obl         602       605\n",
      "155     میں   میں    ADP   PSP     1      case         606       609\n",
      "156     آگے   آگے    ADV   NST     4    advmod         610       613\n",
      "157   بڑھنے   بڑھ   VERB    VM     6      nmod         614       619\n",
      "158      کی    کا    ADP   PSP     4      mark         620       622\n",
      "159    چاہت  چاہت   NOUN    NN     8       obj         623       627\n",
      "160     ختم   ختم    ADJ    JJ     8  compound         628       631\n",
      "161  ہوجائے  ہوجا   VERB    VM    18     advcl         632       638\n",
      "162      گی    گا    AUX  VAUX     8       aux         639       641\n",
      "163       ،     ،  PUNCT   SYM     8     punct         641       642\n",
      "-----\n",
      "       text   lemma   upos xpos  head deprel  start_char  end_char\n",
      "197      آپ      آپ   PRON  PRP     3  nsubj         780       782\n",
      "198      یہ      یہ   PRON  PRP     3    obj         783       785\n",
      "199  سمجھیں    سمجھ   VERB   VM     0   root         786       792\n",
      "200      کہ      کہ  SCONJ   CC    12   mark         793       795\n",
      "201      یہ      یہ    DET  DEM     6    det         796       798\n",
      "202  بیماری  بیماری   NOUN   NN    12  nsubj         799       805\n",
      "203     اُس      وہ   PRON  PRP    12    obl         806       809\n",
      "204      سے      سے    ADP  PSP     7   case         810       812\n",
      "205     اُس      وہ   PRON  PRP    11   nmod         813       816\n",
      "206      کا      کا    ADP  PSP     9   case         817       819\n",
      "-----\n",
      "      text  lemma   upos  xpos  head    deprel  start_char  end_char\n",
      "212    اور    اور  CCONJ    CC     9        cc         839       842\n",
      "213     وہ     وہ   PRON   PRP     9     nsubj         843       845\n",
      "214   اِسی   اِسا    DET   DEM     4       det         846       850\n",
      "215  کیفیت  کیفیت   NOUN    NN     9       obl         851       856\n",
      "216    میں    میں    ADP   PSP     4      case         857       860\n",
      "217  زیادہ  زیادہ    ADJ    JJ     7      amod         861       866\n",
      "218  زندگی  زندگی   NOUN    NN     9  compound         867       872\n",
      "219   نہیں   نہیں   PART   NEG     9    advmod         873       877\n",
      "220     جی     جی   VERB    VM     0      root         878       880\n",
      "221    سکے     سک    AUX  VAUX     9       aux         881       884\n",
      "-----\n",
      "       text  lemma   upos  xpos  head deprel  start_char  end_char\n",
      "250      نہ     نہ   PART   NEG     5    obl        1004      1006\n",
      "251   رنگوں    رنگ   NOUN    NN     4   nmod        1007      1012\n",
      "252      کے     کا    ADP   PSP     2   case        1013      1015\n",
      "253    پھول   پھول   NOUN    NN     5  nsubj        1016      1020\n",
      "254   کھلتے    کھل   VERB    VM    15  advcl        1021      1026\n",
      "255     ہیں     ہے    AUX  VAUX     5    aux        1027      1030\n",
      "256       ،      ،  PUNCT   SYM     5  punct        1030      1031\n",
      "257      نہ     نہ   PART   NEG    15    obl        1032      1034\n",
      "258  ذائقوں  ذائقہ   NOUN    NN    11   nmod        1035      1041\n",
      "259      کی     کا    ADP   PSP     9   case        1042      1044\n",
      "-----\n",
      "      text      lemma   upos xpos  head     deprel  start_char  end_char\n",
      "292     بس         بس   INTJ  INJ     8  discourse        1177      1179\n",
      "293    ایک        ایک    NUM   QC     4     nummod        1180      1183\n",
      "294     بے         بے    ADJ   JJ     4       amod        1184      1186\n",
      "295    رنگ        رنگ   NOUN   NN     8      nsubj        1187      1190\n",
      "296    اور        اور  CCONJ   CC     7         cc        1191      1194\n",
      "297     بے         بے    ADJ   JJ     7       amod        1195      1197\n",
      "298  ذائقہ      ذائقہ   NOUN   NN     4       conj        1198      1203\n",
      "299   حیات  شریک_حیات   NOUN   NN     0       root        1204      1208\n",
      "300      ۔          ۔  PUNCT  SYM     8      punct        1208      1209\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# display the first 10 sentences\n",
    "for sentence in sentences[:10]:\n",
    "    print(sentence.head(10))\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33ec1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the Sentences with S_B and S_M\n",
    "def label_sentence(df_sentence):\n",
    "    df_sentence = df_sentence.copy()\n",
    "    df_sentence['label'] = ['S_B'] + ['S_M'] * (len(df_sentence) - 1)\n",
    "    return df_sentence\n",
    "\n",
    "labeled_sentences = [label_sentence(sent) for sent in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28d9c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Sentences into Train / Val / Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split train vs temp\n",
    "train_sents, temp_sents = train_test_split(labeled_sentences, test_size=0.36, random_state=42)\n",
    "\n",
    "# Then split temp into validation and test\n",
    "val_sents, test_sents = train_test_split(temp_sents, test_size=0.56, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58b47645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Sentence Lists into DataFrames\n",
    "train_df = pd.concat(train_sents).reset_index(drop=True)\n",
    "val_df   = pd.concat(val_sents).reset_index(drop=True)\n",
    "test_df  = pd.concat(test_sents).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dfbad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'label' to 'y' for consistency\n",
    "train_df['y'] = train_df['label']\n",
    "val_df['y'] = val_df['label']\n",
    "test_df['y'] = test_df['label']\n",
    "\n",
    "# Drop any unnecessary columns if needed\n",
    "X_train, y_train = train_df.drop(columns=['y']), train_df['y']\n",
    "X_val, y_val = val_df.drop(columns=['y']), val_df['y']\n",
    "X_test, y_test = test_df.drop(columns=['y']), test_df['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "485861de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "def word2features(row, idx, df):\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': row['text'].lower(),\n",
    "        'word.isdigit()': row['text'].isdigit(),\n",
    "        'lemma': row['lemma'],\n",
    "        'upos': row['upos'],\n",
    "        'xpos': row['xpos'],\n",
    "        'deprel': row['deprel'],\n",
    "    }\n",
    "\n",
    "    # Previous token features\n",
    "    if idx > 0:\n",
    "        prev_row = df.iloc[idx - 1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': prev_row['text'].lower(),\n",
    "            '-1:lemma': prev_row['lemma'],\n",
    "            '-1:upos': prev_row['upos'],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True \n",
    "\n",
    "    # Next token features\n",
    "    if idx < len(df) - 1:\n",
    "        next_row = df.iloc[idx + 1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': next_row['text'].lower(),\n",
    "            '+1:lemma': next_row['lemma'],\n",
    "            '+1:upos': next_row['upos'],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True  # End of sentence\n",
    "\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9acf1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_sequences(X_df, y_df):\n",
    "    sequences_X, sequences_y = [], []\n",
    "    current_X, current_y = [], []\n",
    "\n",
    "    for i, (idx, row) in enumerate(X_df.iterrows()):\n",
    "        features = word2features(row, i, X_df)\n",
    "        current_X.append(features)\n",
    "        current_y.append(y_df.iloc[i])\n",
    "\n",
    "        # Detect end of sentence (safe: when next row is BOS)\n",
    "        if (i + 1 == len(X_df)) or (X_df.iloc[i + 1]['text'] == '۔'):\n",
    "            sequences_X.append(current_X)\n",
    "            sequences_y.append(current_y)\n",
    "            current_X, current_y = [], []\n",
    "\n",
    "    return sequences_X, sequences_y\n",
    "\n",
    "\n",
    "# Prepare sequences for train/val/test\n",
    "X_train_seq, y_train_seq = dataframe_to_sequences(train_df.drop(columns='y'), train_df['y'])\n",
    "X_val_seq, y_val_seq = dataframe_to_sequences(val_df.drop(columns='y'), val_df['y'])\n",
    "X_test_seq, y_test_seq = dataframe_to_sequences(test_df.drop(columns='y'), test_df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "899ddbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, max_iterations=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CRF</label><div class=\"sk-toggleable__content\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, max_iterations=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CRF(algorithm='lbfgs', max_iterations=100)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = CRF(algorithm='lbfgs', max_iterations=100)\n",
    "crf.fit(X_train_seq, y_train_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e1cdc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         S_B       1.00      1.00      1.00      1440\n",
      "         S_M       1.00      1.00      1.00     39517\n",
      "\n",
      "    accuracy                           1.00     40957\n",
      "   macro avg       1.00      1.00      1.00     40957\n",
      "weighted avg       1.00      1.00      1.00     40957\n",
      "\n",
      "Test Results:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         S_B       1.00      1.00      1.00      1834\n",
      "         S_M       1.00      1.00      1.00     49007\n",
      "\n",
      "    accuracy                           1.00     50841\n",
      "   macro avg       1.00      1.00      1.00     50841\n",
      "weighted avg       1.00      1.00      1.00     50841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_pred_val = crf.predict(X_val_seq)\n",
    "print(\"Validation Results:\\n\", flat_classification_report(y_val_seq, y_pred_val))\n",
    "\n",
    "y_pred_test = crf.predict(X_test_seq)\n",
    "print(\"Test Results:\\n\", flat_classification_report(y_test_seq, y_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
