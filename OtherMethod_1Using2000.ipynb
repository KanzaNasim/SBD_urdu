{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10113408,"sourceType":"datasetVersion","datasetId":6239597}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Other Methods -1 (with 2000 max features)\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import classification_report, accuracy_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:54:25.219045Z","iopub.execute_input":"2025-01-01T20:54:25.219809Z","iopub.status.idle":"2025-01-01T20:54:25.224188Z","shell.execute_reply.started":"2025-01-01T20:54:25.219767Z","shell.execute_reply":"2025-01-01T20:54:25.223308Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Read the CSV file\ndata = pd.read_csv('/kaggle/input/sbd-data/dataset.csv')\n\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:54:26.760975Z","iopub.execute_input":"2025-01-01T20:54:26.761384Z","iopub.status.idle":"2025-01-01T20:54:27.271582Z","shell.execute_reply.started":"2025-01-01T20:54:26.761348Z","shell.execute_reply":"2025-01-01T20:54:27.270425Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   id   text  lemma  upos xpos  head deprel  start_char  end_char\n0   1     اس     یہ   DET  DEM     2    det           0         2\n1   2  سلسلے  سلسلہ  NOUN   NN     5   nmod           3         8\n2   3     کی     کا   ADP  PSP     2   case           9        11\n3   4   دیگر   دیگر   ADJ   JJ     5   amod          12        16\n4   5  اقساط  اقساط  NOUN   NN     7  nsubj          17        22","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>deprel</th>\n      <th>start_char</th>\n      <th>end_char</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>اس</td>\n      <td>یہ</td>\n      <td>DET</td>\n      <td>DEM</td>\n      <td>2</td>\n      <td>det</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>سلسلے</td>\n      <td>سلسلہ</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>5</td>\n      <td>nmod</td>\n      <td>3</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>کی</td>\n      <td>کا</td>\n      <td>ADP</td>\n      <td>PSP</td>\n      <td>2</td>\n      <td>case</td>\n      <td>9</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>دیگر</td>\n      <td>دیگر</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>5</td>\n      <td>amod</td>\n      <td>12</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>اقساط</td>\n      <td>اقساط</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>7</td>\n      <td>nsubj</td>\n      <td>17</td>\n      <td>22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"data = data.drop(columns=['id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:54:29.587155Z","iopub.execute_input":"2025-01-01T20:54:29.588057Z","iopub.status.idle":"2025-01-01T20:54:29.613083Z","shell.execute_reply.started":"2025-01-01T20:54:29.588017Z","shell.execute_reply":"2025-01-01T20:54:29.612313Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import string\nimport re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:54:32.230845Z","iopub.execute_input":"2025-01-01T20:54:32.231582Z","iopub.status.idle":"2025-01-01T20:54:32.235422Z","shell.execute_reply.started":"2025-01-01T20:54:32.231543Z","shell.execute_reply":"2025-01-01T20:54:32.234468Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Initialize a new column 'y' with the default value 'S_M'\ndata['y'] = 'S_M'\n\n# Iterate through the rows to assign 'S_B'\nfor i in range(len(data) - 1):\n    # Check if the current word ends with a full stop\n    if data.loc[i, 'text'].endswith('۔'):\n        # Assign 'S_B' to the next word\n        if i + 1 < len(data):\n            data.loc[i + 1, 'y'] = 'S_B'  # Sentence Beginning\n\n# Convert 'y' column to categorical type (optional, for ML efficiency)\ndata['y'] = data['y'].astype('category')\n\n# Map categorical labels to numeric values\nlabel_mapping = {'S_B': 1, 'S_M': 0}\ndata['y'] = data['y'].map(label_mapping)\n\n# Verify the result\ndata.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:54:34.200790Z","iopub.execute_input":"2025-01-01T20:54:34.201207Z","iopub.status.idle":"2025-01-01T20:54:37.793730Z","shell.execute_reply.started":"2025-01-01T20:54:34.201171Z","shell.execute_reply":"2025-01-01T20:54:37.792679Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"    text  lemma   upos xpos  head  deprel  start_char  end_char  y\n0     اس     یہ    DET  DEM     2     det           0         2  0\n1  سلسلے  سلسلہ   NOUN   NN     5    nmod           3         8  0\n2     کی     کا    ADP  PSP     2    case           9        11  0\n3   دیگر   دیگر    ADJ   JJ     5    amod          12        16  0\n4  اقساط  اقساط   NOUN   NN     7   nsubj          17        22  0\n5   یہاں   یہاں   PRON  PRP     7     obl          23        27  0\n6  پڑھیے    پڑھ   VERB   VM     0    root          28        33  0\n7      ۔      ۔  PUNCT  SYM     7   punct          33        34  0\n8     یہ     یہ   PRON  PRP     3   nsubj          36        38  1\n9   کیسے   کیسا   PRON   WQ     3  advmod          39        43  0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>deprel</th>\n      <th>start_char</th>\n      <th>end_char</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>اس</td>\n      <td>یہ</td>\n      <td>DET</td>\n      <td>DEM</td>\n      <td>2</td>\n      <td>det</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>سلسلے</td>\n      <td>سلسلہ</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>5</td>\n      <td>nmod</td>\n      <td>3</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>کی</td>\n      <td>کا</td>\n      <td>ADP</td>\n      <td>PSP</td>\n      <td>2</td>\n      <td>case</td>\n      <td>9</td>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>دیگر</td>\n      <td>دیگر</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>5</td>\n      <td>amod</td>\n      <td>12</td>\n      <td>16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>اقساط</td>\n      <td>اقساط</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>7</td>\n      <td>nsubj</td>\n      <td>17</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>یہاں</td>\n      <td>یہاں</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>7</td>\n      <td>obl</td>\n      <td>23</td>\n      <td>27</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>پڑھیے</td>\n      <td>پڑھ</td>\n      <td>VERB</td>\n      <td>VM</td>\n      <td>0</td>\n      <td>root</td>\n      <td>28</td>\n      <td>33</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>۔</td>\n      <td>۔</td>\n      <td>PUNCT</td>\n      <td>SYM</td>\n      <td>7</td>\n      <td>punct</td>\n      <td>33</td>\n      <td>34</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>یہ</td>\n      <td>یہ</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>3</td>\n      <td>nsubj</td>\n      <td>36</td>\n      <td>38</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>کیسے</td>\n      <td>کیسا</td>\n      <td>PRON</td>\n      <td>WQ</td>\n      <td>3</td>\n      <td>advmod</td>\n      <td>39</td>\n      <td>43</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Drop rows where the 'text' column contains only punctuation\ndata = data[~data['text'].str.contains(r'^[^\\w\\s]+$', na=False)]\n\n# Verify the result\ndata.head(10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:54:37.795139Z","iopub.execute_input":"2025-01-01T20:54:37.795471Z","iopub.status.idle":"2025-01-01T20:54:37.938577Z","shell.execute_reply.started":"2025-01-01T20:54:37.795439Z","shell.execute_reply":"2025-01-01T20:54:37.937538Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"     text  lemma  upos xpos  head  deprel  start_char  end_char  y\n0      اس     یہ   DET  DEM     2     det           0         2  0\n1   سلسلے  سلسلہ  NOUN   NN     5    nmod           3         8  0\n2      کی     کا   ADP  PSP     2    case           9        11  0\n3    دیگر   دیگر   ADJ   JJ     5    amod          12        16  0\n4   اقساط  اقساط  NOUN   NN     7   nsubj          17        22  0\n5    یہاں   یہاں  PRON  PRP     7     obl          23        27  0\n6   پڑھیے    پڑھ  VERB   VM     0    root          28        33  0\n8      یہ     یہ  PRON  PRP     3   nsubj          36        38  1\n9    کیسے   کیسا  PRON   WQ     3  advmod          39        43  0\n10   ممکن   ممکن   ADJ   JJ     0    root          44        48  0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>deprel</th>\n      <th>start_char</th>\n      <th>end_char</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>اس</td>\n      <td>یہ</td>\n      <td>DET</td>\n      <td>DEM</td>\n      <td>2</td>\n      <td>det</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>سلسلے</td>\n      <td>سلسلہ</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>5</td>\n      <td>nmod</td>\n      <td>3</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>کی</td>\n      <td>کا</td>\n      <td>ADP</td>\n      <td>PSP</td>\n      <td>2</td>\n      <td>case</td>\n      <td>9</td>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>دیگر</td>\n      <td>دیگر</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>5</td>\n      <td>amod</td>\n      <td>12</td>\n      <td>16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>اقساط</td>\n      <td>اقساط</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>7</td>\n      <td>nsubj</td>\n      <td>17</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>یہاں</td>\n      <td>یہاں</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>7</td>\n      <td>obl</td>\n      <td>23</td>\n      <td>27</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>پڑھیے</td>\n      <td>پڑھ</td>\n      <td>VERB</td>\n      <td>VM</td>\n      <td>0</td>\n      <td>root</td>\n      <td>28</td>\n      <td>33</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>یہ</td>\n      <td>یہ</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>3</td>\n      <td>nsubj</td>\n      <td>36</td>\n      <td>38</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>کیسے</td>\n      <td>کیسا</td>\n      <td>PRON</td>\n      <td>WQ</td>\n      <td>3</td>\n      <td>advmod</td>\n      <td>39</td>\n      <td>43</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ممکن</td>\n      <td>ممکن</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>0</td>\n      <td>root</td>\n      <td>44</td>\n      <td>48</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:54:40.960540Z","iopub.execute_input":"2025-01-01T20:54:40.961424Z","iopub.status.idle":"2025-01-01T20:54:40.975907Z","shell.execute_reply.started":"2025-01-01T20:54:40.961387Z","shell.execute_reply":"2025-01-01T20:54:40.974975Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# One-hot encode 'upos', 'xpos', and 'deprel'\nencoder = OneHotEncoder(sparse_output=False)\nencoded_cats = encoder.fit_transform(data[['upos', 'xpos', 'deprel']])\n\n# Convert to DataFrame for easier merging\nencoded_cats_df = pd.DataFrame(encoded_cats, columns=encoder.get_feature_names_out())\n\n# Concatenate encoded features back to the dataset\ndata = pd.concat([data.reset_index(drop=True), encoded_cats_df], axis=1)\n\n# Drop the original categorical columns (optional)\ndata = data.drop(columns=['upos', 'xpos', 'deprel'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:54:42.376458Z","iopub.execute_input":"2025-01-01T20:54:42.376832Z","iopub.status.idle":"2025-01-01T20:54:43.012977Z","shell.execute_reply.started":"2025-01-01T20:54:42.376799Z","shell.execute_reply":"2025-01-01T20:54:43.012209Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Select the numerical features to normalize\nnumerical_features = ['start_char', 'end_char', 'head']\n\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Option 2: Min-Max Scaling (scales features to a range, typically 0 to 1)\nmin_max_scaler = MinMaxScaler()\ndata[numerical_features] = min_max_scaler.fit_transform(data[numerical_features])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:54:44.584728Z","iopub.execute_input":"2025-01-01T20:54:44.586278Z","iopub.status.idle":"2025-01-01T20:54:44.605780Z","shell.execute_reply.started":"2025-01-01T20:54:44.586203Z","shell.execute_reply":"2025-01-01T20:54:44.605020Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nimport pandas as pd\n\n# Initialize TF-IDF Vectorizer\ntfidf_vectorizer = TfidfVectorizer(max_features=2000)  # Adjust max_features as needed\n\n# Fit and transform only the text column\ntfidf_features = tfidf_vectorizer.fit_transform(data['text'])\n\n# Convert the sparse matrix to a DataFrame for better integration\ntfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n\n# Add the TF-IDF features back to the original DataFrame\ndata = pd.concat([data.reset_index(drop=True), tfidf_df], axis=1)\n\n# Drop the original text and lemma columns \ndata = data.drop(columns=['text', 'lemma'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:54:46.024158Z","iopub.execute_input":"2025-01-01T20:54:46.024590Z","iopub.status.idle":"2025-01-01T20:54:56.755016Z","shell.execute_reply.started":"2025-01-01T20:54:46.024554Z","shell.execute_reply":"2025-01-01T20:54:56.754274Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:54:56.756397Z","iopub.execute_input":"2025-01-01T20:54:56.756652Z","iopub.status.idle":"2025-01-01T20:54:56.781896Z","shell.execute_reply.started":"2025-01-01T20:54:56.756626Z","shell.execute_reply":"2025-01-01T20:54:56.780933Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"       head  start_char  end_char  y  upos_ADJ  upos_ADP  upos_ADV  upos_AUX  \\\n0  0.014493    0.000000  0.000000  0       0.0       0.0       0.0       0.0   \n1  0.036232    0.000003  0.000005  0       0.0       0.0       0.0       0.0   \n2  0.014493    0.000008  0.000008  0       0.0       1.0       0.0       0.0   \n3  0.036232    0.000011  0.000012  0       1.0       0.0       0.0       0.0   \n4  0.050725    0.000015  0.000018  0       0.0       0.0       0.0       0.0   \n\n   upos_CCONJ  upos_DET  ...  یقینی  یونانی  یونیورسٹی  یوں   یک  یکسانیت  \\\n0         0.0       1.0  ...    0.0     0.0        0.0  0.0  0.0      0.0   \n1         0.0       0.0  ...    0.0     0.0        0.0  0.0  0.0      0.0   \n2         0.0       0.0  ...    0.0     0.0        0.0  0.0  0.0      0.0   \n3         0.0       0.0  ...    0.0     0.0        0.0  0.0  0.0      0.0   \n4         0.0       0.0  ...    0.0     0.0        0.0  0.0  0.0      0.0   \n\n    یہ  یہاں  یہی  یہیں  \n0  0.0   0.0  0.0   0.0  \n1  0.0   0.0  0.0   0.0  \n2  0.0   0.0  0.0   0.0  \n3  0.0   0.0  0.0   0.0  \n4  0.0   0.0  0.0   0.0  \n\n[5 rows x 2079 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>head</th>\n      <th>start_char</th>\n      <th>end_char</th>\n      <th>y</th>\n      <th>upos_ADJ</th>\n      <th>upos_ADP</th>\n      <th>upos_ADV</th>\n      <th>upos_AUX</th>\n      <th>upos_CCONJ</th>\n      <th>upos_DET</th>\n      <th>...</th>\n      <th>یقینی</th>\n      <th>یونانی</th>\n      <th>یونیورسٹی</th>\n      <th>یوں</th>\n      <th>یک</th>\n      <th>یکسانیت</th>\n      <th>یہ</th>\n      <th>یہاں</th>\n      <th>یہی</th>\n      <th>یہیں</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.014493</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.036232</td>\n      <td>0.000003</td>\n      <td>0.000005</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.014493</td>\n      <td>0.000008</td>\n      <td>0.000008</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.036232</td>\n      <td>0.000011</td>\n      <td>0.000012</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.050725</td>\n      <td>0.000015</td>\n      <td>0.000018</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 2079 columns</p>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Define the feature matrix (drop 'y') and target\nX = data.drop(columns=['y'])\ny = data['y']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:55:01.816866Z","iopub.execute_input":"2025-01-01T20:55:01.817765Z","iopub.status.idle":"2025-01-01T20:55:02.955360Z","shell.execute_reply.started":"2025-01-01T20:55:01.817726Z","shell.execute_reply":"2025-01-01T20:55:02.954320Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Split into training (64%), validation (16%), and test (20%) sets\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.36, random_state=42, stratify=y)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.56, random_state=42, stratify=y_temp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:55:04.238878Z","iopub.execute_input":"2025-01-01T20:55:04.239268Z","iopub.status.idle":"2025-01-01T20:55:09.238587Z","shell.execute_reply.started":"2025-01-01T20:55:04.239222Z","shell.execute_reply":"2025-01-01T20:55:09.237471Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"### XGB","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report, accuracy_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:36:55.575172Z","iopub.execute_input":"2025-01-01T20:36:55.575674Z","iopub.status.idle":"2025-01-01T20:36:55.728557Z","shell.execute_reply.started":"2025-01-01T20:36:55.575616Z","shell.execute_reply":"2025-01-01T20:36:55.727612Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Initialize XGBoost\nxgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n\n# Fit the model\nxgb_model.fit(X_train, y_train)\n\n# Predict on validation and test sets\ny_train_pred_xgb = xgb_model.predict(X_train)\ny_val_pred_xgb = xgb_model.predict(X_val)\ny_test_pred_xgb = xgb_model.predict(X_test)\n\n# Evaluate XGBoost\nprint(\"XGBoost - Train Set:\")\nprint(classification_report(y_train, y_train_pred_xgb))\nprint(\"XGBoost - Validation Set:\")\nprint(classification_report(y_val, y_val_pred_xgb))\nprint(\"XGBoost - Test Set:\")\nprint(classification_report(y_test, y_test_pred_xgb))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:36:55.729727Z","iopub.execute_input":"2025-01-01T20:36:55.730459Z","iopub.status.idle":"2025-01-01T20:37:35.111449Z","shell.execute_reply.started":"2025-01-01T20:36:55.730414Z","shell.execute_reply":"2025-01-01T20:37:35.110519Z"}},"outputs":[{"name":"stdout","text":"XGBoost - Train Set:\n              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99    148335\n           1       0.82      0.57      0.68      5768\n\n    accuracy                           0.98    154103\n   macro avg       0.90      0.78      0.83    154103\nweighted avg       0.98      0.98      0.98    154103\n\nXGBoost - Validation Set:\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99     36713\n           1       0.79      0.56      0.65      1427\n\n    accuracy                           0.98     38140\n   macro avg       0.89      0.78      0.82     38140\nweighted avg       0.98      0.98      0.98     38140\n\nXGBoost - Test Set:\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99     46727\n           1       0.79      0.55      0.65      1817\n\n    accuracy                           0.98     48544\n   macro avg       0.89      0.77      0.82     48544\nweighted avg       0.98      0.98      0.98     48544\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### Decision Tree","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\nimport matplotlib.pyplot as plt\nfrom sklearn import tree\n\n# Initialize the Decision Tree Classifier\ndt_model = DecisionTreeClassifier(random_state=42, max_depth=10)  \n# Fit the model on the training set\ndt_model.fit(X_train, y_train)\n\n# Predict on the validation and test sets\n#also predict on the training set to see how well the model is doing\ny_train_pred = dt_model.predict(X_train)\ny_val_pred = dt_model.predict(X_val)\ny_test_pred = dt_model.predict(X_test)\n\n# Evaluate the model\nprint(\"Decision Tree - Train Set:\")\nprint(classification_report(y_train, y_train_pred))\nprint(\"Decision Tree - Validation Set:\")\nprint(classification_report(y_val, y_val_pred))\n\nprint(\"Decision Tree - Test Set:\")\nprint(classification_report(y_test, y_test_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:37:35.112630Z","iopub.execute_input":"2025-01-01T20:37:35.112909Z","iopub.status.idle":"2025-01-01T20:37:51.890659Z","shell.execute_reply.started":"2025-01-01T20:37:35.112884Z","shell.execute_reply":"2025-01-01T20:37:51.889850Z"}},"outputs":[{"name":"stdout","text":"Decision Tree - Train Set:\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99    148335\n           1       0.80      0.57      0.67      5768\n\n    accuracy                           0.98    154103\n   macro avg       0.89      0.78      0.83    154103\nweighted avg       0.98      0.98      0.98    154103\n\nDecision Tree - Validation Set:\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99     36713\n           1       0.76      0.53      0.62      1427\n\n    accuracy                           0.98     38140\n   macro avg       0.87      0.76      0.80     38140\nweighted avg       0.97      0.98      0.97     38140\n\nDecision Tree - Test Set:\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99     46727\n           1       0.76      0.55      0.63      1817\n\n    accuracy                           0.98     48544\n   macro avg       0.87      0.77      0.81     48544\nweighted avg       0.97      0.98      0.97     48544\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"### RandomForest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\n# Initialize Random Forest\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Fit the model\nrf_model.fit(X_train, y_train)\n\n# Predict on validation and test sets\n# also predict on the training set to see how well the model is doing\ny_train_pred_rf = rf_model.predict(X_train)\ny_val_pred_rf = rf_model.predict(X_val)\ny_test_pred_rf = rf_model.predict(X_test)\n\n# Evaluate Random Forest\nprint(\"Random Forest - Train Set:\")\nprint(classification_report(y_train, y_train_pred_rf))\nprint(\"Random Forest - Validation Set:\")\nprint(classification_report(y_val, y_val_pred_rf))\nprint(\"Random Forest - Test Set:\")\nprint(classification_report(y_test, y_test_pred_rf))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:37:51.891579Z","iopub.execute_input":"2025-01-01T20:37:51.891834Z","iopub.status.idle":"2025-01-01T20:41:15.751776Z","shell.execute_reply.started":"2025-01-01T20:37:51.891809Z","shell.execute_reply":"2025-01-01T20:41:15.750824Z"}},"outputs":[{"name":"stdout","text":"Random Forest - Train Set:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00    148335\n           1       1.00      1.00      1.00      5768\n\n    accuracy                           1.00    154103\n   macro avg       1.00      1.00      1.00    154103\nweighted avg       1.00      1.00      1.00    154103\n\nRandom Forest - Validation Set:\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99     36713\n           1       0.73      0.59      0.65      1427\n\n    accuracy                           0.98     38140\n   macro avg       0.86      0.79      0.82     38140\nweighted avg       0.97      0.98      0.98     38140\n\nRandom Forest - Test Set:\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99     46727\n           1       0.71      0.59      0.64      1817\n\n    accuracy                           0.98     48544\n   macro avg       0.85      0.79      0.82     48544\nweighted avg       0.97      0.98      0.97     48544\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"### Feedforward Network","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Define a simple DNN model\ndef create_dnn_model(input_dim, num_classes):\n    model = keras.Sequential([\n        layers.InputLayer(input_shape=(input_dim,)),  # Corrected input layer definition\n        layers.Dense(128, activation='relu'),  # Hidden layer with ReLU activation\n        layers.Dropout(0.2),  # Dropout for regularization\n        layers.Dense(64, activation='relu'),  # Another hidden layer\n        layers.Dropout(0.2),  # Dropout for regularization\n        layers.Dense(num_classes, activation='softmax')  # Output layer with softmax for multi-class classification\n    ])\n    \n    model.compile(optimizer='adam', \n                  loss='sparse_categorical_crossentropy',  # Use sparse categorical crossentropy for integer labels\n                  metrics=['accuracy'])\n    \n    return model\n\n# Ensure labels are integer encoded if they are categorical\ny_train = y_train.astype('int') if y_train.dtype.name == 'category' else y_train\ny_val = y_val.astype('int') if y_val.dtype.name == 'category' else y_val\ny_test = y_test.astype('int') if y_test.dtype.name == 'category' else y_test\n\n# Create the DNN model\ninput_dim = X_train.shape[1]  # Number of features\nnum_classes = len(y_train.unique())  # Number of output classes ( S_B, S_M)\n\ndnn_model = create_dnn_model(input_dim, num_classes)\n\n# Train the DNN model\ndnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n\n# Evaluate the model on the validation set\nval_loss, val_accuracy = dnn_model.evaluate(X_val, y_val, verbose=0)\nprint(f'Validation Accuracy: {val_accuracy:.4f}')\n\n# Make predictions on the validation set\ny_val_pred = dnn_model.predict(X_val)\ny_val_pred = y_val_pred.argmax(axis=1)  # Get the predicted class labels\n\n# Evaluate the model on the validation set\nprint(\"Classification Report (Validation):\\n\", classification_report(y_val, y_val_pred))\n\n# Make predictions on the test set (optional)\ny_test_pred = dnn_model.predict(X_test)\ny_test_pred = y_test_pred.argmax(axis=1)\n\n# Evaluate the model on the test set\ntest_loss, test_accuracy = dnn_model.evaluate(X_test, y_test, verbose=0)\nprint(f'Test Accuracy: {test_accuracy:.4f}')\nprint(\"Classification Report (Test):\\n\", classification_report(y_test, y_test_pred))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:50:09.951895Z","iopub.execute_input":"2025-01-01T20:50:09.952745Z","iopub.status.idle":"2025-01-01T20:52:00.225076Z","shell.execute_reply.started":"2025-01-01T20:50:09.952711Z","shell.execute_reply":"2025-01-01T20:52:00.224113Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1735764615.750428     103 service.cc:145] XLA service 0x7985e00043e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1735764615.750472     103 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1735764615.750477     103 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 111/4816\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9014 - loss: 0.3636","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1735764619.116392     103 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m4816/4816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.1203 - val_accuracy: 0.9688 - val_loss: 0.0821\nEpoch 2/10\n\u001b[1m4816/4816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9679 - loss: 0.0816 - val_accuracy: 0.9683 - val_loss: 0.0784\nEpoch 3/10\n\u001b[1m4816/4816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9722 - loss: 0.0718 - val_accuracy: 0.9728 - val_loss: 0.0718\nEpoch 4/10\n\u001b[1m4816/4816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9739 - loss: 0.0667 - val_accuracy: 0.9741 - val_loss: 0.0684\nEpoch 5/10\n\u001b[1m4816/4816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9759 - loss: 0.0619 - val_accuracy: 0.9744 - val_loss: 0.0661\nEpoch 6/10\n\u001b[1m4816/4816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.0591 - val_accuracy: 0.9757 - val_loss: 0.0635\nEpoch 7/10\n\u001b[1m4816/4816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.0589 - val_accuracy: 0.9753 - val_loss: 0.0646\nEpoch 8/10\n\u001b[1m4816/4816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.0569 - val_accuracy: 0.9760 - val_loss: 0.0633\nEpoch 9/10\n\u001b[1m4816/4816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9782 - loss: 0.0550 - val_accuracy: 0.9771 - val_loss: 0.0627\nEpoch 10/10\n\u001b[1m4816/4816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9783 - loss: 0.0549 - val_accuracy: 0.9761 - val_loss: 0.0630\nValidation Accuracy: 0.9761\n\u001b[1m1192/1192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\nClassification Report (Validation):\n               precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99     36713\n           1       0.71      0.61      0.66      1427\n\n    accuracy                           0.98     38140\n   macro avg       0.85      0.80      0.82     38140\nweighted avg       0.97      0.98      0.98     38140\n\n\u001b[1m1517/1517\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\nTest Accuracy: 0.9761\nClassification Report (Test):\n               precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99     46727\n           1       0.71      0.60      0.65      1817\n\n    accuracy                           0.98     48544\n   macro avg       0.85      0.80      0.82     48544\nweighted avg       0.97      0.98      0.98     48544\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"### Logistic Regression","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom imblearn.over_sampling import SMOTE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:55:18.314122Z","iopub.execute_input":"2025-01-01T20:55:18.314834Z","iopub.status.idle":"2025-01-01T20:55:18.319165Z","shell.execute_reply.started":"2025-01-01T20:55:18.314795Z","shell.execute_reply":"2025-01-01T20:55:18.318188Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Apply SMOTE to the training data\n#smote = SMOTE(random_state=42)\n#X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:53:54.592337Z","iopub.execute_input":"2025-01-01T20:53:54.593218Z","iopub.status.idle":"2025-01-01T20:53:54.877488Z","shell.execute_reply.started":"2025-01-01T20:53:54.593182Z","shell.execute_reply":"2025-01-01T20:53:54.876304Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Apply SMOTE to the training data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m X_train_resampled, y_train_resampled \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(\u001b[43mX_train\u001b[49m, y_train)\n","\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"],"ename":"NameError","evalue":"name 'X_train' is not defined","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"# Train the logistic regression model\nlogistic_model = LogisticRegression(random_state=42)\nlogistic_model.fit(X_train, y_train)\n\n# Make predictions and evaluate the model\ny_train_pred = logistic_model.predict(X_train)\ny_val_pred = logistic_model.predict(X_val)\ny_test_pred = logistic_model.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:55:45.957012Z","iopub.execute_input":"2025-01-01T20:55:45.957501Z","iopub.status.idle":"2025-01-01T20:56:14.655686Z","shell.execute_reply.started":"2025-01-01T20:55:45.957463Z","shell.execute_reply":"2025-01-01T20:56:14.654290Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"print(\"Logistic Regression - Training Set:\")\nprint(classification_report(y_train, y_train_pred))\nprint(\"Logistic Regression - Validation Set:\")\nprint(classification_report(y_val, y_val_pred))\nprint(\"Logistic Regression - test Set:\")\nprint(classification_report(y_test, y_test_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T20:56:25.993908Z","iopub.execute_input":"2025-01-01T20:56:25.994315Z","iopub.status.idle":"2025-01-01T20:56:26.602797Z","shell.execute_reply.started":"2025-01-01T20:56:25.994269Z","shell.execute_reply":"2025-01-01T20:56:26.601831Z"}},"outputs":[{"name":"stdout","text":"Logistic Regression - Training Set:\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.98    148335\n           1       0.76      0.29      0.42      5768\n\n    accuracy                           0.97    154103\n   macro avg       0.86      0.64      0.70    154103\nweighted avg       0.96      0.97      0.96    154103\n\nLogistic Regression - Validation Set:\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.98     36713\n           1       0.72      0.27      0.39      1427\n\n    accuracy                           0.97     38140\n   macro avg       0.84      0.63      0.69     38140\nweighted avg       0.96      0.97      0.96     38140\n\nLogistic Regression - test Set:\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.98     46727\n           1       0.70      0.27      0.39      1817\n\n    accuracy                           0.97     48544\n   macro avg       0.84      0.63      0.69     48544\nweighted avg       0.96      0.97      0.96     48544\n\n","output_type":"stream"}],"execution_count":19}]}