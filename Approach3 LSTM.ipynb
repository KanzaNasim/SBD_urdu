{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10113408,"sourceType":"datasetVersion","datasetId":6239597}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Approach 3: LSTM","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:07.833796Z","iopub.execute_input":"2024-12-27T11:41:07.834613Z","iopub.status.idle":"2024-12-27T11:41:07.838284Z","shell.execute_reply.started":"2024-12-27T11:41:07.834579Z","shell.execute_reply":"2024-12-27T11:41:07.837370Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Read the CSV file\ndf = pd.read_csv('/kaggle/input/sbd-data/dataset.csv')\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:07.893780Z","iopub.execute_input":"2024-12-27T11:41:07.894008Z","iopub.status.idle":"2024-12-27T11:41:08.246178Z","shell.execute_reply.started":"2024-12-27T11:41:07.893986Z","shell.execute_reply":"2024-12-27T11:41:08.245309Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"   id   text  lemma  upos xpos  head deprel  start_char  end_char\n0   1     اس     یہ   DET  DEM     2    det           0         2\n1   2  سلسلے  سلسلہ  NOUN   NN     5   nmod           3         8\n2   3     کی     کا   ADP  PSP     2   case           9        11\n3   4   دیگر   دیگر   ADJ   JJ     5   amod          12        16\n4   5  اقساط  اقساط  NOUN   NN     7  nsubj          17        22","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>deprel</th>\n      <th>start_char</th>\n      <th>end_char</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>اس</td>\n      <td>یہ</td>\n      <td>DET</td>\n      <td>DEM</td>\n      <td>2</td>\n      <td>det</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>سلسلے</td>\n      <td>سلسلہ</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>5</td>\n      <td>nmod</td>\n      <td>3</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>کی</td>\n      <td>کا</td>\n      <td>ADP</td>\n      <td>PSP</td>\n      <td>2</td>\n      <td>case</td>\n      <td>9</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>دیگر</td>\n      <td>دیگر</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>5</td>\n      <td>amod</td>\n      <td>12</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>اقساط</td>\n      <td>اقساط</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>7</td>\n      <td>nsubj</td>\n      <td>17</td>\n      <td>22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"data = df.drop(columns=['id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:08.247482Z","iopub.execute_input":"2024-12-27T11:41:08.247762Z","iopub.status.idle":"2024-12-27T11:41:08.261562Z","shell.execute_reply.started":"2024-12-27T11:41:08.247735Z","shell.execute_reply":"2024-12-27T11:41:08.260706Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"import string\nimport re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:08.262682Z","iopub.execute_input":"2024-12-27T11:41:08.263005Z","iopub.status.idle":"2024-12-27T11:41:08.268637Z","shell.execute_reply.started":"2024-12-27T11:41:08.262965Z","shell.execute_reply":"2024-12-27T11:41:08.267858Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Initialize a new column 'y' with the default value 'S_M'\ndata['y'] = 'S_M'\n\n# Iterate through the rows to assign 'S_B'\nfor i in range(len(data) - 1):\n    # Check if the current word ends with a full stop\n    if data.loc[i, 'text'].endswith('۔'):\n        # Assign 'S_B' to the next word\n        if i + 1 < len(data):\n            data.loc[i + 1, 'y'] = 'S_B'  # Sentence Beginning\n\n# Convert 'y' column to categorical type (optional, for ML efficiency)\ndata['y'] = data['y'].astype('category')\n\n# Map categorical labels to numeric values\nlabel_mapping = {'S_B': 1, 'S_M': 0}\ndata['y'] = data['y'].map(label_mapping)\n\n# Verify the result\ndata.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:08.270524Z","iopub.execute_input":"2024-12-27T11:41:08.270851Z","iopub.status.idle":"2024-12-27T11:41:11.806289Z","shell.execute_reply.started":"2024-12-27T11:41:08.270814Z","shell.execute_reply":"2024-12-27T11:41:11.805283Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"    text  lemma   upos xpos  head  deprel  start_char  end_char  y\n0     اس     یہ    DET  DEM     2     det           0         2  0\n1  سلسلے  سلسلہ   NOUN   NN     5    nmod           3         8  0\n2     کی     کا    ADP  PSP     2    case           9        11  0\n3   دیگر   دیگر    ADJ   JJ     5    amod          12        16  0\n4  اقساط  اقساط   NOUN   NN     7   nsubj          17        22  0\n5   یہاں   یہاں   PRON  PRP     7     obl          23        27  0\n6  پڑھیے    پڑھ   VERB   VM     0    root          28        33  0\n7      ۔      ۔  PUNCT  SYM     7   punct          33        34  0\n8     یہ     یہ   PRON  PRP     3   nsubj          36        38  1\n9   کیسے   کیسا   PRON   WQ     3  advmod          39        43  0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>deprel</th>\n      <th>start_char</th>\n      <th>end_char</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>اس</td>\n      <td>یہ</td>\n      <td>DET</td>\n      <td>DEM</td>\n      <td>2</td>\n      <td>det</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>سلسلے</td>\n      <td>سلسلہ</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>5</td>\n      <td>nmod</td>\n      <td>3</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>کی</td>\n      <td>کا</td>\n      <td>ADP</td>\n      <td>PSP</td>\n      <td>2</td>\n      <td>case</td>\n      <td>9</td>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>دیگر</td>\n      <td>دیگر</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>5</td>\n      <td>amod</td>\n      <td>12</td>\n      <td>16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>اقساط</td>\n      <td>اقساط</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>7</td>\n      <td>nsubj</td>\n      <td>17</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>یہاں</td>\n      <td>یہاں</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>7</td>\n      <td>obl</td>\n      <td>23</td>\n      <td>27</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>پڑھیے</td>\n      <td>پڑھ</td>\n      <td>VERB</td>\n      <td>VM</td>\n      <td>0</td>\n      <td>root</td>\n      <td>28</td>\n      <td>33</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>۔</td>\n      <td>۔</td>\n      <td>PUNCT</td>\n      <td>SYM</td>\n      <td>7</td>\n      <td>punct</td>\n      <td>33</td>\n      <td>34</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>یہ</td>\n      <td>یہ</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>3</td>\n      <td>nsubj</td>\n      <td>36</td>\n      <td>38</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>کیسے</td>\n      <td>کیسا</td>\n      <td>PRON</td>\n      <td>WQ</td>\n      <td>3</td>\n      <td>advmod</td>\n      <td>39</td>\n      <td>43</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# Drop rows where the 'text' column contains only punctuation\ndata = data[~data['text'].str.contains(r'^[^\\w\\s]+$', na=False)]\n\n# Verify the result\ndata.head(10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:11.807085Z","iopub.execute_input":"2024-12-27T11:41:11.807311Z","iopub.status.idle":"2024-12-27T11:41:11.946481Z","shell.execute_reply.started":"2024-12-27T11:41:11.807289Z","shell.execute_reply":"2024-12-27T11:41:11.945516Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"     text  lemma  upos xpos  head  deprel  start_char  end_char  y\n0      اس     یہ   DET  DEM     2     det           0         2  0\n1   سلسلے  سلسلہ  NOUN   NN     5    nmod           3         8  0\n2      کی     کا   ADP  PSP     2    case           9        11  0\n3    دیگر   دیگر   ADJ   JJ     5    amod          12        16  0\n4   اقساط  اقساط  NOUN   NN     7   nsubj          17        22  0\n5    یہاں   یہاں  PRON  PRP     7     obl          23        27  0\n6   پڑھیے    پڑھ  VERB   VM     0    root          28        33  0\n8      یہ     یہ  PRON  PRP     3   nsubj          36        38  1\n9    کیسے   کیسا  PRON   WQ     3  advmod          39        43  0\n10   ممکن   ممکن   ADJ   JJ     0    root          44        48  0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>deprel</th>\n      <th>start_char</th>\n      <th>end_char</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>اس</td>\n      <td>یہ</td>\n      <td>DET</td>\n      <td>DEM</td>\n      <td>2</td>\n      <td>det</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>سلسلے</td>\n      <td>سلسلہ</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>5</td>\n      <td>nmod</td>\n      <td>3</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>کی</td>\n      <td>کا</td>\n      <td>ADP</td>\n      <td>PSP</td>\n      <td>2</td>\n      <td>case</td>\n      <td>9</td>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>دیگر</td>\n      <td>دیگر</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>5</td>\n      <td>amod</td>\n      <td>12</td>\n      <td>16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>اقساط</td>\n      <td>اقساط</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>7</td>\n      <td>nsubj</td>\n      <td>17</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>یہاں</td>\n      <td>یہاں</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>7</td>\n      <td>obl</td>\n      <td>23</td>\n      <td>27</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>پڑھیے</td>\n      <td>پڑھ</td>\n      <td>VERB</td>\n      <td>VM</td>\n      <td>0</td>\n      <td>root</td>\n      <td>28</td>\n      <td>33</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>یہ</td>\n      <td>یہ</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>3</td>\n      <td>nsubj</td>\n      <td>36</td>\n      <td>38</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>کیسے</td>\n      <td>کیسا</td>\n      <td>PRON</td>\n      <td>WQ</td>\n      <td>3</td>\n      <td>advmod</td>\n      <td>39</td>\n      <td>43</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ممکن</td>\n      <td>ممکن</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>0</td>\n      <td>root</td>\n      <td>44</td>\n      <td>48</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:11.947719Z","iopub.execute_input":"2024-12-27T11:41:11.948006Z","iopub.status.idle":"2024-12-27T11:41:11.952478Z","shell.execute_reply.started":"2024-12-27T11:41:11.947979Z","shell.execute_reply":"2024-12-27T11:41:11.951320Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# One-hot encode 'upos', 'xpos', and 'deprel'\nencoder = OneHotEncoder(sparse_output=False)\nencoded_cats = encoder.fit_transform(data[['upos', 'xpos', 'deprel']])\n\n# Convert to DataFrame for easier merging\nencoded_cats_df = pd.DataFrame(encoded_cats, columns=encoder.get_feature_names_out())\n\n# Concatenate encoded features back to the dataset\ndata = pd.concat([data.reset_index(drop=True), encoded_cats_df], axis=1)\n\n# Drop the original categorical columns (optional)\ndata = data.drop(columns=['upos', 'xpos', 'deprel'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:11.954190Z","iopub.execute_input":"2024-12-27T11:41:11.954766Z","iopub.status.idle":"2024-12-27T11:41:12.557871Z","shell.execute_reply.started":"2024-12-27T11:41:11.954727Z","shell.execute_reply":"2024-12-27T11:41:12.557198Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Select the numerical features to normalize\nnumerical_features = ['start_char', 'end_char', 'head']\n\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Option 2: Min-Max Scaling (scales features to a range, typically 0 to 1)\nmin_max_scaler = MinMaxScaler()\ndata[numerical_features] = min_max_scaler.fit_transform(data[numerical_features])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:12.558929Z","iopub.execute_input":"2024-12-27T11:41:12.559255Z","iopub.status.idle":"2024-12-27T11:41:12.572656Z","shell.execute_reply.started":"2024-12-27T11:41:12.559221Z","shell.execute_reply":"2024-12-27T11:41:12.571668Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Combine text and lemma columns into a single string representation (if needed)\ndata['text_lemma'] = data['text'] + \" \" + data['lemma']\n\n# Initialize TF-IDF Vectorizer\ntfidf_vectorizer = TfidfVectorizer(max_features=500)  # Adjust max_features as needed\n\n# Fit and transform the combined text and lemma\ntfidf_features = tfidf_vectorizer.fit_transform(data['text_lemma'])\n\n# Convert the sparse matrix to a DataFrame for better integration\ntfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n\n# Add the TF-IDF features back to the original DataFrame\ndata = pd.concat([data.reset_index(drop=True), tfidf_df], axis=1)\n\n# Drop the original text and lemma columns (optional)\ndata = data.drop(columns=['text', 'lemma', 'text_lemma'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:12.573962Z","iopub.execute_input":"2024-12-27T11:41:12.574273Z","iopub.status.idle":"2024-12-27T11:41:16.708897Z","shell.execute_reply.started":"2024-12-27T11:41:12.574246Z","shell.execute_reply":"2024-12-27T11:41:16.707925Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"data.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:16.711446Z","iopub.execute_input":"2024-12-27T11:41:16.711801Z","iopub.status.idle":"2024-12-27T11:41:16.741928Z","shell.execute_reply.started":"2024-12-27T11:41:16.711767Z","shell.execute_reply":"2024-12-27T11:41:16.741020Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"       head  start_char  end_char  y  upos_ADJ  upos_ADP  upos_ADV  upos_AUX  \\\n0  0.014493    0.000000  0.000000  0       0.0       0.0       0.0       0.0   \n1  0.036232    0.000003  0.000005  0       0.0       0.0       0.0       0.0   \n2  0.014493    0.000008  0.000008  0       0.0       1.0       0.0       0.0   \n3  0.036232    0.000011  0.000012  0       1.0       0.0       0.0       0.0   \n4  0.050725    0.000015  0.000018  0       0.0       0.0       0.0       0.0   \n5  0.050725    0.000020  0.000022  0       0.0       0.0       0.0       0.0   \n6  0.000000    0.000025  0.000027  0       0.0       0.0       0.0       0.0   \n7  0.021739    0.000032  0.000032  1       0.0       0.0       0.0       0.0   \n8  0.021739    0.000035  0.000036  0       0.0       0.0       0.0       0.0   \n9  0.000000    0.000039  0.000041  0       1.0       0.0       0.0       0.0   \n\n   upos_CCONJ  upos_DET  ...  ہوں   ہی  ہیں   ہے   یا  یعنی  یقینا        یہ  \\\n0         0.0       1.0  ...  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.646062   \n1         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.000000   \n2         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.000000   \n3         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.000000   \n4         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.000000   \n5         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.000000   \n6         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.000000   \n7         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0    0.0  1.000000   \n8         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.000000   \n9         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.000000   \n\n   یہاں  یہی  \n0   0.0  0.0  \n1   0.0  0.0  \n2   0.0  0.0  \n3   0.0  0.0  \n4   0.0  0.0  \n5   1.0  0.0  \n6   0.0  0.0  \n7   0.0  0.0  \n8   0.0  0.0  \n9   0.0  0.0  \n\n[10 rows x 579 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>head</th>\n      <th>start_char</th>\n      <th>end_char</th>\n      <th>y</th>\n      <th>upos_ADJ</th>\n      <th>upos_ADP</th>\n      <th>upos_ADV</th>\n      <th>upos_AUX</th>\n      <th>upos_CCONJ</th>\n      <th>upos_DET</th>\n      <th>...</th>\n      <th>ہوں</th>\n      <th>ہی</th>\n      <th>ہیں</th>\n      <th>ہے</th>\n      <th>یا</th>\n      <th>یعنی</th>\n      <th>یقینا</th>\n      <th>یہ</th>\n      <th>یہاں</th>\n      <th>یہی</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.014493</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.646062</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.036232</td>\n      <td>0.000003</td>\n      <td>0.000005</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.014493</td>\n      <td>0.000008</td>\n      <td>0.000008</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.036232</td>\n      <td>0.000011</td>\n      <td>0.000012</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.050725</td>\n      <td>0.000015</td>\n      <td>0.000018</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.050725</td>\n      <td>0.000020</td>\n      <td>0.000022</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.000000</td>\n      <td>0.000025</td>\n      <td>0.000027</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.021739</td>\n      <td>0.000032</td>\n      <td>0.000032</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.021739</td>\n      <td>0.000035</td>\n      <td>0.000036</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.000000</td>\n      <td>0.000039</td>\n      <td>0.000041</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 579 columns</p>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"# Define the feature matrix (drop 'y') and target\nX = data.drop(columns=['y'])\ny = data['y']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:16.743043Z","iopub.execute_input":"2024-12-27T11:41:16.743413Z","iopub.status.idle":"2024-12-27T11:41:17.080868Z","shell.execute_reply.started":"2024-12-27T11:41:16.743385Z","shell.execute_reply":"2024-12-27T11:41:17.079897Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# Split into training (64%), validation (16%), and test (20%) sets\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.36, random_state=42, stratify=y)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.56, random_state=42, stratify=y_temp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:17.082083Z","iopub.execute_input":"2024-12-27T11:41:17.082361Z","iopub.status.idle":"2024-12-27T11:41:18.585264Z","shell.execute_reply.started":"2024-12-27T11:41:17.082335Z","shell.execute_reply":"2024-12-27T11:41:18.584528Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom imblearn.over_sampling import SMOTE\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:18.586376Z","iopub.execute_input":"2024-12-27T11:41:18.586779Z","iopub.status.idle":"2024-12-27T11:41:18.592349Z","shell.execute_reply.started":"2024-12-27T11:41:18.586740Z","shell.execute_reply":"2024-12-27T11:41:18.591511Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n# Compute class weights based on the class distribution in the target variable y\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\nclass_weight_dict = dict(zip(np.unique(y_train), class_weights))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:18.593448Z","iopub.execute_input":"2024-12-27T11:41:18.593834Z","iopub.status.idle":"2024-12-27T11:41:18.637153Z","shell.execute_reply.started":"2024-12-27T11:41:18.593807Z","shell.execute_reply":"2024-12-27T11:41:18.636267Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom imblearn.over_sampling import SMOTE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:18.638519Z","iopub.execute_input":"2024-12-27T11:41:18.638860Z","iopub.status.idle":"2024-12-27T11:41:18.643924Z","shell.execute_reply.started":"2024-12-27T11:41:18.638824Z","shell.execute_reply":"2024-12-27T11:41:18.643152Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# Apply SMOTE to the training data\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:18.645790Z","iopub.execute_input":"2024-12-27T11:41:18.646075Z","iopub.status.idle":"2024-12-27T11:41:23.772174Z","shell.execute_reply.started":"2024-12-27T11:41:18.646036Z","shell.execute_reply":"2024-12-27T11:41:23.771504Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# Reshape the resampled data for LSTM input (3D tensor: [samples, timesteps, features])\nX_train_resampled_lstm = X_train_resampled.values.reshape(X_train_resampled.shape[0], 1, X_train_resampled.shape[1])\nX_val_lstm = X_val.values.reshape(X_val.shape[0], 1, X_val.shape[1])\nX_test_lstm = X_test.values.reshape(X_test.shape[0], 1, X_test.shape[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:23.773142Z","iopub.execute_input":"2024-12-27T11:41:23.773406Z","iopub.status.idle":"2024-12-27T11:41:24.206697Z","shell.execute_reply.started":"2024-12-27T11:41:23.773380Z","shell.execute_reply":"2024-12-27T11:41:24.205656Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Convert target variables to supported dtype\ny_train_resampled = y_train_resampled.to_numpy(dtype='int32')\ny_val = y_val.to_numpy(dtype='int32')\ny_test = y_test.to_numpy(dtype='int32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:24.207797Z","iopub.execute_input":"2024-12-27T11:41:24.208068Z","iopub.status.idle":"2024-12-27T11:41:24.214999Z","shell.execute_reply.started":"2024-12-27T11:41:24.208044Z","shell.execute_reply":"2024-12-27T11:41:24.214096Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# Ensure feature data is in float32\ndef ensure_float32(data):\n    return data.astype('float32')\n\nX_train_resampled_lstm = ensure_float32(X_train_resampled_lstm)\nX_val_lstm = ensure_float32(X_val_lstm)\nX_test_lstm = ensure_float32(X_test_lstm)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:24.216082Z","iopub.execute_input":"2024-12-27T11:41:24.216325Z","iopub.status.idle":"2024-12-27T11:41:24.555889Z","shell.execute_reply.started":"2024-12-27T11:41:24.216301Z","shell.execute_reply":"2024-12-27T11:41:24.554836Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# Update the output layer of the LSTM model\nmodel = Sequential([\n    LSTM(128, input_shape=(X_train_resampled_lstm.shape[1], X_train_resampled_lstm.shape[2]), return_sequences=False),\n    BatchNormalization(),\n    Dropout(0.2),\n    Dense(64, activation='relu'),\n    Dropout(0.2),\n    Dense(2, activation='softmax')  # Updated to 2 output classes\n])\n\n# Compile the model with the appropriate loss function\nmodel.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Set up early stopping to prevent overfitting\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n# Train the model with class weights and resampled data\nhistory = model.fit(\n    X_train_resampled_lstm, y_train_resampled,\n    validation_data=(X_val_lstm, y_val),\n    epochs=10,\n    batch_size=64,\n    class_weight=class_weight_dict,  # Add class weights here\n    callbacks=[early_stopping],\n    verbose=2\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:41:44.528889Z","iopub.execute_input":"2024-12-27T11:41:44.529228Z","iopub.status.idle":"2024-12-27T11:45:28.608067Z","shell.execute_reply.started":"2024-12-27T11:41:44.529197Z","shell.execute_reply":"2024-12-27T11:45:28.607095Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n4636/4636 - 26s - 6ms/step - accuracy: 0.8370 - loss: 0.3781 - val_accuracy: 0.7656 - val_loss: 0.6989\nEpoch 2/10\n4636/4636 - 22s - 5ms/step - accuracy: 0.8742 - loss: 0.2841 - val_accuracy: 0.7996 - val_loss: 0.6834\nEpoch 3/10\n4636/4636 - 22s - 5ms/step - accuracy: 0.8850 - loss: 0.2589 - val_accuracy: 0.7972 - val_loss: 0.6636\nEpoch 4/10\n4636/4636 - 22s - 5ms/step - accuracy: 0.8901 - loss: 0.2470 - val_accuracy: 0.7915 - val_loss: 0.6616\nEpoch 5/10\n4636/4636 - 22s - 5ms/step - accuracy: 0.8935 - loss: 0.2373 - val_accuracy: 0.7997 - val_loss: 0.6035\nEpoch 6/10\n4636/4636 - 22s - 5ms/step - accuracy: 0.8951 - loss: 0.2339 - val_accuracy: 0.8213 - val_loss: 0.5932\nEpoch 7/10\n4636/4636 - 21s - 5ms/step - accuracy: 0.8986 - loss: 0.2275 - val_accuracy: 0.8089 - val_loss: 0.5783\nEpoch 8/10\n4636/4636 - 22s - 5ms/step - accuracy: 0.8994 - loss: 0.2236 - val_accuracy: 0.8097 - val_loss: 0.5859\nEpoch 9/10\n4636/4636 - 22s - 5ms/step - accuracy: 0.9011 - loss: 0.2198 - val_accuracy: 0.8192 - val_loss: 0.6063\nEpoch 10/10\n4636/4636 - 22s - 5ms/step - accuracy: 0.9018 - loss: 0.2192 - val_accuracy: 0.8072 - val_loss: 0.5935\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"# Evaluate the model on the test set\ntest_loss, test_accuracy = model.evaluate(X_test_lstm, y_test, verbose=2)\nprint(f\"Test Loss: {test_loss}\")\nprint(f\"Test Accuracy: {test_accuracy}\")\n\n# Make predictions on the test set\ny_pred = model.predict(X_test_lstm)\ny_pred_classes = np.argmax(y_pred, axis=1)  # Get the predicted class labels\n\n# Evaluate performance with precision, recall, and F1-score\nprint(classification_report(y_test, y_pred_classes))\nprint(confusion_matrix(y_test, y_pred_classes))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T11:45:28.609971Z","iopub.execute_input":"2024-12-27T11:45:28.610324Z","iopub.status.idle":"2024-12-27T11:45:34.699643Z","shell.execute_reply.started":"2024-12-27T11:45:28.610288Z","shell.execute_reply":"2024-12-27T11:45:34.698716Z"}},"outputs":[{"name":"stdout","text":"1517/1517 - 3s - 2ms/step - accuracy: 0.8112 - loss: 0.5706\nTest Loss: 0.5705779790878296\nTest Accuracy: 0.8111816048622131\n\u001b[1m1517/1517\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n              precision    recall  f1-score   support\n\n           0       1.00      0.80      0.89     46727\n           1       0.16      0.98      0.28      1817\n\n    accuracy                           0.81     48544\n   macro avg       0.58      0.89      0.59     48544\nweighted avg       0.97      0.81      0.87     48544\n\n[[37605  9122]\n [   44  1773]]\n","output_type":"stream"}],"execution_count":46}]}