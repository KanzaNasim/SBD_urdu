{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>اس</td>\n",
       "      <td>یہ</td>\n",
       "      <td>DET</td>\n",
       "      <td>DEM</td>\n",
       "      <td>2</td>\n",
       "      <td>det</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>سلسلے</td>\n",
       "      <td>سلسلہ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>5</td>\n",
       "      <td>nmod</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>کی</td>\n",
       "      <td>کا</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PSP</td>\n",
       "      <td>2</td>\n",
       "      <td>case</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>دیگر</td>\n",
       "      <td>دیگر</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>5</td>\n",
       "      <td>amod</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>اقساط</td>\n",
       "      <td>اقساط</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>7</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   text  lemma  upos xpos  head deprel  start_char  end_char\n",
       "0   1     اس     یہ   DET  DEM     2    det           0         2\n",
       "1   2  سلسلے  سلسلہ  NOUN   NN     5   nmod           3         8\n",
       "2   3     کی     کا   ADP  PSP     2   case           9        11\n",
       "3   4   دیگر   دیگر   ADJ   JJ     5   amod          12        16\n",
       "4   5  اقساط  اقساط  NOUN   NN     7  nsubj          17        22"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>اس</td>\n",
       "      <td>یہ</td>\n",
       "      <td>DET</td>\n",
       "      <td>DEM</td>\n",
       "      <td>2</td>\n",
       "      <td>det</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>سلسلے</td>\n",
       "      <td>سلسلہ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>5</td>\n",
       "      <td>nmod</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کی</td>\n",
       "      <td>کا</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PSP</td>\n",
       "      <td>2</td>\n",
       "      <td>case</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>دیگر</td>\n",
       "      <td>دیگر</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>5</td>\n",
       "      <td>amod</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اقساط</td>\n",
       "      <td>اقساط</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>7</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>یہاں</td>\n",
       "      <td>یہاں</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>7</td>\n",
       "      <td>obl</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>پڑھیے</td>\n",
       "      <td>پڑھ</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VM</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>۔</td>\n",
       "      <td>۔</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>SYM</td>\n",
       "      <td>7</td>\n",
       "      <td>punct</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>یہ</td>\n",
       "      <td>یہ</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>3</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>کیسے</td>\n",
       "      <td>کیسا</td>\n",
       "      <td>PRON</td>\n",
       "      <td>WQ</td>\n",
       "      <td>3</td>\n",
       "      <td>advmod</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text  lemma   upos xpos  head  deprel  start_char  end_char  y\n",
       "0     اس     یہ    DET  DEM     2     det           0         2  0\n",
       "1  سلسلے  سلسلہ   NOUN   NN     5    nmod           3         8  0\n",
       "2     کی     کا    ADP  PSP     2    case           9        11  0\n",
       "3   دیگر   دیگر    ADJ   JJ     5    amod          12        16  0\n",
       "4  اقساط  اقساط   NOUN   NN     7   nsubj          17        22  0\n",
       "5   یہاں   یہاں   PRON  PRP     7     obl          23        27  0\n",
       "6  پڑھیے    پڑھ   VERB   VM     0    root          28        33  0\n",
       "7      ۔      ۔  PUNCT  SYM     7   punct          33        34  0\n",
       "8     یہ     یہ   PRON  PRP     3   nsubj          36        38  1\n",
       "9   کیسے   کیسا   PRON   WQ     3  advmod          39        43  0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a new column 'y' with the default value 'S_M'\n",
    "data['y'] = 'S_M'\n",
    "\n",
    "# Iterate through the rows to assign 'S_B'\n",
    "for i in range(len(data) - 1):\n",
    "    # Check if the current word ends with a full stop\n",
    "    if data.loc[i, 'text'].endswith('۔'):\n",
    "        # Assign 'S_B' to the next word\n",
    "        if i + 1 < len(data):\n",
    "            data.loc[i + 1, 'y'] = 'S_B'  # Sentence Beginning\n",
    "\n",
    "# Convert 'y' column to categorical type (optional, for ML efficiency)\n",
    "data['y'] = data['y'].astype('category')\n",
    "\n",
    "# Map categorical labels to numeric values\n",
    "label_mapping = {'S_B': 1, 'S_M': 0}\n",
    "data['y'] = data['y'].map(label_mapping)\n",
    "\n",
    "# Verify the result\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>اس</td>\n",
       "      <td>یہ</td>\n",
       "      <td>DET</td>\n",
       "      <td>DEM</td>\n",
       "      <td>2</td>\n",
       "      <td>det</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>سلسلے</td>\n",
       "      <td>سلسلہ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>5</td>\n",
       "      <td>nmod</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کی</td>\n",
       "      <td>کا</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PSP</td>\n",
       "      <td>2</td>\n",
       "      <td>case</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>دیگر</td>\n",
       "      <td>دیگر</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>5</td>\n",
       "      <td>amod</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اقساط</td>\n",
       "      <td>اقساط</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>7</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>یہاں</td>\n",
       "      <td>یہاں</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>7</td>\n",
       "      <td>obl</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>پڑھیے</td>\n",
       "      <td>پڑھ</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VM</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>یہ</td>\n",
       "      <td>یہ</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>3</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>کیسے</td>\n",
       "      <td>کیسا</td>\n",
       "      <td>PRON</td>\n",
       "      <td>WQ</td>\n",
       "      <td>3</td>\n",
       "      <td>advmod</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ممکن</td>\n",
       "      <td>ممکن</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     text  lemma  upos xpos  head  deprel  start_char  end_char  y\n",
       "0      اس     یہ   DET  DEM     2     det           0         2  0\n",
       "1   سلسلے  سلسلہ  NOUN   NN     5    nmod           3         8  0\n",
       "2      کی     کا   ADP  PSP     2    case           9        11  0\n",
       "3    دیگر   دیگر   ADJ   JJ     5    amod          12        16  0\n",
       "4   اقساط  اقساط  NOUN   NN     7   nsubj          17        22  0\n",
       "5    یہاں   یہاں  PRON  PRP     7     obl          23        27  0\n",
       "6   پڑھیے    پڑھ  VERB   VM     0    root          28        33  0\n",
       "8      یہ     یہ  PRON  PRP     3   nsubj          36        38  1\n",
       "9    کیسے   کیسا  PRON   WQ     3  advmod          39        43  0\n",
       "10   ممکن   ممکن   ADJ   JJ     0    root          44        48  0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows where the 'text' column contains only punctuation\n",
    "data = data[~data['text'].str.contains(r'^[^\\w\\s]+$', na=False)]\n",
    "\n",
    "# Verify the result\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode 'upos', 'xpos', and 'deprel'\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_cats = encoder.fit_transform(data[['upos', 'xpos', 'deprel']])\n",
    "\n",
    "# Convert to DataFrame for easier merging\n",
    "encoded_cats_df = pd.DataFrame(encoded_cats, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Concatenate encoded features back to the dataset\n",
    "data = pd.concat([data.reset_index(drop=True), encoded_cats_df], axis=1)\n",
    "\n",
    "# Drop the original categorical columns (optional)\n",
    "data = data.drop(columns=['upos', 'xpos', 'deprel','lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the numerical features to normalize\n",
    "numerical_features = ['start_char', 'end_char', 'head']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Option 2: Min-Max Scaling (scales features to a range, typically 0 to 1)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "data[numerical_features] = min_max_scaler.fit_transform(data[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>head</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "      <th>y</th>\n",
       "      <th>upos_ADJ</th>\n",
       "      <th>upos_ADP</th>\n",
       "      <th>upos_ADV</th>\n",
       "      <th>upos_AUX</th>\n",
       "      <th>upos_CCONJ</th>\n",
       "      <th>...</th>\n",
       "      <th>deprel_mark</th>\n",
       "      <th>deprel_nmod</th>\n",
       "      <th>deprel_nsubj</th>\n",
       "      <th>deprel_nummod</th>\n",
       "      <th>deprel_obj</th>\n",
       "      <th>deprel_obl</th>\n",
       "      <th>deprel_punct</th>\n",
       "      <th>deprel_root</th>\n",
       "      <th>deprel_vocative</th>\n",
       "      <th>deprel_xcomp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>اس</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>سلسلے</td>\n",
       "      <td>0.036232</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کی</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>دیگر</td>\n",
       "      <td>0.036232</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اقساط</td>\n",
       "      <td>0.050725</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>یہاں</td>\n",
       "      <td>0.050725</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>پڑھیے</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>یہ</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>کیسے</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ممکن</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    text      head  start_char  end_char  y  upos_ADJ  upos_ADP  upos_ADV  \\\n",
       "0     اس  0.014493    0.000000  0.000000  0       0.0       0.0       0.0   \n",
       "1  سلسلے  0.036232    0.000003  0.000005  0       0.0       0.0       0.0   \n",
       "2     کی  0.014493    0.000008  0.000008  0       0.0       1.0       0.0   \n",
       "3   دیگر  0.036232    0.000011  0.000012  0       1.0       0.0       0.0   \n",
       "4  اقساط  0.050725    0.000015  0.000018  0       0.0       0.0       0.0   \n",
       "5   یہاں  0.050725    0.000020  0.000022  0       0.0       0.0       0.0   \n",
       "6  پڑھیے  0.000000    0.000025  0.000027  0       0.0       0.0       0.0   \n",
       "7     یہ  0.021739    0.000032  0.000032  1       0.0       0.0       0.0   \n",
       "8   کیسے  0.021739    0.000035  0.000036  0       0.0       0.0       0.0   \n",
       "9   ممکن  0.000000    0.000039  0.000041  0       1.0       0.0       0.0   \n",
       "\n",
       "   upos_AUX  upos_CCONJ  ...  deprel_mark  deprel_nmod  deprel_nsubj  \\\n",
       "0       0.0         0.0  ...          0.0          0.0           0.0   \n",
       "1       0.0         0.0  ...          0.0          1.0           0.0   \n",
       "2       0.0         0.0  ...          0.0          0.0           0.0   \n",
       "3       0.0         0.0  ...          0.0          0.0           0.0   \n",
       "4       0.0         0.0  ...          0.0          0.0           1.0   \n",
       "5       0.0         0.0  ...          0.0          0.0           0.0   \n",
       "6       0.0         0.0  ...          0.0          0.0           0.0   \n",
       "7       0.0         0.0  ...          0.0          0.0           1.0   \n",
       "8       0.0         0.0  ...          0.0          0.0           0.0   \n",
       "9       0.0         0.0  ...          0.0          0.0           0.0   \n",
       "\n",
       "   deprel_nummod  deprel_obj  deprel_obl  deprel_punct  deprel_root  \\\n",
       "0            0.0         0.0         0.0           0.0          0.0   \n",
       "1            0.0         0.0         0.0           0.0          0.0   \n",
       "2            0.0         0.0         0.0           0.0          0.0   \n",
       "3            0.0         0.0         0.0           0.0          0.0   \n",
       "4            0.0         0.0         0.0           0.0          0.0   \n",
       "5            0.0         0.0         1.0           0.0          0.0   \n",
       "6            0.0         0.0         0.0           0.0          1.0   \n",
       "7            0.0         0.0         0.0           0.0          0.0   \n",
       "8            0.0         0.0         0.0           0.0          0.0   \n",
       "9            0.0         0.0         0.0           0.0          1.0   \n",
       "\n",
       "   deprel_vocative  deprel_xcomp  \n",
       "0              0.0           0.0  \n",
       "1              0.0           0.0  \n",
       "2              0.0           0.0  \n",
       "3              0.0           0.0  \n",
       "4              0.0           0.0  \n",
       "5              0.0           0.0  \n",
       "6              0.0           0.0  \n",
       "7              0.0           0.0  \n",
       "8              0.0           0.0  \n",
       "9              0.0           0.0  \n",
       "\n",
       "[10 rows x 80 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the result\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText, KeyedVectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanza Nasim\\AppData\\Local\\Temp\\ipykernel_26552\\3350117351.py:3: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  fasttext_model = FastText.load_fasttext_format(\"C:\\\\Users\\\\Kanza Nasim\\\\Downloads\\\\embeddings\\\\cc.ur.300.bin\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "fasttext_model = FastText.load_fasttext_format(\"C:\\\\Users\\\\Kanza Nasim\\\\Downloads\\\\embeddings\\\\cc.ur.300.bin\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************************************************************* NO NO**********************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence, model):\n",
    "    \"\"\"\n",
    "    Computes the mean FastText embedding for a sentence.\n",
    "    \"\"\"\n",
    "    words = sentence.split()\n",
    "    embeddings = []\n",
    "    for word in words:\n",
    "        if word in model.wv:  # Check if the word is in the vocabulary\n",
    "            embeddings.append(model.wv[word])  # Access the word vector using the 'wv' attribute\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # Return a zero vector if no words are found\n",
    "\n",
    "\n",
    "# Generate FastText embeddings for each row\n",
    "data['fasttext_embedding'] = data['text'].apply(lambda x: get_sentence_embedding(x, fasttext_model))\n",
    "\n",
    "# Convert the embeddings into a numpy array\n",
    "embedding_matrix = np.vstack(data['fasttext_embedding'].values)\n",
    "\n",
    "# Drop the original text-related columns (optional)\n",
    "data = data.drop(columns=['text', 'fasttext_embedding'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add FastText embeddings as features\n",
    "embedding_df = pd.DataFrame(embedding_matrix, columns=[f'ft_dim_{i}' for i in range(embedding_matrix.shape[1])])\n",
    "data = pd.concat([data.reset_index(drop=True), embedding_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "      <th>y</th>\n",
       "      <th>upos_ADJ</th>\n",
       "      <th>upos_ADP</th>\n",
       "      <th>upos_ADV</th>\n",
       "      <th>upos_AUX</th>\n",
       "      <th>upos_CCONJ</th>\n",
       "      <th>upos_DET</th>\n",
       "      <th>...</th>\n",
       "      <th>ft_dim_290</th>\n",
       "      <th>ft_dim_291</th>\n",
       "      <th>ft_dim_292</th>\n",
       "      <th>ft_dim_293</th>\n",
       "      <th>ft_dim_294</th>\n",
       "      <th>ft_dim_295</th>\n",
       "      <th>ft_dim_296</th>\n",
       "      <th>ft_dim_297</th>\n",
       "      <th>ft_dim_298</th>\n",
       "      <th>ft_dim_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083593</td>\n",
       "      <td>-0.094064</td>\n",
       "      <td>-0.041935</td>\n",
       "      <td>-0.013302</td>\n",
       "      <td>-0.014009</td>\n",
       "      <td>-0.106306</td>\n",
       "      <td>0.029570</td>\n",
       "      <td>0.141715</td>\n",
       "      <td>-0.008373</td>\n",
       "      <td>-0.046092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036232</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009919</td>\n",
       "      <td>-0.005164</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>-0.032672</td>\n",
       "      <td>-0.028227</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>-0.019054</td>\n",
       "      <td>0.029461</td>\n",
       "      <td>0.015847</td>\n",
       "      <td>-0.001126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>-0.096879</td>\n",
       "      <td>-0.015673</td>\n",
       "      <td>0.040102</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>-0.046326</td>\n",
       "      <td>-0.042110</td>\n",
       "      <td>-0.048978</td>\n",
       "      <td>-0.052121</td>\n",
       "      <td>-0.037590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036232</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007919</td>\n",
       "      <td>-0.000579</td>\n",
       "      <td>0.012618</td>\n",
       "      <td>-0.003285</td>\n",
       "      <td>0.028999</td>\n",
       "      <td>0.023561</td>\n",
       "      <td>0.031377</td>\n",
       "      <td>-0.030129</td>\n",
       "      <td>-0.009216</td>\n",
       "      <td>0.040360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050725</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090482</td>\n",
       "      <td>0.035621</td>\n",
       "      <td>-0.018918</td>\n",
       "      <td>-0.143578</td>\n",
       "      <td>-0.021579</td>\n",
       "      <td>0.056538</td>\n",
       "      <td>-0.083902</td>\n",
       "      <td>0.070562</td>\n",
       "      <td>-0.014618</td>\n",
       "      <td>-0.061094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 379 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       head  start_char  end_char  y  upos_ADJ  upos_ADP  upos_ADV  upos_AUX  \\\n",
       "0  0.014493    0.000000  0.000000  0       0.0       0.0       0.0       0.0   \n",
       "1  0.036232    0.000003  0.000005  0       0.0       0.0       0.0       0.0   \n",
       "2  0.014493    0.000008  0.000008  0       0.0       1.0       0.0       0.0   \n",
       "3  0.036232    0.000011  0.000012  0       1.0       0.0       0.0       0.0   \n",
       "4  0.050725    0.000015  0.000018  0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   upos_CCONJ  upos_DET  ...  ft_dim_290  ft_dim_291  ft_dim_292  ft_dim_293  \\\n",
       "0         0.0       1.0  ...    0.083593   -0.094064   -0.041935   -0.013302   \n",
       "1         0.0       0.0  ...   -0.009919   -0.005164    0.005828   -0.032672   \n",
       "2         0.0       0.0  ...    0.009689   -0.096879   -0.015673    0.040102   \n",
       "3         0.0       0.0  ...    0.007919   -0.000579    0.012618   -0.003285   \n",
       "4         0.0       0.0  ...    0.090482    0.035621   -0.018918   -0.143578   \n",
       "\n",
       "   ft_dim_294  ft_dim_295  ft_dim_296  ft_dim_297  ft_dim_298  ft_dim_299  \n",
       "0   -0.014009   -0.106306    0.029570    0.141715   -0.008373   -0.046092  \n",
       "1   -0.028227    0.011800   -0.019054    0.029461    0.015847   -0.001126  \n",
       "2   -0.020523   -0.046326   -0.042110   -0.048978   -0.052121   -0.037590  \n",
       "3    0.028999    0.023561    0.031377   -0.030129   -0.009216    0.040360  \n",
       "4   -0.021579    0.056538   -0.083902    0.070562   -0.014618   -0.061094  \n",
       "\n",
       "[5 rows x 379 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature matrix (drop 'y') and target\n",
    "X = data.drop(columns=['y'])\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training (64%), validation (16%), and test (20%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.36, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.56, random_state=42, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Train Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    148335\n",
      "           1       0.82      0.64      0.72      5768\n",
      "\n",
      "    accuracy                           0.98    154103\n",
      "   macro avg       0.90      0.81      0.85    154103\n",
      "weighted avg       0.98      0.98      0.98    154103\n",
      "\n",
      "Decision Tree - Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     36713\n",
      "           1       0.78      0.57      0.66      1427\n",
      "\n",
      "    accuracy                           0.98     38140\n",
      "   macro avg       0.88      0.78      0.83     38140\n",
      "weighted avg       0.98      0.98      0.98     38140\n",
      "\n",
      "Decision Tree - Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     46727\n",
      "           1       0.76      0.58      0.66      1817\n",
      "\n",
      "    accuracy                           0.98     48544\n",
      "   macro avg       0.87      0.79      0.82     48544\n",
      "weighted avg       0.98      0.98      0.98     48544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42, max_depth=10)  \n",
    "# Fit the model on the training set\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = dt_model.predict(X_train)\n",
    "y_val_pred = dt_model.predict(X_val)\n",
    "y_test_pred = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree - Train Set:\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(\"Decision Tree - Validation Set:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "print(\"Decision Tree - Test Set:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:13:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Train Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    148335\n",
      "           1       0.87      0.74      0.80      5768\n",
      "\n",
      "    accuracy                           0.99    154103\n",
      "   macro avg       0.93      0.87      0.89    154103\n",
      "weighted avg       0.99      0.99      0.99    154103\n",
      "\n",
      "XGBoost - Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     36713\n",
      "           1       0.81      0.66      0.72      1427\n",
      "\n",
      "    accuracy                           0.98     38140\n",
      "   macro avg       0.90      0.82      0.86     38140\n",
      "weighted avg       0.98      0.98      0.98     38140\n",
      "\n",
      "XGBoost - Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     46727\n",
      "           1       0.81      0.66      0.73      1817\n",
      "\n",
      "    accuracy                           0.98     48544\n",
      "   macro avg       0.90      0.83      0.86     48544\n",
      "weighted avg       0.98      0.98      0.98     48544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize XGBoost\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation and test sets\n",
    "y_train_pred_xgb = xgb_model.predict(X_train)\n",
    "y_val_pred_xgb = xgb_model.predict(X_val)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate XGBoost\n",
    "print(\"XGBoost - Train Set:\")\n",
    "print(classification_report(y_train, y_train_pred_xgb))\n",
    "print(\"XGBoost - Validation Set:\")\n",
    "print(classification_report(y_val, y_val_pred_xgb))\n",
    "print(\"XGBoost - Test Set:\")\n",
    "print(classification_report(y_test, y_test_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Train Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    148335\n",
      "           1       1.00      1.00      1.00      5768\n",
      "\n",
      "    accuracy                           1.00    154103\n",
      "   macro avg       1.00      1.00      1.00    154103\n",
      "weighted avg       1.00      1.00      1.00    154103\n",
      "\n",
      "Random Forest - Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     36713\n",
      "           1       0.75      0.61      0.67      1427\n",
      "\n",
      "    accuracy                           0.98     38140\n",
      "   macro avg       0.87      0.80      0.83     38140\n",
      "weighted avg       0.98      0.98      0.98     38140\n",
      "\n",
      "Random Forest - Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     46727\n",
      "           1       0.73      0.60      0.66      1817\n",
      "\n",
      "    accuracy                           0.98     48544\n",
      "   macro avg       0.86      0.80      0.82     48544\n",
      "weighted avg       0.97      0.98      0.98     48544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# Initialize Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation and test sets\n",
    "# also predict on the training set to see how well the model is doing\n",
    "y_train_pred_rf = rf_model.predict(X_train)\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"Random Forest - Train Set:\")\n",
    "print(classification_report(y_train, y_train_pred_rf))\n",
    "print(\"Random Forest - Validation Set:\")\n",
    "print(classification_report(y_val, y_val_pred_rf))\n",
    "print(\"Random Forest - Test Set:\")\n",
    "print(classification_report(y_test, y_test_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4816/4816 [==============================] - 22s 4ms/step - loss: 0.1004 - accuracy: 0.9637 - val_loss: 0.0842 - val_accuracy: 0.9649\n",
      "Epoch 2/10\n",
      "4816/4816 [==============================] - 20s 4ms/step - loss: 0.0833 - accuracy: 0.9676 - val_loss: 0.0765 - val_accuracy: 0.9682\n",
      "Epoch 3/10\n",
      "4816/4816 [==============================] - 19s 4ms/step - loss: 0.0755 - accuracy: 0.9697 - val_loss: 0.0692 - val_accuracy: 0.9730\n",
      "Epoch 4/10\n",
      "4816/4816 [==============================] - 20s 4ms/step - loss: 0.0703 - accuracy: 0.9721 - val_loss: 0.0656 - val_accuracy: 0.9736\n",
      "Epoch 5/10\n",
      "4816/4816 [==============================] - 21s 4ms/step - loss: 0.0666 - accuracy: 0.9729 - val_loss: 0.0660 - val_accuracy: 0.9737\n",
      "Epoch 6/10\n",
      "4816/4816 [==============================] - 21s 4ms/step - loss: 0.0635 - accuracy: 0.9744 - val_loss: 0.0615 - val_accuracy: 0.9744\n",
      "Epoch 7/10\n",
      "4816/4816 [==============================] - 20s 4ms/step - loss: 0.0619 - accuracy: 0.9753 - val_loss: 0.0599 - val_accuracy: 0.9761\n",
      "Epoch 8/10\n",
      "4816/4816 [==============================] - 21s 4ms/step - loss: 0.0599 - accuracy: 0.9758 - val_loss: 0.0601 - val_accuracy: 0.9764\n",
      "Epoch 9/10\n",
      "4816/4816 [==============================] - 20s 4ms/step - loss: 0.0585 - accuracy: 0.9760 - val_loss: 0.0593 - val_accuracy: 0.9754\n",
      "Epoch 10/10\n",
      "4816/4816 [==============================] - 19s 4ms/step - loss: 0.0568 - accuracy: 0.9769 - val_loss: 0.0597 - val_accuracy: 0.9757\n",
      "Validation Accuracy: 0.9757\n",
      "1192/1192 [==============================] - 3s 2ms/step\n",
      "Classification Report (Validation):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     36713\n",
      "           1       0.76      0.52      0.61      1427\n",
      "\n",
      "    accuracy                           0.98     38140\n",
      "   macro avg       0.87      0.76      0.80     38140\n",
      "weighted avg       0.97      0.98      0.97     38140\n",
      "\n",
      "1517/1517 [==============================] - 3s 2ms/step\n",
      "Test Accuracy: 0.9763\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     46727\n",
      "           1       0.75      0.55      0.63      1817\n",
      "\n",
      "    accuracy                           0.98     48544\n",
      "   macro avg       0.87      0.77      0.81     48544\n",
      "weighted avg       0.97      0.98      0.97     48544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define a simple DNN model\n",
    "def create_dnn_model(input_dim, num_classes):\n",
    "    model = keras.Sequential([\n",
    "        layers.InputLayer(input_shape=(input_dim,)),  # Corrected input layer definition\n",
    "        layers.Dense(128, activation='relu'),  # Hidden layer with ReLU activation\n",
    "        layers.Dropout(0.2),  # Dropout for regularization\n",
    "        layers.Dense(64, activation='relu'),  # Another hidden layer\n",
    "        layers.Dropout(0.2),  # Dropout for regularization\n",
    "        layers.Dense(num_classes, activation='softmax')  # Output layer with softmax for multi-class classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy',  # Use sparse categorical crossentropy for integer labels\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the DNN model\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "num_classes = len(y.unique())  # Number of output classes ( S_B, S_M)\n",
    "\n",
    "dnn_model = create_dnn_model(input_dim, num_classes)\n",
    "\n",
    "# Train the DNN model\n",
    "dnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = dnn_model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = dnn_model.predict(X_val)\n",
    "y_val_pred = y_val_pred.argmax(axis=1)  # Get the predicted class labels\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report (Validation):\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Make predictions on the test set (optional)\n",
    "y_test_pred = dnn_model.predict(X_test)\n",
    "y_test_pred = y_test_pred.argmax(axis=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = dnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print(\"Classification Report (Test):\\n\", classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "# Compute class weights based on the class distribution in the target variable y\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DNN model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_dim=X_train.shape[1]),  # Input layer\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),  # Hidden layer\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),  # Hidden layer\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Output layer (binary classification)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DNN model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_dim=X_train.shape[1]),  # Input layer\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),  # Hidden layer\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),  # Hidden layer\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Output layer (binary classification)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4816/4816 [==============================] - 31s 6ms/step - loss: 0.4062 - accuracy: 0.7787 - val_loss: 0.3685 - val_accuracy: 0.8281\n",
      "Epoch 2/10\n",
      "4816/4816 [==============================] - 32s 7ms/step - loss: 0.3108 - accuracy: 0.8382 - val_loss: 0.3489 - val_accuracy: 0.8305\n",
      "Epoch 3/10\n",
      "4816/4816 [==============================] - 34s 7ms/step - loss: 0.2792 - accuracy: 0.8572 - val_loss: 0.3144 - val_accuracy: 0.8492\n",
      "Epoch 4/10\n",
      "4816/4816 [==============================] - 37s 8ms/step - loss: 0.2616 - accuracy: 0.8692 - val_loss: 0.3157 - val_accuracy: 0.8599\n",
      "Epoch 5/10\n",
      "4816/4816 [==============================] - 34s 7ms/step - loss: 0.2477 - accuracy: 0.8773 - val_loss: 0.2764 - val_accuracy: 0.8865\n",
      "Epoch 6/10\n",
      "4816/4816 [==============================] - 34s 7ms/step - loss: 0.2340 - accuracy: 0.8877 - val_loss: 0.2260 - val_accuracy: 0.9049\n",
      "Epoch 7/10\n",
      "4816/4816 [==============================] - 38s 8ms/step - loss: 0.2266 - accuracy: 0.8919 - val_loss: 0.2265 - val_accuracy: 0.9004\n",
      "Epoch 8/10\n",
      "4816/4816 [==============================] - 33s 7ms/step - loss: 0.2198 - accuracy: 0.8970 - val_loss: 0.2148 - val_accuracy: 0.9077\n",
      "Epoch 9/10\n",
      "4816/4816 [==============================] - 33s 7ms/step - loss: 0.2163 - accuracy: 0.8954 - val_loss: 0.2408 - val_accuracy: 0.9004\n",
      "Epoch 10/10\n",
      "4816/4816 [==============================] - 31s 6ms/step - loss: 0.2105 - accuracy: 0.8972 - val_loss: 0.2448 - val_accuracy: 0.8966\n"
     ]
    }
   ],
   "source": [
    "# Early stopping to avoid overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1517/1517 [==============================] - 4s 3ms/step - loss: 0.2453 - accuracy: 0.8977\n",
      "Test Loss: 0.2452559918165207\n",
      "Test Accuracy: 0.8976598381996155\n",
      "1517/1517 [==============================] - 4s 2ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.94     46727\n",
      "           1       0.26      0.95      0.41      1817\n",
      "\n",
      "    accuracy                           0.90     48544\n",
      "   macro avg       0.63      0.92      0.68     48544\n",
      "weighted avg       0.97      0.90      0.92     48544\n",
      "\n",
      "Confusion Matrix:\n",
      " [[41846  4881]\n",
      " [   87  1730]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Generate classification report and confusion matrix\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# Train the logistic regression model\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_train_pred = logistic_model.predict(X_train)\n",
    "y_val_pred = logistic_model.predict(X_val)\n",
    "y_test_pred = logistic_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Training Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98    148335\n",
      "           1       0.76      0.22      0.35      5768\n",
      "\n",
      "    accuracy                           0.97    154103\n",
      "   macro avg       0.86      0.61      0.66    154103\n",
      "weighted avg       0.96      0.97      0.96    154103\n",
      "\n",
      "Logistic Regression - Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     36713\n",
      "           1       0.73      0.22      0.33      1427\n",
      "\n",
      "    accuracy                           0.97     38140\n",
      "   macro avg       0.85      0.61      0.66     38140\n",
      "weighted avg       0.96      0.97      0.96     38140\n",
      "\n",
      "Logistic Regression - test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     46727\n",
      "           1       0.70      0.20      0.31      1817\n",
      "\n",
      "    accuracy                           0.97     48544\n",
      "   macro avg       0.83      0.60      0.65     48544\n",
      "weighted avg       0.96      0.97      0.96     48544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression - Training Set:\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(\"Logistic Regression - Validation Set:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"Logistic Regression - test Set:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
