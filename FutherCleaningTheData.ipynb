{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"KANZOO/scrapped_articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['title', 'text'],\n",
      "        num_rows: 144\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge all text into one large dataset\n",
    "def merge_all_text(dataset):\n",
    "    combined_text = \"\"\n",
    "    for example in dataset['train']:\n",
    "        combined_text += example['text'] + \" \"  # Add a space between articles\n",
    "    return combined_text.strip()\n",
    "\n",
    "# Merge all text from the dataset\n",
    "combined_text = merge_all_text(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Function to remove all punctuation except for Urdu period (۔)\n",
    "def remove_punctuation(text):\n",
    "    # Regex pattern to remove all punctuation except for \"۔\"\n",
    "    pattern = r'[^\\w\\s۔]'  # \\w matches word characters, \\s matches spaces, \"۔\" is kept\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# Remove all punctuation except for \"۔\"\n",
    "cleaned_text = remove_punctuation(combined_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences: 9251\n",
      "Small sentences (less than 3 words): ['1', '2', '3', '1', '2', '3', '4', '519 ق', '476 ق', '5', '5', '1', '2', '3', '1', '2', '3', '4', '519 ق', '476 ق', '5', '1', '2', '3', '1', '2', '3', '4', '519 ق', '476 ق']\n",
      "Number of small sentences: 30\n"
     ]
    }
   ],
   "source": [
    "# checking the length of shorter sentences to clean up the dataset\n",
    "def split_into_sentences(text):\n",
    "    sentences = text.split(\"۔\")  # Split the text at each Urdu period\n",
    "    return [sentence.strip() for sentence in sentences if sentence.strip()]  # Remove leading/trailing spaces\n",
    "\n",
    "# Function to find the length of each sentence\n",
    "def sentence_lengths(sentences):\n",
    "    return [len(sentence) for sentence in sentences]\n",
    "\n",
    "# Define a threshold for \"small\" sentences (e.g., sentences with fewer than 5 words)\n",
    "def find_small_sentences(sentences, length_threshold=3):\n",
    "    small_sentences = [sentence for sentence in sentences if len(sentence.split()) < length_threshold]\n",
    "    return small_sentences\n",
    "\n",
    "# Split the cleaned text into sentences\n",
    "sentences = split_into_sentences(cleaned_text)\n",
    "\n",
    "# Get the length of each sentence\n",
    "lengths = sentence_lengths(sentences)\n",
    "\n",
    "# Find sentences that are shorter than the threshold\n",
    "small_sentences = find_small_sentences(sentences)\n",
    "\n",
    "# Output\n",
    "print(f\"Total number of sentences: {len(sentences)}\")\n",
    "print(f\"Small sentences (less than 3 words): {small_sentences}\")\n",
    "print(f\"Number of small sentences: {len(small_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences after filtering: 9221\n"
     ]
    }
   ],
   "source": [
    "# Function to remove small sentences with fewer than 3 words\n",
    "def remove_small_sentences(sentences, word_threshold=3):\n",
    "    # Keep only sentences with 3 or more words\n",
    "    filtered_sentences = [sentence for sentence in sentences if len(sentence.split()) >= word_threshold]\n",
    "    return filtered_sentences\n",
    "\n",
    "# Split the cleaned text into sentences\n",
    "sentences = split_into_sentences(cleaned_text)\n",
    "\n",
    "# Remove sentences that have fewer than 3 words\n",
    "filtered_sentences = remove_small_sentences(sentences, word_threshold=3)\n",
    "\n",
    "# Recombine the filtered sentences back into a single text\n",
    "cleaned_filtered_text = \"۔ \".join(filtered_sentences)  # Add back the Urdu period between sentences\n",
    "\n",
    "# Output\n",
    "print(f\"Total number of sentences after filtering: {len(filtered_sentences)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences with 4 or fewer words:\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "مہاویر 527599 ق\n",
      "519 ق\n",
      "476 ق\n",
      "5\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "مہاویر 527599 ق\n",
      "519 ق\n",
      "476 ق\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "مہاویر 527599 ق\n",
      "519 ق\n",
      "476 ق\n",
      "\n",
      "Total number of sentences with 4 or fewer words: 33\n"
     ]
    }
   ],
   "source": [
    "# checking the length of shorter sentences to clean up the dataset further \n",
    "# Function to find sentences with 4 or fewer words\n",
    "def find_small_sentences(sentences, word_threshold=4):\n",
    "    # Find sentences that have 4 or fewer words\n",
    "    small_sentences = [sentence for sentence in sentences if len(sentence.split()) <= word_threshold]\n",
    "    return small_sentences\n",
    "\n",
    "# Split the cleaned text into sentences\n",
    "sentences = split_into_sentences(cleaned_text)\n",
    "\n",
    "# Find sentences with 4 or fewer words\n",
    "small_sentences = find_small_sentences(sentences, word_threshold=3)\n",
    "\n",
    "# Output the small sentences for inspection\n",
    "print(\"Sentences with 4 or fewer words:\")\n",
    "for sentence in small_sentences:\n",
    "    print(sentence)\n",
    "\n",
    "print(f\"\\nTotal number of sentences with 3 or fewer words: {len(small_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of remaining sentences: 9218\n"
     ]
    }
   ],
   "source": [
    "# Function to remove sentences with 3 or fewer words\n",
    "def remove_small_sentences(sentences, word_threshold=3):\n",
    "    # Keep only sentences that have more than 3 words\n",
    "    filtered_sentences = [sentence for sentence in sentences if len(sentence.split()) > word_threshold]\n",
    "    return filtered_sentences\n",
    "\n",
    "# Remove sentences with 3 or fewer words\n",
    "filtered_sentences = remove_small_sentences(sentences, word_threshold=3)\n",
    "\n",
    "print(f\"\\nTotal number of remaining sentences: {len(filtered_sentences)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences with 4 or fewer words from filtered sentences:\n",
      "پھر ایک اتفاق ہوا\n",
      "سورج ڈھل رہا ہے\n",
      "وہ نام ہے دلورائے\n",
      "سورج ڈھل رہا ہے\n",
      "وہ نام ہے دلورائے\n",
      "پھر ایک اتفاق ہوا\n",
      "ائیے جانتے ہیں کیسے\n",
      "سورج ڈھل رہا ہے\n",
      "وہ نام ہے دلورائے\n",
      "پھر ایک اتفاق ہوا\n",
      "ائیے جانتے ہیں کیسے\n",
      "\n",
      "Total number of sentences with 4 or fewer words: 11\n"
     ]
    }
   ],
   "source": [
    "# Now find sentences with 4 or fewer words from the filtered list\n",
    "small_sentences = find_small_sentences(filtered_sentences, word_threshold=4)\n",
    "\n",
    "# Output the small sentences for inspection\n",
    "print(\"Sentences with 4 or fewer words from filtered sentences:\")\n",
    "for sentence in small_sentences:\n",
    "    print(sentence)\n",
    "\n",
    "print(f\"\\nTotal number of sentences with 4 or fewer words: {len(small_sentences)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
