{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10113408,"sourceType":"datasetVersion","datasetId":6239597}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Approach 2:","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:50:16.561586Z","iopub.execute_input":"2024-12-16T16:50:16.565601Z","iopub.status.idle":"2024-12-16T16:50:17.879428Z","shell.execute_reply.started":"2024-12-16T16:50:16.565520Z","shell.execute_reply":"2024-12-16T16:50:17.878101Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Read the CSV file\ndf = pd.read_csv('/kaggle/input/sbd-data/dataset.csv')\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:50:17.881662Z","iopub.execute_input":"2024-12-16T16:50:17.882082Z","iopub.status.idle":"2024-12-16T16:50:19.954459Z","shell.execute_reply.started":"2024-12-16T16:50:17.882048Z","shell.execute_reply":"2024-12-16T16:50:19.953275Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   id   text  lemma  upos xpos  head deprel  start_char  end_char\n0   1     اس     یہ   DET  DEM     2    det           0         2\n1   2  سلسلے  سلسلہ  NOUN   NN     5   nmod           3         8\n2   3     کی     کا   ADP  PSP     2   case           9        11\n3   4   دیگر   دیگر   ADJ   JJ     5   amod          12        16\n4   5  اقساط  اقساط  NOUN   NN     7  nsubj          17        22","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>deprel</th>\n      <th>start_char</th>\n      <th>end_char</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>اس</td>\n      <td>یہ</td>\n      <td>DET</td>\n      <td>DEM</td>\n      <td>2</td>\n      <td>det</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>سلسلے</td>\n      <td>سلسلہ</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>5</td>\n      <td>nmod</td>\n      <td>3</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>کی</td>\n      <td>کا</td>\n      <td>ADP</td>\n      <td>PSP</td>\n      <td>2</td>\n      <td>case</td>\n      <td>9</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>دیگر</td>\n      <td>دیگر</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>5</td>\n      <td>amod</td>\n      <td>12</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>اقساط</td>\n      <td>اقساط</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>7</td>\n      <td>nsubj</td>\n      <td>17</td>\n      <td>22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"data = df.drop(columns=['id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:50:19.955850Z","iopub.execute_input":"2024-12-16T16:50:19.956272Z","iopub.status.idle":"2024-12-16T16:50:19.984754Z","shell.execute_reply.started":"2024-12-16T16:50:19.956224Z","shell.execute_reply":"2024-12-16T16:50:19.983649Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import numpy as np\n\n# Create a new column 'y' with default value 'S_M'\ndata['y'] = 'S_M'\n\n# Iterate through the rows to assign 'S_E' and 'S_B'\nfor i in range(len(data) - 1):\n    # Check if the current word ends with a full stop\n    if data.loc[i, 'text'].endswith('۔'):\n        data.loc[i, 'y'] = 'S_E'  # Sentence End\n        # Assign 'S_B' to the next word\n        if i + 1 < len(data):\n            data.loc[i + 1, 'y'] = 'S_B'  # Sentence Beginning\n\n# Convert 'y' column to categorical type (optional, for ML efficiency)\ndata['y'] = data['y'].astype('category')\n\n# Display the first few rows to verify\ndata.head(10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:50:19.987825Z","iopub.execute_input":"2024-12-16T16:50:19.988504Z","iopub.status.idle":"2024-12-16T16:50:25.188615Z","shell.execute_reply.started":"2024-12-16T16:50:19.988455Z","shell.execute_reply":"2024-12-16T16:50:25.187550Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"    text  lemma   upos xpos  head  deprel  start_char  end_char    y\n0     اس     یہ    DET  DEM     2     det           0         2  S_M\n1  سلسلے  سلسلہ   NOUN   NN     5    nmod           3         8  S_M\n2     کی     کا    ADP  PSP     2    case           9        11  S_M\n3   دیگر   دیگر    ADJ   JJ     5    amod          12        16  S_M\n4  اقساط  اقساط   NOUN   NN     7   nsubj          17        22  S_M\n5   یہاں   یہاں   PRON  PRP     7     obl          23        27  S_M\n6  پڑھیے    پڑھ   VERB   VM     0    root          28        33  S_M\n7      ۔      ۔  PUNCT  SYM     7   punct          33        34  S_E\n8     یہ     یہ   PRON  PRP     3   nsubj          36        38  S_B\n9   کیسے   کیسا   PRON   WQ     3  advmod          39        43  S_M","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>deprel</th>\n      <th>start_char</th>\n      <th>end_char</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>اس</td>\n      <td>یہ</td>\n      <td>DET</td>\n      <td>DEM</td>\n      <td>2</td>\n      <td>det</td>\n      <td>0</td>\n      <td>2</td>\n      <td>S_M</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>سلسلے</td>\n      <td>سلسلہ</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>5</td>\n      <td>nmod</td>\n      <td>3</td>\n      <td>8</td>\n      <td>S_M</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>کی</td>\n      <td>کا</td>\n      <td>ADP</td>\n      <td>PSP</td>\n      <td>2</td>\n      <td>case</td>\n      <td>9</td>\n      <td>11</td>\n      <td>S_M</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>دیگر</td>\n      <td>دیگر</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>5</td>\n      <td>amod</td>\n      <td>12</td>\n      <td>16</td>\n      <td>S_M</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>اقساط</td>\n      <td>اقساط</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>7</td>\n      <td>nsubj</td>\n      <td>17</td>\n      <td>22</td>\n      <td>S_M</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>یہاں</td>\n      <td>یہاں</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>7</td>\n      <td>obl</td>\n      <td>23</td>\n      <td>27</td>\n      <td>S_M</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>پڑھیے</td>\n      <td>پڑھ</td>\n      <td>VERB</td>\n      <td>VM</td>\n      <td>0</td>\n      <td>root</td>\n      <td>28</td>\n      <td>33</td>\n      <td>S_M</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>۔</td>\n      <td>۔</td>\n      <td>PUNCT</td>\n      <td>SYM</td>\n      <td>7</td>\n      <td>punct</td>\n      <td>33</td>\n      <td>34</td>\n      <td>S_E</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>یہ</td>\n      <td>یہ</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>3</td>\n      <td>nsubj</td>\n      <td>36</td>\n      <td>38</td>\n      <td>S_B</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>کیسے</td>\n      <td>کیسا</td>\n      <td>PRON</td>\n      <td>WQ</td>\n      <td>3</td>\n      <td>advmod</td>\n      <td>39</td>\n      <td>43</td>\n      <td>S_M</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import numpy as np\n\n# Create a new column 'y' with default value 'S_M'\ndata['y'] = 'S_M'\n\n# Iterate through the rows to assign 'S_E' and 'S_B'\nfor i in range(len(data) - 1):\n    # Check if the current word ends with a full stop\n    if data.loc[i, 'text'].endswith('۔'):\n        data.loc[i, 'y'] = 'S_E'  # Sentence End\n        # Assign 'S_B' to the next word\n        if i + 1 < len(data):\n            data.loc[i + 1, 'y'] = 'S_B'  # Sentence Beginning\n\n# Map categorical labels to numeric values\nlabel_mapping = {'S_E': 0, 'S_B': 1, 'S_M': 2}\ndata['y'] = data['y'].map(label_mapping)\n\n# Verify the result\ndata.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:50:25.190436Z","iopub.execute_input":"2024-12-16T16:50:25.191030Z","iopub.status.idle":"2024-12-16T16:50:30.176702Z","shell.execute_reply.started":"2024-12-16T16:50:25.190988Z","shell.execute_reply":"2024-12-16T16:50:30.175868Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"    text  lemma   upos xpos  head  deprel  start_char  end_char  y\n0     اس     یہ    DET  DEM     2     det           0         2  2\n1  سلسلے  سلسلہ   NOUN   NN     5    nmod           3         8  2\n2     کی     کا    ADP  PSP     2    case           9        11  2\n3   دیگر   دیگر    ADJ   JJ     5    amod          12        16  2\n4  اقساط  اقساط   NOUN   NN     7   nsubj          17        22  2\n5   یہاں   یہاں   PRON  PRP     7     obl          23        27  2\n6  پڑھیے    پڑھ   VERB   VM     0    root          28        33  2\n7      ۔      ۔  PUNCT  SYM     7   punct          33        34  0\n8     یہ     یہ   PRON  PRP     3   nsubj          36        38  1\n9   کیسے   کیسا   PRON   WQ     3  advmod          39        43  2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>deprel</th>\n      <th>start_char</th>\n      <th>end_char</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>اس</td>\n      <td>یہ</td>\n      <td>DET</td>\n      <td>DEM</td>\n      <td>2</td>\n      <td>det</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>سلسلے</td>\n      <td>سلسلہ</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>5</td>\n      <td>nmod</td>\n      <td>3</td>\n      <td>8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>کی</td>\n      <td>کا</td>\n      <td>ADP</td>\n      <td>PSP</td>\n      <td>2</td>\n      <td>case</td>\n      <td>9</td>\n      <td>11</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>دیگر</td>\n      <td>دیگر</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>5</td>\n      <td>amod</td>\n      <td>12</td>\n      <td>16</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>اقساط</td>\n      <td>اقساط</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>7</td>\n      <td>nsubj</td>\n      <td>17</td>\n      <td>22</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>یہاں</td>\n      <td>یہاں</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>7</td>\n      <td>obl</td>\n      <td>23</td>\n      <td>27</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>پڑھیے</td>\n      <td>پڑھ</td>\n      <td>VERB</td>\n      <td>VM</td>\n      <td>0</td>\n      <td>root</td>\n      <td>28</td>\n      <td>33</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>۔</td>\n      <td>۔</td>\n      <td>PUNCT</td>\n      <td>SYM</td>\n      <td>7</td>\n      <td>punct</td>\n      <td>33</td>\n      <td>34</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>یہ</td>\n      <td>یہ</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>3</td>\n      <td>nsubj</td>\n      <td>36</td>\n      <td>38</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>کیسے</td>\n      <td>کیسا</td>\n      <td>PRON</td>\n      <td>WQ</td>\n      <td>3</td>\n      <td>advmod</td>\n      <td>39</td>\n      <td>43</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:50:30.178070Z","iopub.execute_input":"2024-12-16T16:50:30.178482Z","iopub.status.idle":"2024-12-16T16:50:30.878888Z","shell.execute_reply.started":"2024-12-16T16:50:30.178441Z","shell.execute_reply":"2024-12-16T16:50:30.878209Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# One-hot encode 'upos', 'xpos', and 'deprel'\n\nencoder = OneHotEncoder(sparse_output=False)\nencoded_cats = encoder.fit_transform(data[['upos', 'xpos', 'deprel']])\n\n# Convert to DataFrame for easier merging\nencoded_cats_df = pd.DataFrame(encoded_cats, columns=encoder.get_feature_names_out())\n\n# Concatenate encoded features back to the dataset\ndata = pd.concat([data.reset_index(drop=True), encoded_cats_df], axis=1)\n\n# Drop the original categorical columns (optional)\ndata = data.drop(columns=['upos', 'xpos', 'deprel'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:50:30.879886Z","iopub.execute_input":"2024-12-16T16:50:30.880257Z","iopub.status.idle":"2024-12-16T16:50:31.552239Z","shell.execute_reply.started":"2024-12-16T16:50:30.880230Z","shell.execute_reply":"2024-12-16T16:50:31.551295Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Select the numerical features to normalize\nnumerical_features = ['start_char', 'end_char', 'head']\n\n# Option 2: Standard Scaling (zero mean and unit variance)\nstandard_scaler = StandardScaler()\ndata[numerical_features] = standard_scaler.fit_transform(data[numerical_features])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:50:31.553296Z","iopub.execute_input":"2024-12-16T16:50:31.553546Z","iopub.status.idle":"2024-12-16T16:50:31.573039Z","shell.execute_reply.started":"2024-12-16T16:50:31.553522Z","shell.execute_reply":"2024-12-16T16:50:31.572277Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Combine text and lemma columns into a single string representation (if needed)\ndata['text_lemma'] = data['text'] + \" \" + data['lemma']\n\n# Initialize TF-IDF Vectorizer\ntfidf_vectorizer = TfidfVectorizer(max_features=500)  # Adjust max_features as needed\n\n# Fit and transform the combined text and lemma\ntfidf_features = tfidf_vectorizer.fit_transform(data['text_lemma'])\n\n# Convert the sparse matrix to a DataFrame for better integration\ntfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n\n# Add the TF-IDF features back to the original DataFrame\ndata = pd.concat([data.reset_index(drop=True), tfidf_df], axis=1)\n\n# Drop the original text and lemma columns (optional)\ndata = data.drop(columns=['text', 'lemma', 'text_lemma'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:50:31.574041Z","iopub.execute_input":"2024-12-16T16:50:31.574360Z","iopub.status.idle":"2024-12-16T16:50:36.052779Z","shell.execute_reply.started":"2024-12-16T16:50:31.574334Z","shell.execute_reply":"2024-12-16T16:50:36.051706Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:50:36.054989Z","iopub.execute_input":"2024-12-16T16:50:36.055299Z","iopub.status.idle":"2024-12-16T16:50:36.156964Z","shell.execute_reply.started":"2024-12-16T16:50:36.055272Z","shell.execute_reply":"2024-12-16T16:50:36.156023Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"            head  start_char  end_char  y  upos_ADJ  upos_ADP  upos_ADV  \\\n0      -1.051740   -1.732661 -1.732666  2       0.0       0.0       0.0   \n1      -0.857181   -1.732652 -1.732647  2       0.0       0.0       0.0   \n2      -1.051740   -1.732634 -1.732638  2       0.0       1.0       0.0   \n3      -0.857181   -1.732625 -1.732623  2       1.0       0.0       0.0   \n4      -0.727474   -1.732609 -1.732604  2       0.0       0.0       0.0   \n...          ...         ...       ... ..       ...       ...       ...   \n254923  2.580032    1.737197  1.737196  2       0.0       0.0       0.0   \n254924  1.672089    1.737209  1.737214  2       0.0       0.0       0.0   \n254925  2.580032    1.737228  1.737236  2       0.0       0.0       0.0   \n254926  2.580032    1.737249  1.737245  2       0.0       0.0       0.0   \n254927  2.580032    1.737256  1.737248  2       0.0       0.0       0.0   \n\n        upos_AUX  upos_CCONJ  upos_DET  ...  ہوں   ہی  ہیں   ہے   یا  یعنی  \\\n0            0.0         0.0       1.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n1            0.0         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n2            0.0         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n3            0.0         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n4            0.0         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n...          ...         ...       ...  ...  ...  ...  ...  ...  ...   ...   \n254923       0.0         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n254924       0.0         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n254925       1.0         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n254926       1.0         0.0       0.0  ...  0.0  0.0  0.0  1.0  0.0   0.0   \n254927       0.0         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n\n        یقینا        یہ  یہاں  یہی  \n0         0.0  0.646811   0.0  0.0  \n1         0.0  0.000000   0.0  0.0  \n2         0.0  0.000000   0.0  0.0  \n3         0.0  0.000000   0.0  0.0  \n4         0.0  0.000000   0.0  0.0  \n...       ...       ...   ...  ...  \n254923    0.0  0.000000   0.0  0.0  \n254924    0.0  0.000000   0.0  0.0  \n254925    0.0  0.000000   0.0  0.0  \n254926    0.0  0.000000   0.0  0.0  \n254927    0.0  0.000000   0.0  0.0  \n\n[254928 rows x 579 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>head</th>\n      <th>start_char</th>\n      <th>end_char</th>\n      <th>y</th>\n      <th>upos_ADJ</th>\n      <th>upos_ADP</th>\n      <th>upos_ADV</th>\n      <th>upos_AUX</th>\n      <th>upos_CCONJ</th>\n      <th>upos_DET</th>\n      <th>...</th>\n      <th>ہوں</th>\n      <th>ہی</th>\n      <th>ہیں</th>\n      <th>ہے</th>\n      <th>یا</th>\n      <th>یعنی</th>\n      <th>یقینا</th>\n      <th>یہ</th>\n      <th>یہاں</th>\n      <th>یہی</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.051740</td>\n      <td>-1.732661</td>\n      <td>-1.732666</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.646811</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.857181</td>\n      <td>-1.732652</td>\n      <td>-1.732647</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.051740</td>\n      <td>-1.732634</td>\n      <td>-1.732638</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.857181</td>\n      <td>-1.732625</td>\n      <td>-1.732623</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.727474</td>\n      <td>-1.732609</td>\n      <td>-1.732604</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>254923</th>\n      <td>2.580032</td>\n      <td>1.737197</td>\n      <td>1.737196</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>254924</th>\n      <td>1.672089</td>\n      <td>1.737209</td>\n      <td>1.737214</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>254925</th>\n      <td>2.580032</td>\n      <td>1.737228</td>\n      <td>1.737236</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>254926</th>\n      <td>2.580032</td>\n      <td>1.737249</td>\n      <td>1.737245</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>254927</th>\n      <td>2.580032</td>\n      <td>1.737256</td>\n      <td>1.737248</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>254928 rows × 579 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Assuming 'y' is your target column\nclass_counts = data['y'].value_counts()\nprint(class_counts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:50:36.158517Z","iopub.execute_input":"2024-12-16T16:50:36.159258Z","iopub.status.idle":"2024-12-16T16:50:36.170459Z","shell.execute_reply.started":"2024-12-16T16:50:36.159190Z","shell.execute_reply":"2024-12-16T16:50:36.169464Z"}},"outputs":[{"name":"stdout","text":"y\n2    236746\n0      9091\n1      9091\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Define the feature matrix (drop 'y') and target\nX = data.drop(columns=['y'])\ny = data['y']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:50:36.171779Z","iopub.execute_input":"2024-12-16T16:50:36.172219Z","iopub.status.idle":"2024-12-16T16:50:36.527868Z","shell.execute_reply.started":"2024-12-16T16:50:36.172154Z","shell.execute_reply":"2024-12-16T16:50:36.527096Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Train-validation-test split\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.36, random_state=42, stratify=y)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.56, random_state=42, stratify=y_temp)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:50:36.528877Z","iopub.execute_input":"2024-12-16T16:50:36.529130Z","iopub.status.idle":"2024-12-16T16:50:38.128942Z","shell.execute_reply.started":"2024-12-16T16:50:36.529105Z","shell.execute_reply":"2024-12-16T16:50:38.128126Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, f1_score\nfrom imblearn.over_sampling import SMOTE\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow import keras\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:51:22.672166Z","iopub.execute_input":"2024-12-16T16:51:22.672854Z","iopub.status.idle":"2024-12-16T16:51:36.630605Z","shell.execute_reply.started":"2024-12-16T16:51:22.672820Z","shell.execute_reply":"2024-12-16T16:51:36.629678Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Handle class imbalance with SMOTE\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:52:11.503800Z","iopub.execute_input":"2024-12-16T16:52:11.504311Z","iopub.status.idle":"2024-12-16T16:52:20.882216Z","shell.execute_reply.started":"2024-12-16T16:52:11.504263Z","shell.execute_reply":"2024-12-16T16:52:20.881072Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Compute class weights for weighted loss\nclass_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\nclass_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:52:45.309334Z","iopub.execute_input":"2024-12-16T16:52:45.309688Z","iopub.status.idle":"2024-12-16T16:52:45.338504Z","shell.execute_reply.started":"2024-12-16T16:52:45.309659Z","shell.execute_reply":"2024-12-16T16:52:45.337581Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Define the CNN model\ndef create_cnn_model_multiclass(input_dim, num_classes):\n    model = keras.Sequential([\n        layers.InputLayer(input_shape=(input_dim,)),\n        layers.Reshape((input_dim, 1)),\n        layers.Conv1D(filters=64, kernel_size=3, activation='relu'),\n        layers.MaxPooling1D(pool_size=2),\n        layers.Conv1D(filters=32, kernel_size=3, activation='relu'),\n        layers.GlobalMaxPooling1D(),\n        layers.Dense(128, activation='relu'),\n        layers.Dropout(0.3),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:52:59.147911Z","iopub.execute_input":"2024-12-16T16:52:59.148294Z","iopub.status.idle":"2024-12-16T16:52:59.154659Z","shell.execute_reply.started":"2024-12-16T16:52:59.148264Z","shell.execute_reply":"2024-12-16T16:52:59.153666Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Create and train the model\nnum_classes = len(np.unique(y))\ncnn_model_multi = create_cnn_model_multiclass(X_train_resampled.shape[1], num_classes)\ncnn_model_multi.fit(\n    X_train_resampled, y_train_resampled,\n    epochs=10,\n    batch_size=32,\n    validation_data=(X_val, y_val),\n    class_weight=class_weights_dict\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T16:53:11.817164Z","iopub.execute_input":"2024-12-16T16:53:11.817632Z","iopub.status.idle":"2024-12-16T17:02:08.331357Z","shell.execute_reply.started":"2024-12-16T16:53:11.817599Z","shell.execute_reply":"2024-12-16T17:02:08.330425Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1734368000.414284     105 service.cc:145] XLA service 0x7c36a0006360 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1734368000.414360     105 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1734368000.414367     105 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   44/14205\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 4ms/step - accuracy: 0.3363 - loss: 5.9109  ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1734368004.352604     105 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m14205/14205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 4ms/step - accuracy: 0.6391 - loss: 2.2145 - val_accuracy: 0.3550 - val_loss: 2.6814\nEpoch 2/10\n\u001b[1m14205/14205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 4ms/step - accuracy: 0.7220 - loss: 1.6440 - val_accuracy: 0.3962 - val_loss: 2.5138\nEpoch 3/10\n\u001b[1m14205/14205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 4ms/step - accuracy: 0.7344 - loss: 1.5771 - val_accuracy: 0.3929 - val_loss: 2.4694\nEpoch 4/10\n\u001b[1m14205/14205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 4ms/step - accuracy: 0.7392 - loss: 1.5701 - val_accuracy: 0.3680 - val_loss: 2.4683\nEpoch 5/10\n\u001b[1m14205/14205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 4ms/step - accuracy: 0.7438 - loss: 1.5434 - val_accuracy: 0.4425 - val_loss: 2.2179\nEpoch 6/10\n\u001b[1m14205/14205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4ms/step - accuracy: 0.7476 - loss: 1.5403 - val_accuracy: 0.4238 - val_loss: 2.2319\nEpoch 7/10\n\u001b[1m14205/14205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4ms/step - accuracy: 0.7504 - loss: 1.5333 - val_accuracy: 0.3912 - val_loss: 2.3832\nEpoch 8/10\n\u001b[1m14205/14205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4ms/step - accuracy: 0.7502 - loss: 1.5345 - val_accuracy: 0.4396 - val_loss: 2.1815\nEpoch 9/10\n\u001b[1m14205/14205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4ms/step - accuracy: 0.7510 - loss: 1.5352 - val_accuracy: 0.4648 - val_loss: 2.2144\nEpoch 10/10\n\u001b[1m14205/14205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 4ms/step - accuracy: 0.7549 - loss: 1.5283 - val_accuracy: 0.4262 - val_loss: 2.1797\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7c3736cc4880>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# Evaluate on validation data\nval_loss, val_accuracy = cnn_model_multi.evaluate(X_val, y_val, verbose=0)\nprint(f'Validation Accuracy: {val_accuracy:.4f}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:07:40.883480Z","iopub.execute_input":"2024-12-16T17:07:40.883865Z","iopub.status.idle":"2024-12-16T17:07:43.050876Z","shell.execute_reply.started":"2024-12-16T17:07:40.883831Z","shell.execute_reply":"2024-12-16T17:07:43.049894Z"}},"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.4262\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Predict and evaluate on validation set\ny_val_pred = cnn_model_multi.predict(X_val).argmax(axis=1)\nprint(\"Classification Report (Validation):\\n\", classification_report(y_val, y_val_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:07:46.218462Z","iopub.execute_input":"2024-12-16T17:07:46.219430Z","iopub.status.idle":"2024-12-16T17:07:49.547561Z","shell.execute_reply.started":"2024-12-16T17:07:46.219393Z","shell.execute_reply":"2024-12-16T17:07:49.546503Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1262/1262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\nClassification Report (Validation):\n               precision    recall  f1-score   support\n\n           0       0.10      0.95      0.18      1440\n           1       0.10      0.87      0.18      1440\n           2       1.00      0.39      0.56     37500\n\n    accuracy                           0.43     40380\n   macro avg       0.40      0.74      0.31     40380\nweighted avg       0.94      0.43      0.53     40380\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Evaluate on test data\ntest_loss, test_accuracy = cnn_model_multi.evaluate(X_test, y_test, verbose=0)\nprint(f'Test Accuracy: {test_accuracy:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:07:51.858497Z","iopub.execute_input":"2024-12-16T17:07:51.859395Z","iopub.status.idle":"2024-12-16T17:07:55.107387Z","shell.execute_reply.started":"2024-12-16T17:07:51.859359Z","shell.execute_reply":"2024-12-16T17:07:55.106297Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.4239\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Predict and evaluate on test set\ny_test_pred = cnn_model_multi.predict(X_test).argmax(axis=1)\nprint(\"Classification Report (Test):\\n\", classification_report(y_test, y_test_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T17:07:57.352194Z","iopub.execute_input":"2024-12-16T17:07:57.352637Z","iopub.status.idle":"2024-12-16T17:08:01.163538Z","shell.execute_reply.started":"2024-12-16T17:07:57.352600Z","shell.execute_reply":"2024-12-16T17:08:01.162462Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\nClassification Report (Test):\n               precision    recall  f1-score   support\n\n           0       0.10      0.96      0.18      1833\n           1       0.10      0.87      0.18      1833\n           2       1.00      0.39      0.56     47729\n\n    accuracy                           0.42     51395\n   macro avg       0.40      0.74      0.31     51395\nweighted avg       0.94      0.42      0.53     51395\n\n","output_type":"stream"}],"execution_count":25}]}