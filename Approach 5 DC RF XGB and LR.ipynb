{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10113408,"sourceType":"datasetVersion","datasetId":6239597}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Approach 5: (without puntuation, with added features)\n\nDecision Tree, XGB , Random forest, logistic regression","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, accuracy_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T09:16:49.081986Z","iopub.execute_input":"2024-12-28T09:16:49.082321Z","iopub.status.idle":"2024-12-28T09:16:51.322532Z","shell.execute_reply.started":"2024-12-28T09:16:49.082276Z","shell.execute_reply":"2024-12-28T09:16:51.321574Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Read the CSV file\ndata = pd.read_csv('/kaggle/input/sbd-data/dataset.csv')\n\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T09:16:51.325360Z","iopub.execute_input":"2024-12-28T09:16:51.326351Z","iopub.status.idle":"2024-12-28T09:16:51.914245Z","shell.execute_reply.started":"2024-12-28T09:16:51.326307Z","shell.execute_reply":"2024-12-28T09:16:51.913313Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   id   text  lemma  upos xpos  head deprel  start_char  end_char\n0   1     اس     یہ   DET  DEM     2    det           0         2\n1   2  سلسلے  سلسلہ  NOUN   NN     5   nmod           3         8\n2   3     کی     کا   ADP  PSP     2   case           9        11\n3   4   دیگر   دیگر   ADJ   JJ     5   amod          12        16\n4   5  اقساط  اقساط  NOUN   NN     7  nsubj          17        22","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>deprel</th>\n      <th>start_char</th>\n      <th>end_char</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>اس</td>\n      <td>یہ</td>\n      <td>DET</td>\n      <td>DEM</td>\n      <td>2</td>\n      <td>det</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>سلسلے</td>\n      <td>سلسلہ</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>5</td>\n      <td>nmod</td>\n      <td>3</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>کی</td>\n      <td>کا</td>\n      <td>ADP</td>\n      <td>PSP</td>\n      <td>2</td>\n      <td>case</td>\n      <td>9</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>دیگر</td>\n      <td>دیگر</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>5</td>\n      <td>amod</td>\n      <td>12</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>اقساط</td>\n      <td>اقساط</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>7</td>\n      <td>nsubj</td>\n      <td>17</td>\n      <td>22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"data = data.drop(columns=['id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T09:16:51.915176Z","iopub.execute_input":"2024-12-28T09:16:51.915422Z","iopub.status.idle":"2024-12-28T09:16:51.938404Z","shell.execute_reply.started":"2024-12-28T09:16:51.915398Z","shell.execute_reply":"2024-12-28T09:16:51.937438Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import string\nimport re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T09:16:51.939526Z","iopub.execute_input":"2024-12-28T09:16:51.940030Z","iopub.status.idle":"2024-12-28T09:16:51.943980Z","shell.execute_reply.started":"2024-12-28T09:16:51.940002Z","shell.execute_reply":"2024-12-28T09:16:51.943095Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Initialize a new column 'y' with the default value 'S_M'\ndata['y'] = 'S_M'\n\n# Iterate through the rows to assign 'S_B'\nfor i in range(len(data) - 1):\n    # Check if the current word ends with a full stop\n    if data.loc[i, 'text'].endswith('۔'):\n        # Assign 'S_B' to the next word\n        if i + 1 < len(data):\n            data.loc[i + 1, 'y'] = 'S_B'  # Sentence Beginning\n\n# Convert 'y' column to categorical type (optional, for ML efficiency)\ndata['y'] = data['y'].astype('category')\n\n# Map categorical labels to numeric values\nlabel_mapping = {'S_B': 1, 'S_M': 0}\ndata['y'] = data['y'].map(label_mapping)\n\n# Verify the result\ndata.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T09:16:51.945192Z","iopub.execute_input":"2024-12-28T09:16:51.946042Z","iopub.status.idle":"2024-12-28T09:16:55.398899Z","shell.execute_reply.started":"2024-12-28T09:16:51.945992Z","shell.execute_reply":"2024-12-28T09:16:55.397961Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"    text  lemma   upos xpos  head  deprel  start_char  end_char  y\n0     اس     یہ    DET  DEM     2     det           0         2  0\n1  سلسلے  سلسلہ   NOUN   NN     5    nmod           3         8  0\n2     کی     کا    ADP  PSP     2    case           9        11  0\n3   دیگر   دیگر    ADJ   JJ     5    amod          12        16  0\n4  اقساط  اقساط   NOUN   NN     7   nsubj          17        22  0\n5   یہاں   یہاں   PRON  PRP     7     obl          23        27  0\n6  پڑھیے    پڑھ   VERB   VM     0    root          28        33  0\n7      ۔      ۔  PUNCT  SYM     7   punct          33        34  0\n8     یہ     یہ   PRON  PRP     3   nsubj          36        38  1\n9   کیسے   کیسا   PRON   WQ     3  advmod          39        43  0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>deprel</th>\n      <th>start_char</th>\n      <th>end_char</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>اس</td>\n      <td>یہ</td>\n      <td>DET</td>\n      <td>DEM</td>\n      <td>2</td>\n      <td>det</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>سلسلے</td>\n      <td>سلسلہ</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>5</td>\n      <td>nmod</td>\n      <td>3</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>کی</td>\n      <td>کا</td>\n      <td>ADP</td>\n      <td>PSP</td>\n      <td>2</td>\n      <td>case</td>\n      <td>9</td>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>دیگر</td>\n      <td>دیگر</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>5</td>\n      <td>amod</td>\n      <td>12</td>\n      <td>16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>اقساط</td>\n      <td>اقساط</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>7</td>\n      <td>nsubj</td>\n      <td>17</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>یہاں</td>\n      <td>یہاں</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>7</td>\n      <td>obl</td>\n      <td>23</td>\n      <td>27</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>پڑھیے</td>\n      <td>پڑھ</td>\n      <td>VERB</td>\n      <td>VM</td>\n      <td>0</td>\n      <td>root</td>\n      <td>28</td>\n      <td>33</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>۔</td>\n      <td>۔</td>\n      <td>PUNCT</td>\n      <td>SYM</td>\n      <td>7</td>\n      <td>punct</td>\n      <td>33</td>\n      <td>34</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>یہ</td>\n      <td>یہ</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>3</td>\n      <td>nsubj</td>\n      <td>36</td>\n      <td>38</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>کیسے</td>\n      <td>کیسا</td>\n      <td>PRON</td>\n      <td>WQ</td>\n      <td>3</td>\n      <td>advmod</td>\n      <td>39</td>\n      <td>43</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Drop rows where the 'text' column contains only punctuation\ndata = data[~data['text'].str.contains(r'^[^\\w\\s]+$', na=False)]\n\n# Verify the result\ndata.head(10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T09:16:55.400233Z","iopub.execute_input":"2024-12-28T09:16:55.400601Z","iopub.status.idle":"2024-12-28T09:16:55.542836Z","shell.execute_reply.started":"2024-12-28T09:16:55.400557Z","shell.execute_reply":"2024-12-28T09:16:55.542016Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     text  lemma  upos xpos  head  deprel  start_char  end_char  y\n0      اس     یہ   DET  DEM     2     det           0         2  0\n1   سلسلے  سلسلہ  NOUN   NN     5    nmod           3         8  0\n2      کی     کا   ADP  PSP     2    case           9        11  0\n3    دیگر   دیگر   ADJ   JJ     5    amod          12        16  0\n4   اقساط  اقساط  NOUN   NN     7   nsubj          17        22  0\n5    یہاں   یہاں  PRON  PRP     7     obl          23        27  0\n6   پڑھیے    پڑھ  VERB   VM     0    root          28        33  0\n8      یہ     یہ  PRON  PRP     3   nsubj          36        38  1\n9    کیسے   کیسا  PRON   WQ     3  advmod          39        43  0\n10   ممکن   ممکن   ADJ   JJ     0    root          44        48  0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>deprel</th>\n      <th>start_char</th>\n      <th>end_char</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>اس</td>\n      <td>یہ</td>\n      <td>DET</td>\n      <td>DEM</td>\n      <td>2</td>\n      <td>det</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>سلسلے</td>\n      <td>سلسلہ</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>5</td>\n      <td>nmod</td>\n      <td>3</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>کی</td>\n      <td>کا</td>\n      <td>ADP</td>\n      <td>PSP</td>\n      <td>2</td>\n      <td>case</td>\n      <td>9</td>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>دیگر</td>\n      <td>دیگر</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>5</td>\n      <td>amod</td>\n      <td>12</td>\n      <td>16</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>اقساط</td>\n      <td>اقساط</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>7</td>\n      <td>nsubj</td>\n      <td>17</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>یہاں</td>\n      <td>یہاں</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>7</td>\n      <td>obl</td>\n      <td>23</td>\n      <td>27</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>پڑھیے</td>\n      <td>پڑھ</td>\n      <td>VERB</td>\n      <td>VM</td>\n      <td>0</td>\n      <td>root</td>\n      <td>28</td>\n      <td>33</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>یہ</td>\n      <td>یہ</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>3</td>\n      <td>nsubj</td>\n      <td>36</td>\n      <td>38</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>کیسے</td>\n      <td>کیسا</td>\n      <td>PRON</td>\n      <td>WQ</td>\n      <td>3</td>\n      <td>advmod</td>\n      <td>39</td>\n      <td>43</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ممکن</td>\n      <td>ممکن</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>0</td>\n      <td>root</td>\n      <td>44</td>\n      <td>48</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Define the feature matrix (X) and target variable (y)\nX = data.drop(columns=['y'])\ny = data['y']\n\n# Split the data into training (64%), validation (16%), and test (20%) sets\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.36, random_state=42, stratify=y)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.56, random_state=42, stratify=y_temp)\n\n# Verify split\nprint(\"Training Set Size:\", len(X_train))\nprint(\"Validation Set Size:\", len(X_val))\nprint(\"Test Set Size:\", len(X_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T09:16:55.545030Z","iopub.execute_input":"2024-12-28T09:16:55.545671Z","iopub.status.idle":"2024-12-28T09:16:55.710018Z","shell.execute_reply.started":"2024-12-28T09:16:55.545642Z","shell.execute_reply":"2024-12-28T09:16:55.709086Z"}},"outputs":[{"name":"stdout","text":"Training Set Size: 154103\nValidation Set Size: 38140\nTest Set Size: 48544\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Define a function to add previous and next word features\ndef add_context_features(data):\n    # Previous word features\n    data['prev_text'] = data['text'].shift(1)\n    data['prev_lemma'] = data['lemma'].shift(1)\n    data['prev_upos'] = data['upos'].shift(1)\n    data['prev_xpos'] = data['xpos'].shift(1)\n    data['prev_head'] = data['head'].shift(1)\n    data['prev_deprel'] = data['deprel'].shift(1)\n    data['prev_start_char'] = data['start_char'].shift(1)\n    data['prev_end_char'] = data['end_char'].shift(1)\n    \n    # Next word features\n    data['next_text'] = data['text'].shift(-1)\n    data['next_lemma'] = data['lemma'].shift(-1)\n    data['next_upos'] = data['upos'].shift(-1)\n    data['next_xpos'] = data['xpos'].shift(-1)\n    data['next_head'] = data['head'].shift(-1)\n    data['next_deprel'] = data['deprel'].shift(-1)\n    data['next_start_char'] = data['start_char'].shift(-1)\n    data['next_end_char'] = data['end_char'].shift(-1)\n    \n    # Fill NaN values for edge cases\n    data.fillna(method='bfill', axis=0, inplace=True)  # Backfill for next words\n    data.fillna(method='ffill', axis=0, inplace=True)  # Forward fill for previous words\n    \n    return data\n\n# Apply the function separately to each dataset\nX_train = add_context_features(X_train)\nX_val = add_context_features(X_val)\nX_test = add_context_features(X_test)\n\n# Verify by checking the first few rows of one dataset\nX_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T09:16:55.711452Z","iopub.execute_input":"2024-12-28T09:16:55.711721Z","iopub.status.idle":"2024-12-28T09:16:56.524721Z","shell.execute_reply.started":"2024-12-28T09:16:55.711695Z","shell.execute_reply":"2024-12-28T09:16:56.523793Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/1772432770.py:24: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  data.fillna(method='bfill', axis=0, inplace=True)  # Backfill for next words\n/tmp/ipykernel_23/1772432770.py:25: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  data.fillna(method='ffill', axis=0, inplace=True)  # Forward fill for previous words\n/tmp/ipykernel_23/1772432770.py:24: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  data.fillna(method='bfill', axis=0, inplace=True)  # Backfill for next words\n/tmp/ipykernel_23/1772432770.py:25: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  data.fillna(method='ffill', axis=0, inplace=True)  # Forward fill for previous words\n/tmp/ipykernel_23/1772432770.py:24: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  data.fillna(method='bfill', axis=0, inplace=True)  # Backfill for next words\n/tmp/ipykernel_23/1772432770.py:25: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  data.fillna(method='ffill', axis=0, inplace=True)  # Forward fill for previous words\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"         text  lemma  upos  xpos  head deprel  start_char  end_char prev_text  \\\n15824      آپ     آپ  PRON   PRP    40  nsubj       71264     71266        آپ   \n154359     کی     کا   ADP   PSP     1   case      683744    683746        آپ   \n154738  ٹوئسٹ  ٹوئسٹ  NOUN    NN    33    obl      685463    685468        کی   \n153576   جدید   جدید   ADJ    JJ    16   amod      680277    680281     ٹوئسٹ   \n6068      تھی    تھا   AUX  VAUX    18    aux       27346     27349      جدید   \n\n       prev_lemma  ... prev_start_char prev_end_char  next_text next_lemma  \\\n15824          آپ  ...         71264.0       71266.0         کی         کا   \n154359         آپ  ...         71264.0       71266.0      ٹوئسٹ      ٹوئسٹ   \n154738         کا  ...        683744.0      683746.0       جدید       جدید   \n153576      ٹوئسٹ  ...        685463.0      685468.0        تھی        تھا   \n6068         جدید  ...        680277.0      680281.0        گھر        گھر   \n\n        next_upos  next_xpos next_head next_deprel next_start_char  \\\n15824         ADP        PSP       1.0        case        683744.0   \n154359       NOUN         NN      33.0         obl        685463.0   \n154738        ADJ         JJ      16.0        amod        680277.0   \n153576        AUX       VAUX      18.0         aux         27346.0   \n6068         NOUN         NN      28.0        nmod       1115470.0   \n\n       next_end_char  \n15824       683746.0  \n154359      685468.0  \n154738      680281.0  \n153576       27349.0  \n6068       1115473.0  \n\n[5 rows x 24 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>deprel</th>\n      <th>start_char</th>\n      <th>end_char</th>\n      <th>prev_text</th>\n      <th>prev_lemma</th>\n      <th>...</th>\n      <th>prev_start_char</th>\n      <th>prev_end_char</th>\n      <th>next_text</th>\n      <th>next_lemma</th>\n      <th>next_upos</th>\n      <th>next_xpos</th>\n      <th>next_head</th>\n      <th>next_deprel</th>\n      <th>next_start_char</th>\n      <th>next_end_char</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15824</th>\n      <td>آپ</td>\n      <td>آپ</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>40</td>\n      <td>nsubj</td>\n      <td>71264</td>\n      <td>71266</td>\n      <td>آپ</td>\n      <td>آپ</td>\n      <td>...</td>\n      <td>71264.0</td>\n      <td>71266.0</td>\n      <td>کی</td>\n      <td>کا</td>\n      <td>ADP</td>\n      <td>PSP</td>\n      <td>1.0</td>\n      <td>case</td>\n      <td>683744.0</td>\n      <td>683746.0</td>\n    </tr>\n    <tr>\n      <th>154359</th>\n      <td>کی</td>\n      <td>کا</td>\n      <td>ADP</td>\n      <td>PSP</td>\n      <td>1</td>\n      <td>case</td>\n      <td>683744</td>\n      <td>683746</td>\n      <td>آپ</td>\n      <td>آپ</td>\n      <td>...</td>\n      <td>71264.0</td>\n      <td>71266.0</td>\n      <td>ٹوئسٹ</td>\n      <td>ٹوئسٹ</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>33.0</td>\n      <td>obl</td>\n      <td>685463.0</td>\n      <td>685468.0</td>\n    </tr>\n    <tr>\n      <th>154738</th>\n      <td>ٹوئسٹ</td>\n      <td>ٹوئسٹ</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>33</td>\n      <td>obl</td>\n      <td>685463</td>\n      <td>685468</td>\n      <td>کی</td>\n      <td>کا</td>\n      <td>...</td>\n      <td>683744.0</td>\n      <td>683746.0</td>\n      <td>جدید</td>\n      <td>جدید</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>16.0</td>\n      <td>amod</td>\n      <td>680277.0</td>\n      <td>680281.0</td>\n    </tr>\n    <tr>\n      <th>153576</th>\n      <td>جدید</td>\n      <td>جدید</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>16</td>\n      <td>amod</td>\n      <td>680277</td>\n      <td>680281</td>\n      <td>ٹوئسٹ</td>\n      <td>ٹوئسٹ</td>\n      <td>...</td>\n      <td>685463.0</td>\n      <td>685468.0</td>\n      <td>تھی</td>\n      <td>تھا</td>\n      <td>AUX</td>\n      <td>VAUX</td>\n      <td>18.0</td>\n      <td>aux</td>\n      <td>27346.0</td>\n      <td>27349.0</td>\n    </tr>\n    <tr>\n      <th>6068</th>\n      <td>تھی</td>\n      <td>تھا</td>\n      <td>AUX</td>\n      <td>VAUX</td>\n      <td>18</td>\n      <td>aux</td>\n      <td>27346</td>\n      <td>27349</td>\n      <td>جدید</td>\n      <td>جدید</td>\n      <td>...</td>\n      <td>680277.0</td>\n      <td>680281.0</td>\n      <td>گھر</td>\n      <td>گھر</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>28.0</td>\n      <td>nmod</td>\n      <td>1115470.0</td>\n      <td>1115473.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Initialize OneHotEncoder with 'handle_unknown=\"ignore\"'\nencoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nmin_max_scaler = MinMaxScaler()\n\n# 1. One-Hot Encoding for 'upos', 'xpos', 'deprel' (including for next and previous words)\nencoded_cats_train = encoder.fit_transform(X_train[['prev_upos', 'prev_xpos', 'prev_deprel', \n                                                   'upos', 'xpos', 'deprel', \n                                                   'next_upos', 'next_xpos', 'next_deprel']])\n\nencoded_cats_val = encoder.transform(X_val[['prev_upos', 'prev_xpos', 'prev_deprel', \n                                            'upos', 'xpos', 'deprel', \n                                            'next_upos', 'next_xpos', 'next_deprel']])\n\nencoded_cats_test = encoder.transform(X_test[['prev_upos', 'prev_xpos', 'prev_deprel', \n                                              'upos', 'xpos', 'deprel', \n                                              'next_upos', 'next_xpos', 'next_deprel']])\n\n# Convert to DataFrame\nencoded_cats_train_df = pd.DataFrame(encoded_cats_train, columns=encoder.get_feature_names_out())\nencoded_cats_val_df = pd.DataFrame(encoded_cats_val, columns=encoder.get_feature_names_out())\nencoded_cats_test_df = pd.DataFrame(encoded_cats_test, columns=encoder.get_feature_names_out())\n\n# Concatenate the encoded features back to the original datasets\nX_train = pd.concat([X_train.reset_index(drop=True), encoded_cats_train_df], axis=1)\nX_val = pd.concat([X_val.reset_index(drop=True), encoded_cats_val_df], axis=1)\nX_test = pd.concat([X_test.reset_index(drop=True), encoded_cats_test_df], axis=1)\n\n# Drop original categorical columns\nX_train = X_train.drop(columns=['prev_upos', 'prev_xpos', 'prev_deprel', 'upos', 'xpos', 'deprel', \n                                'next_upos', 'next_xpos', 'next_deprel'])\nX_val = X_val.drop(columns=['prev_upos', 'prev_xpos', 'prev_deprel', 'upos', 'xpos', 'deprel', \n                            'next_upos', 'next_xpos', 'next_deprel'])\nX_test = X_test.drop(columns=['prev_upos', 'prev_xpos', 'prev_deprel', 'upos', 'xpos', 'deprel', \n                              'next_upos', 'next_xpos', 'next_deprel'])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T09:16:56.525917Z","iopub.execute_input":"2024-12-28T09:16:56.526262Z","iopub.status.idle":"2024-12-28T09:16:58.533779Z","shell.execute_reply.started":"2024-12-28T09:16:56.526236Z","shell.execute_reply":"2024-12-28T09:16:58.533054Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# 2. Min-Max Scaling for numerical features\nnumerical_features = ['start_char', 'end_char', 'head', \n                      'prev_start_char', 'prev_end_char', \n                      'next_start_char', 'next_end_char']\n\nX_train[numerical_features] = min_max_scaler.fit_transform(X_train[numerical_features])\nX_val[numerical_features] = min_max_scaler.transform(X_val[numerical_features])\nX_test[numerical_features] = min_max_scaler.transform(X_test[numerical_features])\n\n# 3. TF-IDF Vectorization for text and lemma features\nX_train['text_lemma_prev_next'] = (X_train['prev_text'] + \" \" + X_train['prev_lemma'] + \" \" +\n                                   X_train['text'] + \" \" + X_train['lemma'] + \" \" +\n                                   X_train['next_text'] + \" \" + X_train['next_lemma'])\n\nX_val['text_lemma_prev_next'] = (X_val['prev_text'] + \" \" + X_val['prev_lemma'] + \" \" +\n                                 X_val['text'] + \" \" + X_val['lemma'] + \" \" +\n                                 X_val['next_text'] + \" \" + X_val['next_lemma'])\n\nX_test['text_lemma_prev_next'] = (X_test['prev_text'] + \" \" + X_test['prev_lemma'] + \" \" +\n                                  X_test['text'] + \" \" + X_test['lemma'] + \" \" +\n                                  X_test['next_text'] + \" \" + X_test['next_lemma'])\n\n# Initialize TF-IDF Vectorizer\ntfidf_vectorizer = TfidfVectorizer(max_features=500)\n\n# Fit and transform on training set\ntfidf_train = tfidf_vectorizer.fit_transform(X_train['text_lemma_prev_next'])\ntfidf_val = tfidf_vectorizer.transform(X_val['text_lemma_prev_next'])\ntfidf_test = tfidf_vectorizer.transform(X_test['text_lemma_prev_next'])\n\n# Convert sparse matrices to DataFrames\ntfidf_train_df = pd.DataFrame(tfidf_train.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\ntfidf_val_df = pd.DataFrame(tfidf_val.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\ntfidf_test_df = pd.DataFrame(tfidf_test.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n\n# Concatenate TF-IDF features back to the datasets\nX_train = pd.concat([X_train.reset_index(drop=True), tfidf_train_df], axis=1)\nX_val = pd.concat([X_val.reset_index(drop=True), tfidf_val_df], axis=1)\nX_test = pd.concat([X_test.reset_index(drop=True), tfidf_test_df], axis=1)\n\n# Drop original text and lemma columns (optional)\nX_train = X_train.drop(columns=['text', 'lemma', 'text_lemma_prev_next', 'prev_text', 'prev_lemma', 'next_text', 'next_lemma'])\nX_val = X_val.drop(columns=['text', 'lemma', 'text_lemma_prev_next', 'prev_text', 'prev_lemma', 'next_text', 'next_lemma'])\nX_test = X_test.drop(columns=['text', 'lemma', 'text_lemma_prev_next', 'prev_text', 'prev_lemma', 'next_text', 'next_lemma'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T09:16:58.534973Z","iopub.execute_input":"2024-12-28T09:16:58.535348Z","iopub.status.idle":"2024-12-28T09:17:04.310432Z","shell.execute_reply.started":"2024-12-28T09:16:58.535313Z","shell.execute_reply":"2024-12-28T09:17:04.309797Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Initialize the Decision Tree Classifier\ndt_model = DecisionTreeClassifier(random_state=42, max_depth=10)\n\n# Train the model on the training set\ndt_model.fit(X_train, y_train)\n\n# Make predictions on validation and test sets\ny_val_pred = dt_model.predict(X_val)\ny_test_pred = dt_model.predict(X_test)\n\n# Evaluate the model\nprint(\"Decision Tree - Validation Set:\")\nprint(classification_report(y_val, y_val_pred))\n\nprint(\"Decision Tree - Test Set:\")\nprint(classification_report(y_test, y_test_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T09:17:04.311385Z","iopub.execute_input":"2024-12-28T09:17:04.311615Z","iopub.status.idle":"2024-12-28T09:17:13.205996Z","shell.execute_reply.started":"2024-12-28T09:17:04.311592Z","shell.execute_reply":"2024-12-28T09:17:13.205099Z"}},"outputs":[{"name":"stdout","text":"Decision Tree - Validation Set:\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99     36713\n           1       0.75      0.53      0.62      1427\n\n    accuracy                           0.98     38140\n   macro avg       0.87      0.76      0.80     38140\nweighted avg       0.97      0.98      0.97     38140\n\nDecision Tree - Test Set:\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99     46727\n           1       0.74      0.53      0.62      1817\n\n    accuracy                           0.98     48544\n   macro avg       0.86      0.76      0.80     48544\nweighted avg       0.97      0.98      0.97     48544\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# Initialize Random Forest\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Fit the model\nrf_model.fit(X_train, y_train)\n\n# Predict on validation and test sets\ny_val_pred_rf = rf_model.predict(X_val)\ny_test_pred_rf = rf_model.predict(X_test)\n\n# Evaluate Random Forest\nprint(\"Random Forest - Validation Set:\")\nprint(classification_report(y_val, y_val_pred_rf))\nprint(\"Random Forest - Test Set:\")\nprint(classification_report(y_test, y_test_pred_rf))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T09:17:13.207035Z","iopub.execute_input":"2024-12-28T09:17:13.207350Z","iopub.status.idle":"2024-12-28T09:18:51.646025Z","shell.execute_reply.started":"2024-12-28T09:17:13.207322Z","shell.execute_reply":"2024-12-28T09:18:51.645236Z"}},"outputs":[{"name":"stdout","text":"Random Forest - Validation Set:\n              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99     36713\n           1       0.83      0.38      0.52      1427\n\n    accuracy                           0.97     38140\n   macro avg       0.90      0.69      0.75     38140\nweighted avg       0.97      0.97      0.97     38140\n\nRandom Forest - Test Set:\n              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99     46727\n           1       0.83      0.39      0.53      1817\n\n    accuracy                           0.97     48544\n   macro avg       0.90      0.69      0.76     48544\nweighted avg       0.97      0.97      0.97     48544\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\n# Initialize XGBoost\nxgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n\n# Fit the model\nxgb_model.fit(X_train, y_train)\n\n# Predict on validation and test sets\ny_val_pred_xgb = xgb_model.predict(X_val)\ny_test_pred_xgb = xgb_model.predict(X_test)\n\n# Evaluate XGBoost\nprint(\"XGBoost - Validation Set:\")\nprint(classification_report(y_val, y_val_pred_xgb))\nprint(\"XGBoost - Test Set:\")\nprint(classification_report(y_test, y_test_pred_xgb))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T09:18:51.647024Z","iopub.execute_input":"2024-12-28T09:18:51.647291Z","iopub.status.idle":"2024-12-28T09:19:08.096332Z","shell.execute_reply.started":"2024-12-28T09:18:51.647265Z","shell.execute_reply":"2024-12-28T09:19:08.095472Z"}},"outputs":[{"name":"stdout","text":"XGBoost - Validation Set:\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99     36713\n           1       0.78      0.51      0.62      1427\n\n    accuracy                           0.98     38140\n   macro avg       0.88      0.75      0.80     38140\nweighted avg       0.97      0.98      0.97     38140\n\nXGBoost - Test Set:\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99     46727\n           1       0.77      0.52      0.62      1817\n\n    accuracy                           0.98     48544\n   macro avg       0.88      0.76      0.80     48544\nweighted avg       0.97      0.98      0.97     48544\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom imblearn.over_sampling import SMOTE\n\n# Apply SMOTE to the training data\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T09:31:57.482745Z","iopub.execute_input":"2024-12-28T09:31:57.483656Z","iopub.status.idle":"2024-12-28T09:32:03.850919Z","shell.execute_reply.started":"2024-12-28T09:31:57.483609Z","shell.execute_reply":"2024-12-28T09:32:03.849980Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Train the logistic regression model\nlogistic_model = LogisticRegression(random_state=42)\nlogistic_model.fit(X_train_resampled, y_train_resampled)\n\n# Make predictions and evaluate the model\ny_train_pred = logistic_model.predict(X_train_resampled)\ny_val_pred = logistic_model.predict(X_val)\ny_test_pred = logistic_model.predict(X_test)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T09:36:12.387731Z","iopub.execute_input":"2024-12-28T09:36:12.388451Z","iopub.status.idle":"2024-12-28T09:36:34.416313Z","shell.execute_reply.started":"2024-12-28T09:36:12.388400Z","shell.execute_reply":"2024-12-28T09:36:34.414936Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Evaluate the Logistic Regression model on all datasets\nprint(\"Logistic Regression - Training Set:\")\nprint(classification_report(y_train_resampled, y_train_pred))\n\nprint(\"Logistic Regression - Validation Set:\")\nprint(classification_report(y_val, y_val_pred))\n\nprint(\"Logistic Regression - Test Set:\")\nprint(classification_report(y_test, y_test_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T09:36:34.418293Z","iopub.execute_input":"2024-12-28T09:36:34.418738Z","iopub.status.idle":"2024-12-28T09:36:34.778488Z","shell.execute_reply.started":"2024-12-28T09:36:34.418686Z","shell.execute_reply":"2024-12-28T09:36:34.777653Z"}},"outputs":[{"name":"stdout","text":"Logistic Regression - Training Set:\n              precision    recall  f1-score   support\n\n           0       0.91      0.81      0.86    148335\n           1       0.83      0.92      0.88    148335\n\n    accuracy                           0.87    296670\n   macro avg       0.87      0.87      0.87    296670\nweighted avg       0.87      0.87      0.87    296670\n\nLogistic Regression - Validation Set:\n              precision    recall  f1-score   support\n\n           0       1.00      0.81      0.90     36713\n           1       0.16      0.91      0.27      1427\n\n    accuracy                           0.82     38140\n   macro avg       0.58      0.86      0.58     38140\nweighted avg       0.96      0.82      0.87     38140\n\nLogistic Regression - Test Set:\n              precision    recall  f1-score   support\n\n           0       0.99      0.81      0.90     46727\n           1       0.16      0.88      0.26      1817\n\n    accuracy                           0.82     48544\n   macro avg       0.57      0.85      0.58     48544\nweighted avg       0.96      0.82      0.87     48544\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}