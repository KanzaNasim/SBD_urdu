{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10113408,"sourceType":"datasetVersion","datasetId":6239597}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T18:40:00.521498Z","iopub.execute_input":"2024-12-11T18:40:00.521766Z","iopub.status.idle":"2024-12-11T18:40:01.652070Z","shell.execute_reply.started":"2024-12-11T18:40:00.521738Z","shell.execute_reply":"2024-12-11T18:40:01.651104Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Read the CSV file\ndf = pd.read_csv('/kaggle/input/sbd-data/dataset.csv')\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T19:02:21.377408Z","iopub.execute_input":"2024-12-11T19:02:21.377745Z","iopub.status.idle":"2024-12-11T19:02:21.695055Z","shell.execute_reply.started":"2024-12-11T19:02:21.377716Z","shell.execute_reply":"2024-12-11T19:02:21.694164Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"   id   text  lemma  upos xpos  head deprel  start_char  end_char\n0   1     اس     یہ   DET  DEM     2    det           0         2\n1   2  سلسلے  سلسلہ  NOUN   NN     5   nmod           3         8\n2   3     کی     کا   ADP  PSP     2   case           9        11\n3   4   دیگر   دیگر   ADJ   JJ     5   amod          12        16\n4   5  اقساط  اقساط  NOUN   NN     7  nsubj          17        22","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>deprel</th>\n      <th>start_char</th>\n      <th>end_char</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>اس</td>\n      <td>یہ</td>\n      <td>DET</td>\n      <td>DEM</td>\n      <td>2</td>\n      <td>det</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>سلسلے</td>\n      <td>سلسلہ</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>5</td>\n      <td>nmod</td>\n      <td>3</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>کی</td>\n      <td>کا</td>\n      <td>ADP</td>\n      <td>PSP</td>\n      <td>2</td>\n      <td>case</td>\n      <td>9</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>دیگر</td>\n      <td>دیگر</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>5</td>\n      <td>amod</td>\n      <td>12</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>اقساط</td>\n      <td>اقساط</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>7</td>\n      <td>nsubj</td>\n      <td>17</td>\n      <td>22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"data = df.drop(columns=['id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T19:02:23.832286Z","iopub.execute_input":"2024-12-11T19:02:23.832640Z","iopub.status.idle":"2024-12-11T19:02:23.844829Z","shell.execute_reply.started":"2024-12-11T19:02:23.832607Z","shell.execute_reply":"2024-12-11T19:02:23.844054Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"import numpy as np\n\n# Create a new column 'y' with default value 'S_M'\ndata['y'] = 'S_M'\n\n# Iterate through the rows to assign 'S_E' and 'S_B'\nfor i in range(len(data) - 1):\n    # Check if the current word ends with a full stop\n    if data.loc[i, 'text'].endswith('۔'):\n        data.loc[i, 'y'] = 'S_E'  # Sentence End\n        # Assign 'S_B' to the next word\n        if i + 1 < len(data):\n            data.loc[i + 1, 'y'] = 'S_B'  # Sentence Beginning\n\n# Convert 'y' column to categorical type (optional, for ML efficiency)\ndata['y'] = data['y'].astype('category')\n\n# Display the first few rows to verify\ndata.head(10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T19:02:25.690500Z","iopub.execute_input":"2024-12-11T19:02:25.690845Z","iopub.status.idle":"2024-12-11T19:02:30.509903Z","shell.execute_reply.started":"2024-12-11T19:02:25.690815Z","shell.execute_reply":"2024-12-11T19:02:30.508960Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"    text  lemma   upos xpos  head  deprel  start_char  end_char    y\n0     اس     یہ    DET  DEM     2     det           0         2  S_M\n1  سلسلے  سلسلہ   NOUN   NN     5    nmod           3         8  S_M\n2     کی     کا    ADP  PSP     2    case           9        11  S_M\n3   دیگر   دیگر    ADJ   JJ     5    amod          12        16  S_M\n4  اقساط  اقساط   NOUN   NN     7   nsubj          17        22  S_M\n5   یہاں   یہاں   PRON  PRP     7     obl          23        27  S_M\n6  پڑھیے    پڑھ   VERB   VM     0    root          28        33  S_M\n7      ۔      ۔  PUNCT  SYM     7   punct          33        34  S_E\n8     یہ     یہ   PRON  PRP     3   nsubj          36        38  S_B\n9   کیسے   کیسا   PRON   WQ     3  advmod          39        43  S_M","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>deprel</th>\n      <th>start_char</th>\n      <th>end_char</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>اس</td>\n      <td>یہ</td>\n      <td>DET</td>\n      <td>DEM</td>\n      <td>2</td>\n      <td>det</td>\n      <td>0</td>\n      <td>2</td>\n      <td>S_M</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>سلسلے</td>\n      <td>سلسلہ</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>5</td>\n      <td>nmod</td>\n      <td>3</td>\n      <td>8</td>\n      <td>S_M</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>کی</td>\n      <td>کا</td>\n      <td>ADP</td>\n      <td>PSP</td>\n      <td>2</td>\n      <td>case</td>\n      <td>9</td>\n      <td>11</td>\n      <td>S_M</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>دیگر</td>\n      <td>دیگر</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>5</td>\n      <td>amod</td>\n      <td>12</td>\n      <td>16</td>\n      <td>S_M</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>اقساط</td>\n      <td>اقساط</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>7</td>\n      <td>nsubj</td>\n      <td>17</td>\n      <td>22</td>\n      <td>S_M</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>یہاں</td>\n      <td>یہاں</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>7</td>\n      <td>obl</td>\n      <td>23</td>\n      <td>27</td>\n      <td>S_M</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>پڑھیے</td>\n      <td>پڑھ</td>\n      <td>VERB</td>\n      <td>VM</td>\n      <td>0</td>\n      <td>root</td>\n      <td>28</td>\n      <td>33</td>\n      <td>S_M</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>۔</td>\n      <td>۔</td>\n      <td>PUNCT</td>\n      <td>SYM</td>\n      <td>7</td>\n      <td>punct</td>\n      <td>33</td>\n      <td>34</td>\n      <td>S_E</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>یہ</td>\n      <td>یہ</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>3</td>\n      <td>nsubj</td>\n      <td>36</td>\n      <td>38</td>\n      <td>S_B</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>کیسے</td>\n      <td>کیسا</td>\n      <td>PRON</td>\n      <td>WQ</td>\n      <td>3</td>\n      <td>advmod</td>\n      <td>39</td>\n      <td>43</td>\n      <td>S_M</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"import numpy as np\n\n# Create a new column 'y' with default value 'S_M'\ndata['y'] = 'S_M'\n\n# Iterate through the rows to assign 'S_E' and 'S_B'\nfor i in range(len(data) - 1):\n    # Check if the current word ends with a full stop\n    if data.loc[i, 'text'].endswith('۔'):\n        data.loc[i, 'y'] = 'S_E'  # Sentence End\n        # Assign 'S_B' to the next word\n        if i + 1 < len(data):\n            data.loc[i + 1, 'y'] = 'S_B'  # Sentence Beginning\n\n# Map categorical labels to numeric values\nlabel_mapping = {'S_E': 0, 'S_B': 1, 'S_M': 2}\ndata['y'] = data['y'].map(label_mapping)\n\n# Verify the result\ndata.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T19:02:30.511544Z","iopub.execute_input":"2024-12-11T19:02:30.511830Z","iopub.status.idle":"2024-12-11T19:02:35.304527Z","shell.execute_reply.started":"2024-12-11T19:02:30.511802Z","shell.execute_reply":"2024-12-11T19:02:35.303550Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"    text  lemma   upos xpos  head  deprel  start_char  end_char  y\n0     اس     یہ    DET  DEM     2     det           0         2  2\n1  سلسلے  سلسلہ   NOUN   NN     5    nmod           3         8  2\n2     کی     کا    ADP  PSP     2    case           9        11  2\n3   دیگر   دیگر    ADJ   JJ     5    amod          12        16  2\n4  اقساط  اقساط   NOUN   NN     7   nsubj          17        22  2\n5   یہاں   یہاں   PRON  PRP     7     obl          23        27  2\n6  پڑھیے    پڑھ   VERB   VM     0    root          28        33  2\n7      ۔      ۔  PUNCT  SYM     7   punct          33        34  0\n8     یہ     یہ   PRON  PRP     3   nsubj          36        38  1\n9   کیسے   کیسا   PRON   WQ     3  advmod          39        43  2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>upos</th>\n      <th>xpos</th>\n      <th>head</th>\n      <th>deprel</th>\n      <th>start_char</th>\n      <th>end_char</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>اس</td>\n      <td>یہ</td>\n      <td>DET</td>\n      <td>DEM</td>\n      <td>2</td>\n      <td>det</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>سلسلے</td>\n      <td>سلسلہ</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>5</td>\n      <td>nmod</td>\n      <td>3</td>\n      <td>8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>کی</td>\n      <td>کا</td>\n      <td>ADP</td>\n      <td>PSP</td>\n      <td>2</td>\n      <td>case</td>\n      <td>9</td>\n      <td>11</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>دیگر</td>\n      <td>دیگر</td>\n      <td>ADJ</td>\n      <td>JJ</td>\n      <td>5</td>\n      <td>amod</td>\n      <td>12</td>\n      <td>16</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>اقساط</td>\n      <td>اقساط</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>7</td>\n      <td>nsubj</td>\n      <td>17</td>\n      <td>22</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>یہاں</td>\n      <td>یہاں</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>7</td>\n      <td>obl</td>\n      <td>23</td>\n      <td>27</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>پڑھیے</td>\n      <td>پڑھ</td>\n      <td>VERB</td>\n      <td>VM</td>\n      <td>0</td>\n      <td>root</td>\n      <td>28</td>\n      <td>33</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>۔</td>\n      <td>۔</td>\n      <td>PUNCT</td>\n      <td>SYM</td>\n      <td>7</td>\n      <td>punct</td>\n      <td>33</td>\n      <td>34</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>یہ</td>\n      <td>یہ</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>3</td>\n      <td>nsubj</td>\n      <td>36</td>\n      <td>38</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>کیسے</td>\n      <td>کیسا</td>\n      <td>PRON</td>\n      <td>WQ</td>\n      <td>3</td>\n      <td>advmod</td>\n      <td>39</td>\n      <td>43</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T19:02:35.306434Z","iopub.execute_input":"2024-12-11T19:02:35.307077Z","iopub.status.idle":"2024-12-11T19:02:35.310985Z","shell.execute_reply.started":"2024-12-11T19:02:35.307035Z","shell.execute_reply":"2024-12-11T19:02:35.310184Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"# One-hot encode 'upos', 'xpos', and 'deprel'\n\nencoder = OneHotEncoder(sparse_output=False)\nencoded_cats = encoder.fit_transform(data[['upos', 'xpos', 'deprel']])\n\n# Convert to DataFrame for easier merging\nencoded_cats_df = pd.DataFrame(encoded_cats, columns=encoder.get_feature_names_out())\n\n# Concatenate encoded features back to the dataset\ndata = pd.concat([data.reset_index(drop=True), encoded_cats_df], axis=1)\n\n# Drop the original categorical columns (optional)\ndata = data.drop(columns=['upos', 'xpos', 'deprel'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T19:02:35.311991Z","iopub.execute_input":"2024-12-11T19:02:35.312347Z","iopub.status.idle":"2024-12-11T19:02:35.929375Z","shell.execute_reply.started":"2024-12-11T19:02:35.312308Z","shell.execute_reply":"2024-12-11T19:02:35.928651Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# Select the numerical features to normalize\nnumerical_features = ['start_char', 'end_char', 'head']\n\n# Option 2: Standard Scaling (zero mean and unit variance)\nstandard_scaler = StandardScaler()\ndata[numerical_features] = standard_scaler.fit_transform(data[numerical_features])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T19:02:37.936515Z","iopub.execute_input":"2024-12-11T19:02:37.936856Z","iopub.status.idle":"2024-12-11T19:02:37.954184Z","shell.execute_reply.started":"2024-12-11T19:02:37.936823Z","shell.execute_reply":"2024-12-11T19:02:37.953444Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Combine text and lemma columns into a single string representation (if needed)\ndata['text_lemma'] = data['text'] + \" \" + data['lemma']\n\n# Initialize TF-IDF Vectorizer\ntfidf_vectorizer = TfidfVectorizer(max_features=500)  # Adjust max_features as needed\n\n# Fit and transform the combined text and lemma\ntfidf_features = tfidf_vectorizer.fit_transform(data['text_lemma'])\n\n# Convert the sparse matrix to a DataFrame for better integration\ntfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n\n# Add the TF-IDF features back to the original DataFrame\ndata = pd.concat([data.reset_index(drop=True), tfidf_df], axis=1)\n\n# Drop the original text and lemma columns (optional)\ndata = data.drop(columns=['text', 'lemma', 'text_lemma'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T19:02:39.814928Z","iopub.execute_input":"2024-12-11T19:02:39.815290Z","iopub.status.idle":"2024-12-11T19:02:43.974300Z","shell.execute_reply.started":"2024-12-11T19:02:39.815257Z","shell.execute_reply":"2024-12-11T19:02:43.973580Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T19:02:43.975639Z","iopub.execute_input":"2024-12-11T19:02:43.975887Z","iopub.status.idle":"2024-12-11T19:02:44.067752Z","shell.execute_reply.started":"2024-12-11T19:02:43.975861Z","shell.execute_reply":"2024-12-11T19:02:44.066969Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"            head  start_char  end_char  y  upos_ADJ  upos_ADP  upos_ADV  \\\n0      -1.051740   -1.732661 -1.732666  2       0.0       0.0       0.0   \n1      -0.857181   -1.732652 -1.732647  2       0.0       0.0       0.0   \n2      -1.051740   -1.732634 -1.732638  2       0.0       1.0       0.0   \n3      -0.857181   -1.732625 -1.732623  2       1.0       0.0       0.0   \n4      -0.727474   -1.732609 -1.732604  2       0.0       0.0       0.0   \n...          ...         ...       ... ..       ...       ...       ...   \n254923  2.580032    1.737197  1.737196  2       0.0       0.0       0.0   \n254924  1.672089    1.737209  1.737214  2       0.0       0.0       0.0   \n254925  2.580032    1.737228  1.737236  2       0.0       0.0       0.0   \n254926  2.580032    1.737249  1.737245  2       0.0       0.0       0.0   \n254927  2.580032    1.737256  1.737248  2       0.0       0.0       0.0   \n\n        upos_AUX  upos_CCONJ  upos_DET  ...  ہوں   ہی  ہیں   ہے   یا  یعنی  \\\n0            0.0         0.0       1.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n1            0.0         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n2            0.0         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n3            0.0         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n4            0.0         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n...          ...         ...       ...  ...  ...  ...  ...  ...  ...   ...   \n254923       0.0         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n254924       0.0         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n254925       1.0         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n254926       1.0         0.0       0.0  ...  0.0  0.0  0.0  1.0  0.0   0.0   \n254927       0.0         0.0       0.0  ...  0.0  0.0  0.0  0.0  0.0   0.0   \n\n        یقینا        یہ  یہاں  یہی  \n0         0.0  0.646811   0.0  0.0  \n1         0.0  0.000000   0.0  0.0  \n2         0.0  0.000000   0.0  0.0  \n3         0.0  0.000000   0.0  0.0  \n4         0.0  0.000000   0.0  0.0  \n...       ...       ...   ...  ...  \n254923    0.0  0.000000   0.0  0.0  \n254924    0.0  0.000000   0.0  0.0  \n254925    0.0  0.000000   0.0  0.0  \n254926    0.0  0.000000   0.0  0.0  \n254927    0.0  0.000000   0.0  0.0  \n\n[254928 rows x 579 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>head</th>\n      <th>start_char</th>\n      <th>end_char</th>\n      <th>y</th>\n      <th>upos_ADJ</th>\n      <th>upos_ADP</th>\n      <th>upos_ADV</th>\n      <th>upos_AUX</th>\n      <th>upos_CCONJ</th>\n      <th>upos_DET</th>\n      <th>...</th>\n      <th>ہوں</th>\n      <th>ہی</th>\n      <th>ہیں</th>\n      <th>ہے</th>\n      <th>یا</th>\n      <th>یعنی</th>\n      <th>یقینا</th>\n      <th>یہ</th>\n      <th>یہاں</th>\n      <th>یہی</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.051740</td>\n      <td>-1.732661</td>\n      <td>-1.732666</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.646811</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.857181</td>\n      <td>-1.732652</td>\n      <td>-1.732647</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.051740</td>\n      <td>-1.732634</td>\n      <td>-1.732638</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.857181</td>\n      <td>-1.732625</td>\n      <td>-1.732623</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.727474</td>\n      <td>-1.732609</td>\n      <td>-1.732604</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>254923</th>\n      <td>2.580032</td>\n      <td>1.737197</td>\n      <td>1.737196</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>254924</th>\n      <td>1.672089</td>\n      <td>1.737209</td>\n      <td>1.737214</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>254925</th>\n      <td>2.580032</td>\n      <td>1.737228</td>\n      <td>1.737236</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>254926</th>\n      <td>2.580032</td>\n      <td>1.737249</td>\n      <td>1.737245</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>254927</th>\n      <td>2.580032</td>\n      <td>1.737256</td>\n      <td>1.737248</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>254928 rows × 579 columns</p>\n</div>"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"# Define the feature matrix (drop 'y') and target\nX = data.drop(columns=['y'])\ny = data['y']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T19:02:50.189817Z","iopub.execute_input":"2024-12-11T19:02:50.190184Z","iopub.status.idle":"2024-12-11T19:02:50.534495Z","shell.execute_reply.started":"2024-12-11T19:02:50.190123Z","shell.execute_reply":"2024-12-11T19:02:50.533737Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# Split into training (64%), validation (16%), and test (20%) sets\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.36, random_state=42, stratify=y)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.56, random_state=42, stratify=y_temp)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T19:02:52.377104Z","iopub.execute_input":"2024-12-11T19:02:52.377496Z","iopub.status.idle":"2024-12-11T19:02:53.966201Z","shell.execute_reply.started":"2024-12-11T19:02:52.377463Z","shell.execute_reply":"2024-12-11T19:02:53.965442Z"}},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":"### XGBoost  ","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Define the XGBoost model\nxgb_model = xgb.XGBClassifier(\n    objective='multi:softmax',  # Since we have multiple classes\n    num_class=3,  # Number of classes: S_E, S_B, and S_M\n    random_state=42\n)\n\n# Train the model\nxgb_model.fit(X_train, y_train)\n\n# Make predictions on the validation set\ny_val_pred = xgb_model.predict(X_val)\n\n# Evaluate the model\nval_accuracy = accuracy_score(y_val, y_val_pred)\nprint(f'Validation Accuracy: {val_accuracy:.4f}')\nprint(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n\n# Make predictions on the test set (optional)\ny_test_pred = xgb_model.predict(X_test)\n\n# Evaluate the model on the test set\ntest_accuracy = accuracy_score(y_test, y_test_pred)\nprint(f'Test Accuracy: {test_accuracy:.4f}')\nprint(\"Test Classification Report:\\n\", classification_report(y_test, y_test_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T19:05:27.433852Z","iopub.execute_input":"2024-12-11T19:05:27.434474Z","iopub.status.idle":"2024-12-11T19:05:50.648272Z","shell.execute_reply.started":"2024-12-11T19:05:27.434437Z","shell.execute_reply":"2024-12-11T19:05:50.647348Z"}},"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.9624\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.70      0.92      0.79      1440\n           1       0.82      0.55      0.66      1440\n           2       0.98      0.98      0.98     37500\n\n    accuracy                           0.96     40380\n   macro avg       0.83      0.82      0.81     40380\nweighted avg       0.96      0.96      0.96     40380\n\nTest Accuracy: 0.9617\nTest Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.69      0.92      0.79      1833\n           1       0.79      0.55      0.65      1833\n           2       0.98      0.98      0.98     47729\n\n    accuracy                           0.96     51395\n   macro avg       0.82      0.82      0.81     51395\nweighted avg       0.96      0.96      0.96     51395\n\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"### DNN","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Define a simple DNN model\ndef create_dnn_model(input_dim, num_classes):\n    model = keras.Sequential([\n        layers.InputLayer(input_shape=(input_dim,)),  # Corrected input layer definition\n        layers.Dense(128, activation='relu'),  # Hidden layer with ReLU activation\n        layers.Dropout(0.2),  # Dropout for regularization\n        layers.Dense(64, activation='relu'),  # Another hidden layer\n        layers.Dropout(0.2),  # Dropout for regularization\n        layers.Dense(num_classes, activation='softmax')  # Output layer with softmax for multi-class classification\n    ])\n    \n    model.compile(optimizer='adam', \n                  loss='sparse_categorical_crossentropy',  # Use sparse categorical crossentropy for integer labels\n                  metrics=['accuracy'])\n    \n    return model\n\n# Create the DNN model\ninput_dim = X_train.shape[1]  # Number of features\nnum_classes = len(y.unique())  # Number of output classes (S_E, S_B, S_M)\n\ndnn_model = create_dnn_model(input_dim, num_classes)\n\n# Train the DNN model\ndnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n\n# Evaluate the model on the validation set\nval_loss, val_accuracy = dnn_model.evaluate(X_val, y_val, verbose=0)\nprint(f'Validation Accuracy: {val_accuracy:.4f}')\n\n# Make predictions on the validation set\ny_val_pred = dnn_model.predict(X_val)\ny_val_pred = y_val_pred.argmax(axis=1)  # Get the predicted class labels\n\n# Evaluate the model\nprint(\"Classification Report (Validation):\\n\", classification_report(y_val, y_val_pred))\n\n# Make predictions on the test set (optional)\ny_test_pred = dnn_model.predict(X_test)\ny_test_pred = y_test_pred.argmax(axis=1)\n\n# Evaluate the model on the test set\ntest_loss, test_accuracy = dnn_model.evaluate(X_test, y_test, verbose=0)\nprint(f'Test Accuracy: {test_accuracy:.4f}')\nprint(\"Classification Report (Test):\\n\", classification_report(y_test, y_test_pred))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T19:12:14.252739Z","iopub.execute_input":"2024-12-11T19:12:14.253130Z","iopub.status.idle":"2024-12-11T19:13:56.291260Z","shell.execute_reply.started":"2024-12-11T19:12:14.253085Z","shell.execute_reply":"2024-12-11T19:13:56.290287Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1733944337.506510     137 service.cc:145] XLA service 0x7bfa84008360 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1733944337.506557     137 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1733944337.506561     137 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 114/5099\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.4810","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1733944341.016759     137 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m5099/5099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.1532 - val_accuracy: 0.9519 - val_loss: 0.1114\nEpoch 2/10\n\u001b[1m5099/5099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9540 - loss: 0.1064 - val_accuracy: 0.9570 - val_loss: 0.1035\nEpoch 3/10\n\u001b[1m5099/5099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9555 - loss: 0.1031 - val_accuracy: 0.9576 - val_loss: 0.1018\nEpoch 4/10\n\u001b[1m5099/5099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9569 - loss: 0.1006 - val_accuracy: 0.9588 - val_loss: 0.1008\nEpoch 5/10\n\u001b[1m5099/5099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9577 - loss: 0.0985 - val_accuracy: 0.9591 - val_loss: 0.0996\nEpoch 6/10\n\u001b[1m5099/5099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9589 - loss: 0.0949 - val_accuracy: 0.9582 - val_loss: 0.1004\nEpoch 7/10\n\u001b[1m5099/5099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9582 - loss: 0.0965 - val_accuracy: 0.9599 - val_loss: 0.0974\nEpoch 8/10\n\u001b[1m5099/5099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9587 - loss: 0.0947 - val_accuracy: 0.9597 - val_loss: 0.0979\nEpoch 9/10\n\u001b[1m5099/5099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9594 - loss: 0.0944 - val_accuracy: 0.9571 - val_loss: 0.0998\nEpoch 10/10\n\u001b[1m5099/5099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9587 - loss: 0.0940 - val_accuracy: 0.9588 - val_loss: 0.0986\nValidation Accuracy: 0.9588\n\u001b[1m1262/1262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\nClassification Report (Validation):\n               precision    recall  f1-score   support\n\n           0       0.67      0.97      0.79      1440\n           1       0.69      0.63      0.66      1440\n           2       0.98      0.97      0.98     37500\n\n    accuracy                           0.96     40380\n   macro avg       0.78      0.86      0.81     40380\nweighted avg       0.96      0.96      0.96     40380\n\n\u001b[1m1607/1607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\nTest Accuracy: 0.9580\nClassification Report (Test):\n               precision    recall  f1-score   support\n\n           0       0.67      0.96      0.79      1833\n           1       0.68      0.63      0.65      1833\n           2       0.98      0.97      0.98     47729\n\n    accuracy                           0.96     51395\n   macro avg       0.78      0.85      0.81     51395\nweighted avg       0.96      0.96      0.96     51395\n\n","output_type":"stream"}],"execution_count":54},{"cell_type":"markdown","source":"### could run logistic and svm using smote for imbalance ","metadata":{}}]}