{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Methods -1 (with 500,1000,2000 max features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>اس</td>\n",
       "      <td>یہ</td>\n",
       "      <td>DET</td>\n",
       "      <td>DEM</td>\n",
       "      <td>2</td>\n",
       "      <td>det</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>سلسلے</td>\n",
       "      <td>سلسلہ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>5</td>\n",
       "      <td>nmod</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>کی</td>\n",
       "      <td>کا</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PSP</td>\n",
       "      <td>2</td>\n",
       "      <td>case</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>دیگر</td>\n",
       "      <td>دیگر</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>5</td>\n",
       "      <td>amod</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>اقساط</td>\n",
       "      <td>اقساط</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>7</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   text  lemma  upos xpos  head deprel  start_char  end_char\n",
       "0   1     اس     یہ   DET  DEM     2    det           0         2\n",
       "1   2  سلسلے  سلسلہ  NOUN   NN     5   nmod           3         8\n",
       "2   3     کی     کا   ADP  PSP     2   case           9        11\n",
       "3   4   دیگر   دیگر   ADJ   JJ     5   amod          12        16\n",
       "4   5  اقساط  اقساط  NOUN   NN     7  nsubj          17        22"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>اس</td>\n",
       "      <td>یہ</td>\n",
       "      <td>DET</td>\n",
       "      <td>DEM</td>\n",
       "      <td>2</td>\n",
       "      <td>det</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>سلسلے</td>\n",
       "      <td>سلسلہ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>5</td>\n",
       "      <td>nmod</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کی</td>\n",
       "      <td>کا</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PSP</td>\n",
       "      <td>2</td>\n",
       "      <td>case</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>دیگر</td>\n",
       "      <td>دیگر</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>5</td>\n",
       "      <td>amod</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اقساط</td>\n",
       "      <td>اقساط</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>7</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>یہاں</td>\n",
       "      <td>یہاں</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>7</td>\n",
       "      <td>obl</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>پڑھیے</td>\n",
       "      <td>پڑھ</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VM</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>۔</td>\n",
       "      <td>۔</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>SYM</td>\n",
       "      <td>7</td>\n",
       "      <td>punct</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>یہ</td>\n",
       "      <td>یہ</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>3</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>کیسے</td>\n",
       "      <td>کیسا</td>\n",
       "      <td>PRON</td>\n",
       "      <td>WQ</td>\n",
       "      <td>3</td>\n",
       "      <td>advmod</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text  lemma   upos xpos  head  deprel  start_char  end_char  y\n",
       "0     اس     یہ    DET  DEM     2     det           0         2  0\n",
       "1  سلسلے  سلسلہ   NOUN   NN     5    nmod           3         8  0\n",
       "2     کی     کا    ADP  PSP     2    case           9        11  0\n",
       "3   دیگر   دیگر    ADJ   JJ     5    amod          12        16  0\n",
       "4  اقساط  اقساط   NOUN   NN     7   nsubj          17        22  0\n",
       "5   یہاں   یہاں   PRON  PRP     7     obl          23        27  0\n",
       "6  پڑھیے    پڑھ   VERB   VM     0    root          28        33  0\n",
       "7      ۔      ۔  PUNCT  SYM     7   punct          33        34  0\n",
       "8     یہ     یہ   PRON  PRP     3   nsubj          36        38  1\n",
       "9   کیسے   کیسا   PRON   WQ     3  advmod          39        43  0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a new column 'y' with the default value 'S_M'\n",
    "data['y'] = 'S_M'\n",
    "\n",
    "# Iterate through the rows to assign 'S_B'\n",
    "for i in range(len(data) - 1):\n",
    "    # Check if the current word ends with a full stop\n",
    "    if data.loc[i, 'text'].endswith('۔'):\n",
    "        # Assign 'S_B' to the next word\n",
    "        if i + 1 < len(data):\n",
    "            data.loc[i + 1, 'y'] = 'S_B'  # Sentence Beginning\n",
    "\n",
    "# Convert 'y' column to categorical type (optional, for ML efficiency)\n",
    "data['y'] = data['y'].astype('category')\n",
    "\n",
    "# Map categorical labels to numeric values\n",
    "label_mapping = {'S_B': 1, 'S_M': 0}\n",
    "data['y'] = data['y'].map(label_mapping)\n",
    "\n",
    "# Verify the result\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>اس</td>\n",
       "      <td>یہ</td>\n",
       "      <td>DET</td>\n",
       "      <td>DEM</td>\n",
       "      <td>2</td>\n",
       "      <td>det</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>سلسلے</td>\n",
       "      <td>سلسلہ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>5</td>\n",
       "      <td>nmod</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>کی</td>\n",
       "      <td>کا</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PSP</td>\n",
       "      <td>2</td>\n",
       "      <td>case</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>دیگر</td>\n",
       "      <td>دیگر</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>5</td>\n",
       "      <td>amod</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اقساط</td>\n",
       "      <td>اقساط</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>7</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>یہاں</td>\n",
       "      <td>یہاں</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>7</td>\n",
       "      <td>obl</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>پڑھیے</td>\n",
       "      <td>پڑھ</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VM</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>یہ</td>\n",
       "      <td>یہ</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>3</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>کیسے</td>\n",
       "      <td>کیسا</td>\n",
       "      <td>PRON</td>\n",
       "      <td>WQ</td>\n",
       "      <td>3</td>\n",
       "      <td>advmod</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ممکن</td>\n",
       "      <td>ممکن</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     text  lemma  upos xpos  head  deprel  start_char  end_char  y\n",
       "0      اس     یہ   DET  DEM     2     det           0         2  0\n",
       "1   سلسلے  سلسلہ  NOUN   NN     5    nmod           3         8  0\n",
       "2      کی     کا   ADP  PSP     2    case           9        11  0\n",
       "3    دیگر   دیگر   ADJ   JJ     5    amod          12        16  0\n",
       "4   اقساط  اقساط  NOUN   NN     7   nsubj          17        22  0\n",
       "5    یہاں   یہاں  PRON  PRP     7     obl          23        27  0\n",
       "6   پڑھیے    پڑھ  VERB   VM     0    root          28        33  0\n",
       "8      یہ     یہ  PRON  PRP     3   nsubj          36        38  1\n",
       "9    کیسے   کیسا  PRON   WQ     3  advmod          39        43  0\n",
       "10   ممکن   ممکن   ADJ   JJ     0    root          44        48  0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows where the 'text' column contains only punctuation\n",
    "data = data[~data['text'].str.contains(r'^[^\\w\\s]+$', na=False)]\n",
    "\n",
    "# Verify the result\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode 'upos', 'xpos', and 'deprel'\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_cats = encoder.fit_transform(data[['upos', 'xpos', 'deprel']])\n",
    "\n",
    "# Convert to DataFrame for easier merging\n",
    "encoded_cats_df = pd.DataFrame(encoded_cats, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Concatenate encoded features back to the dataset\n",
    "data = pd.concat([data.reset_index(drop=True), encoded_cats_df], axis=1)\n",
    "\n",
    "# Drop the original categorical columns (optional)\n",
    "data = data.drop(columns=['upos', 'xpos', 'deprel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the numerical features to normalize\n",
    "numerical_features = ['start_char', 'end_char', 'head']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Option 2: Min-Max Scaling (scales features to a range, typically 0 to 1)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "data[numerical_features] = min_max_scaler.fit_transform(data[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Adjust max_features as needed\n",
    "\n",
    "# Fit and transform only the text column\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(data['text'])\n",
    "\n",
    "# Convert the sparse matrix to a DataFrame for better integration\n",
    "tfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add the TF-IDF features back to the original DataFrame\n",
    "data = pd.concat([data.reset_index(drop=True), tfidf_df], axis=1)\n",
    "\n",
    "# Drop the original text and lemma columns \n",
    "data = data.drop(columns=['text', 'lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>start_char</th>\n",
       "      <th>end_char</th>\n",
       "      <th>y</th>\n",
       "      <th>upos_ADJ</th>\n",
       "      <th>upos_ADP</th>\n",
       "      <th>upos_ADV</th>\n",
       "      <th>upos_AUX</th>\n",
       "      <th>upos_CCONJ</th>\n",
       "      <th>upos_DET</th>\n",
       "      <th>...</th>\n",
       "      <th>یا</th>\n",
       "      <th>یاد</th>\n",
       "      <th>یعنی</th>\n",
       "      <th>یقین</th>\n",
       "      <th>یقینا</th>\n",
       "      <th>یقینی</th>\n",
       "      <th>یونانی</th>\n",
       "      <th>یہ</th>\n",
       "      <th>یہاں</th>\n",
       "      <th>یہی</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036232</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036232</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050725</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1079 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       head  start_char  end_char  y  upos_ADJ  upos_ADP  upos_ADV  upos_AUX  \\\n",
       "0  0.014493    0.000000  0.000000  0       0.0       0.0       0.0       0.0   \n",
       "1  0.036232    0.000003  0.000005  0       0.0       0.0       0.0       0.0   \n",
       "2  0.014493    0.000008  0.000008  0       0.0       1.0       0.0       0.0   \n",
       "3  0.036232    0.000011  0.000012  0       1.0       0.0       0.0       0.0   \n",
       "4  0.050725    0.000015  0.000018  0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   upos_CCONJ  upos_DET  ...   یا  یاد  یعنی  یقین  یقینا  یقینی  یونانی   یہ  \\\n",
       "0         0.0       1.0  ...  0.0  0.0   0.0   0.0    0.0    0.0     0.0  0.0   \n",
       "1         0.0       0.0  ...  0.0  0.0   0.0   0.0    0.0    0.0     0.0  0.0   \n",
       "2         0.0       0.0  ...  0.0  0.0   0.0   0.0    0.0    0.0     0.0  0.0   \n",
       "3         0.0       0.0  ...  0.0  0.0   0.0   0.0    0.0    0.0     0.0  0.0   \n",
       "4         0.0       0.0  ...  0.0  0.0   0.0   0.0    0.0    0.0     0.0  0.0   \n",
       "\n",
       "   یہاں  یہی  \n",
       "0   0.0  0.0  \n",
       "1   0.0  0.0  \n",
       "2   0.0  0.0  \n",
       "3   0.0  0.0  \n",
       "4   0.0  0.0  \n",
       "\n",
       "[5 rows x 1079 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature matrix (drop 'y') and target\n",
    "X = data.drop(columns=['y'])\n",
    "y = data['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training (64%), validation (16%), and test (20%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.36, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.56, random_state=42, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:57:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Train Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    148335\n",
      "           1       0.82      0.57      0.67      5768\n",
      "\n",
      "    accuracy                           0.98    154103\n",
      "   macro avg       0.90      0.78      0.83    154103\n",
      "weighted avg       0.98      0.98      0.98    154103\n",
      "\n",
      "XGBoost - Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     36713\n",
      "           1       0.79      0.55      0.65      1427\n",
      "\n",
      "    accuracy                           0.98     38140\n",
      "   macro avg       0.89      0.77      0.82     38140\n",
      "weighted avg       0.98      0.98      0.98     38140\n",
      "\n",
      "XGBoost - Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     46727\n",
      "           1       0.79      0.55      0.65      1817\n",
      "\n",
      "    accuracy                           0.98     48544\n",
      "   macro avg       0.89      0.77      0.82     48544\n",
      "weighted avg       0.98      0.98      0.98     48544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize XGBoost\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation and test sets\n",
    "y_train_pred_xgb = xgb_model.predict(X_train)\n",
    "y_val_pred_xgb = xgb_model.predict(X_val)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate XGBoost\n",
    "print(\"XGBoost - Train Set:\")\n",
    "print(classification_report(y_train, y_train_pred_xgb))\n",
    "print(\"XGBoost - Validation Set:\")\n",
    "print(classification_report(y_val, y_val_pred_xgb))\n",
    "print(\"XGBoost - Test Set:\")\n",
    "print(classification_report(y_test, y_test_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Train Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99    148335\n",
      "           1       0.80      0.57      0.67      5768\n",
      "\n",
      "    accuracy                           0.98    154103\n",
      "   macro avg       0.89      0.78      0.83    154103\n",
      "weighted avg       0.98      0.98      0.98    154103\n",
      "\n",
      "Decision Tree - Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     36713\n",
      "           1       0.75      0.53      0.62      1427\n",
      "\n",
      "    accuracy                           0.98     38140\n",
      "   macro avg       0.87      0.76      0.80     38140\n",
      "weighted avg       0.97      0.98      0.97     38140\n",
      "\n",
      "Decision Tree - Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     46727\n",
      "           1       0.76      0.55      0.64      1817\n",
      "\n",
      "    accuracy                           0.98     48544\n",
      "   macro avg       0.87      0.77      0.81     48544\n",
      "weighted avg       0.97      0.98      0.97     48544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42, max_depth=10)  \n",
    "# Fit the model on the training set\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation and test sets\n",
    "#also predict on the training set to see how well the model is doing\n",
    "y_train_pred = dt_model.predict(X_train)\n",
    "y_val_pred = dt_model.predict(X_val)\n",
    "y_test_pred = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree - Train Set:\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print(\"Decision Tree - Validation Set:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "print(\"Decision Tree - Test Set:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Train Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    148335\n",
      "           1       1.00      1.00      1.00      5768\n",
      "\n",
      "    accuracy                           1.00    154103\n",
      "   macro avg       1.00      1.00      1.00    154103\n",
      "weighted avg       1.00      1.00      1.00    154103\n",
      "\n",
      "Random Forest - Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     36713\n",
      "           1       0.71      0.56      0.63      1427\n",
      "\n",
      "    accuracy                           0.98     38140\n",
      "   macro avg       0.85      0.78      0.81     38140\n",
      "weighted avg       0.97      0.98      0.97     38140\n",
      "\n",
      "Random Forest - Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     46727\n",
      "           1       0.70      0.58      0.63      1817\n",
      "\n",
      "    accuracy                           0.97     48544\n",
      "   macro avg       0.84      0.78      0.81     48544\n",
      "weighted avg       0.97      0.97      0.97     48544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# Initialize Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation and test sets\n",
    "# also predict on the training set to see how well the model is doing\n",
    "y_train_pred_rf = rf_model.predict(X_train)\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"Random Forest - Train Set:\")\n",
    "print(classification_report(y_train, y_train_pred_rf))\n",
    "print(\"Random Forest - Validation Set:\")\n",
    "print(classification_report(y_val, y_val_pred_rf))\n",
    "print(\"Random Forest - Test Set:\")\n",
    "print(classification_report(y_test, y_test_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feedforward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4816/4816 [==============================] - 31s 6ms/step - loss: 0.0994 - accuracy: 0.9644 - val_loss: 0.0850 - val_accuracy: 0.9670\n",
      "Epoch 2/10\n",
      "4816/4816 [==============================] - 30s 6ms/step - loss: 0.0809 - accuracy: 0.9689 - val_loss: 0.0803 - val_accuracy: 0.9690\n",
      "Epoch 3/10\n",
      "4816/4816 [==============================] - 28s 6ms/step - loss: 0.0733 - accuracy: 0.9715 - val_loss: 0.0748 - val_accuracy: 0.9709\n",
      "Epoch 4/10\n",
      "4816/4816 [==============================] - 32s 7ms/step - loss: 0.0686 - accuracy: 0.9733 - val_loss: 0.0678 - val_accuracy: 0.9745\n",
      "Epoch 5/10\n",
      "4816/4816 [==============================] - 30s 6ms/step - loss: 0.0655 - accuracy: 0.9745 - val_loss: 0.0661 - val_accuracy: 0.9746\n",
      "Epoch 6/10\n",
      "4816/4816 [==============================] - 29s 6ms/step - loss: 0.0635 - accuracy: 0.9751 - val_loss: 0.0658 - val_accuracy: 0.9754\n",
      "Epoch 7/10\n",
      "4816/4816 [==============================] - 30s 6ms/step - loss: 0.0626 - accuracy: 0.9757 - val_loss: 0.0646 - val_accuracy: 0.9750\n",
      "Epoch 8/10\n",
      "4816/4816 [==============================] - 30s 6ms/step - loss: 0.0615 - accuracy: 0.9760 - val_loss: 0.0642 - val_accuracy: 0.9761\n",
      "Epoch 9/10\n",
      "4816/4816 [==============================] - 30s 6ms/step - loss: 0.0605 - accuracy: 0.9764 - val_loss: 0.0642 - val_accuracy: 0.9754\n",
      "Epoch 10/10\n",
      "4816/4816 [==============================] - 29s 6ms/step - loss: 0.0604 - accuracy: 0.9764 - val_loss: 0.0637 - val_accuracy: 0.9764\n",
      "Validation Accuracy: 0.9764\n",
      "1192/1192 [==============================] - 5s 4ms/step\n",
      "Classification Report (Validation):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     36713\n",
      "           1       0.74      0.57      0.64      1427\n",
      "\n",
      "    accuracy                           0.98     38140\n",
      "   macro avg       0.86      0.78      0.82     38140\n",
      "weighted avg       0.97      0.98      0.97     38140\n",
      "\n",
      "1517/1517 [==============================] - 4s 3ms/step\n",
      "Test Accuracy: 0.9762\n",
      "Classification Report (Test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     46727\n",
      "           1       0.73      0.58      0.64      1817\n",
      "\n",
      "    accuracy                           0.98     48544\n",
      "   macro avg       0.86      0.78      0.82     48544\n",
      "weighted avg       0.97      0.98      0.97     48544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define a simple DNN model\n",
    "def create_dnn_model(input_dim, num_classes):\n",
    "    model = keras.Sequential([\n",
    "        layers.InputLayer(input_shape=(input_dim,)),  # Corrected input layer definition\n",
    "        layers.Dense(128, activation='relu'),  # Hidden layer with ReLU activation\n",
    "        layers.Dropout(0.2),  # Dropout for regularization\n",
    "        layers.Dense(64, activation='relu'),  # Another hidden layer\n",
    "        layers.Dropout(0.2),  # Dropout for regularization\n",
    "        layers.Dense(num_classes, activation='softmax')  # Output layer with softmax for multi-class classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy',  # Use sparse categorical crossentropy for integer labels\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the DNN model\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "num_classes = len(y.unique())  # Number of output classes (S_E, S_B, S_M)\n",
    "\n",
    "dnn_model = create_dnn_model(input_dim, num_classes)\n",
    "\n",
    "# Train the DNN model\n",
    "dnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = dnn_model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = dnn_model.predict(X_val)\n",
    "y_val_pred = y_val_pred.argmax(axis=1)  # Get the predicted class labels\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report (Validation):\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Make predictions on the test set (optional)\n",
    "y_test_pred = dnn_model.predict(X_test)\n",
    "y_test_pred = y_test_pred.argmax(axis=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = dnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print(\"Classification Report (Test):\\n\", classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_train_pred = logistic_model.predict(X_train_resampled)\n",
    "y_val_pred = logistic_model.predict(X_val)\n",
    "y_test_pred = logistic_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Training Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92    148335\n",
      "           1       0.89      0.96      0.92    148335\n",
      "\n",
      "    accuracy                           0.92    296670\n",
      "   macro avg       0.92      0.92      0.92    296670\n",
      "weighted avg       0.92      0.92      0.92    296670\n",
      "\n",
      "Logistic Regression - Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94     36713\n",
      "           1       0.24      0.93      0.38      1427\n",
      "\n",
      "    accuracy                           0.89     38140\n",
      "   macro avg       0.62      0.91      0.66     38140\n",
      "weighted avg       0.97      0.89      0.92     38140\n",
      "\n",
      "Logistic Regression - test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94     46727\n",
      "           1       0.23      0.92      0.37      1817\n",
      "\n",
      "    accuracy                           0.89     48544\n",
      "   macro avg       0.62      0.90      0.66     48544\n",
      "weighted avg       0.97      0.89      0.92     48544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression - Training Set:\")\n",
    "print(classification_report(y_train_resampled, y_train_pred))\n",
    "print(\"Logistic Regression - Validation Set:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "print(\"Logistic Regression - test Set:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
