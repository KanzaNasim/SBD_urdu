{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['title', 'text'],\n",
      "        num_rows: 144\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"KANZOO/scrapped_articles\")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the 'train' subset\n",
    "train_dataset = dataset['train']\n",
    "\n",
    "\n",
    "# Function to merge all text into one large dataset\n",
    "def merge_all_text(dataset):\n",
    "    combined_text = \"\"\n",
    "    for example in dataset['train']:\n",
    "        combined_text += example['text'] + \" \"  \n",
    "    return combined_text.strip()\n",
    "\n",
    "\n",
    "# Merge all text from the dataset\n",
    "combined_text = merge_all_text(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "اس سلسلے کی دیگر اقساط یہاں پڑھیے۔\n",
      "\n",
      "یہ کیسے ممکن ہے کہ کسی کا مستقبل ماضی کے بغیر ہو کیونکہ دن دن سے اور پل پل سے جڑا ہوتا ہے۔ جس طرح ہم گزرے دن کو بھی کل کہتے ہیں اور آنے والے دن کو بھی کل کہتے ہیں اس لیے کیونکہ کل اور کل میں جو آج ہے وہ ایک کڑی ہے جو دونوں کو اپس میں جوڑ کر رکھتی ہے۔ تو ہم اگر کبھی تنہائی میں کچھ پل نکال کر سوچیں کہ ہماری جتنی بھی زندگی گزری خواہ وہ 24 برس ہو 64 کی یا 84 برس ہو ہم یہ حیات اسی صورت میں گزار پاتے ہیں جب ہم اپنے گزرے برسوں اور شب و روز سے جڑے رہتے ہیں۔\n",
      "\n",
      "اگر لوگوں قوموں اور تہذیبوں سے ان کا ماضی چھین لیا جائے تو وہ شاید زیادہ عرصہ زندہ نہیں رہ پائیں گی۔ ان میں آگے بڑھنے کی چاہت ختم ہوجائے گی تگ و دو کا جوہر ان سے چھن جائے گا بالکل ایسے جیسے کسی وجود کو الزائمر کی بیماری لگتی ہے اور اس کی یادداشت کے خلیے بے جان ہونے لگتے ہیں۔ آپ یہ سمجھیں کہ یہ بیماری اس سے اس کا ماضی چھین لیتی ہے۔ اور وہ اسی کیفیت میں زیادہ زندگی نہیں جی سکے گا اور اگر جیے گا بھی تو حیات کے ان رنگوں ذائقوں اور کیفیتوں کے ریگستان میں جہاں موت کی ویرانی کے سوا کچھ نہیں بچتا۔ نہ رنگوں کے پھ\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Function to remove all punctuation except for Urdu period (۔)\n",
    "def remove_punctuation(text):\n",
    "    # Regex pattern to remove all punctuation except for \"۔\"\n",
    "    pattern = r'[^\\w\\s۔]'  # \\w matches word characters, \\s matches spaces, \"۔\" is kept\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# Remove all punctuation except for \"۔\"\n",
    "cleaned_text = remove_punctuation(combined_text)\n",
    "\n",
    "print(cleaned_text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split sentences based on \"۔\" and remove those with length <= 3\n",
    "def filter_short_sentences(text):\n",
    "    # Split the text by \"۔\"\n",
    "    sentences = text.split('۔')\n",
    "    # Filter out sentences with length <= 3\n",
    "    filtered_sentences = [s.strip() for s in sentences if len(s.strip()) > 3]\n",
    "    # Join the filtered sentences back with \"۔\" to get the cleaned text\n",
    "    cleaned_text = '۔'.join(filtered_sentences)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Example usage\n",
    "cleaned_text = filter_short_sentences(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No sentences of length 3 or less found.\n"
     ]
    }
   ],
   "source": [
    "# Function to verify there are no sentences with length 3 or less\n",
    "def check_short_sentences(text):\n",
    "    # Split the text by \"۔\"\n",
    "    sentences = text.split('۔')\n",
    "    # Find sentences with length <= 3\n",
    "    short_sentences = [s.strip() for s in sentences if len(s.strip()) <= 3]\n",
    "    \n",
    "    if short_sentences:\n",
    "        print(\"Found short sentences:\", short_sentences)\n",
    "    else:\n",
    "        print(\"No sentences of length 3 or less found.\")\n",
    "\n",
    "# Check the cleaned_text for any short sentences\n",
    "check_short_sentences(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sentence Count: 9227\n"
     ]
    }
   ],
   "source": [
    "# Function to count the number of sentences based on the period \"۔\"\n",
    "def count_sentences(text):\n",
    "    sentences = text.split('۔') \n",
    "    # Filter out empty strings resulting from splitting\n",
    "    return len([s for s in sentences if s.strip()])  \n",
    "\n",
    "# Get the sentences in the cleaned text\n",
    "sentences = count_sentences(cleaned_text) \n",
    "\n",
    "# Print the total sentence count\n",
    "print(\"Total Sentence Count:\", sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "اس سلسلے کی دیگر اقساط یہاں پڑھیےیہ کیسے ممکن ہے کہ کسی کا مستقبل ماضی کے بغیر ہو کیونکہ دن دن سے اور پل پل سے جڑا ہوتا ہےجس طرح ہم گزرے دن کو بھی کل کہتے ہیں اور آنے والے دن کو بھی کل کہتے ہیں اس لیے کیونکہ کل اور کل میں جو آج ہے وہ ایک کڑی ہے جو دونوں کو اپس میں جوڑ کر رکھتی ہےتو ہم اگر کبھی تنہائی میں کچھ پل نکال کر سوچیں کہ ہماری جتنی بھی زندگی گزری خواہ وہ 24 برس ہو 64 کی یا 84 برس ہو ہم یہ حیات اسی صورت میں گزار پاتے ہیں جب ہم اپنے گزرے برسوں اور شب و روز سے جڑے رہتے ہیںاگر لوگوں قوموں اور تہذیبوں سے ان کا ماضی چھین لیا جائے تو وہ شاید زیادہ عرصہ زندہ نہیں رہ پائیں گیان میں آگے بڑھنے کی چاہت ختم ہوجائے گی تگ و دو کا جوہر ان سے چھن جائے گا بالکل ایسے جیسے کسی وجود کو الزائمر کی بیماری لگتی ہے اور اس کی یادداشت کے خلیے بے جان ہونے لگتے ہیںآپ یہ سمجھیں کہ یہ بیماری اس سے اس کا ماضی چھین لیتی ہےاور وہ اسی کیفیت میں زیادہ زندگی نہیں جی سکے گا اور اگر جیے گا بھی تو حیات کے ان رنگوں ذائقوں اور کیفیتوں کے ریگستان میں جہاں موت کی ویرانی کے سوا کچھ نہیں بچتانہ رنگوں کے پھول کھلتے ہیں نہ ذائقوں کی خوشبو کا کوئی جھونکا آتا ہے اور نہ غم و خوشی کی کوئی فاختہ اڑتی ہے اور نہ آسمان کی نیلاہٹ کے گہرے رنگ میں کشش کی کوئی ناؤ چلتی ہےبس ایک بے رنگ اور بے ذائقہ حیاتہمارا آج کا سفر بھی سمندر کنارے اور ان پہاڑیوں کے جنگلات آبشاروں غاروں اور قدامت کی ان پگڈنڈیوں پر ہی ہے مگر اج ہمیں ڈاکٹر عبدالرؤف کی کراچی ریجن پر کی گئی تحقیق اور اس تحقیق پر پاؤلو بیگی کی تازہ تحقیق پر تفصیلی بات کرنی تھی لیکن جیسے ہی ہم سفر کرنے کی تیاری میں تھے تو ہمارے ساتھیوں میں سے کسی نے دو تین سوال کر ڈالے کہ کھیرتھر کے\n"
     ]
    }
   ],
   "source": [
    "# Function to remove the Urdu period \"۔\" from the text\n",
    "def remove_period(text):\n",
    "    cleaned_text_without_period = text.replace('۔', '')  \n",
    "    return cleaned_text_without_period\n",
    "\n",
    "cleaned_text_without_period = remove_period(cleaned_text)\n",
    "\n",
    "print(cleaned_text_without_period[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split text into chunks\n",
    "def split_into_chunks(text, max_length=512):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for word in words:\n",
    "        # Check if adding the next word would exceed the max length\n",
    "        if len(current_chunk) + len(word.split()) > max_length:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "        else:\n",
    "            current_chunk.append(word)\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Split the cleaned text\n",
    "chunks = split_into_chunks(cleaned_text_without_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\kanza nasim\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Kanza Nasim\\.cache\\huggingface\\hub\\models--xlm-roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForTokenClassification\n",
    "import torch\n",
    "\n",
    "# 1. Load XLM-R tokenizer and model\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "model = XLMRobertaForTokenClassification.from_pretrained('xlm-roberta-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "اس سلسلے کی دیگر اقساط یہاں پڑھیےیہ کیسے ممکن ہے کہ کسی کا مستقبل ماضی کے بغیر ہو کیونکہ دن دن سے اور پل پل سے جڑا ہوتا ہےجس طرح ہم گزرے دن کو بھی کل کہتے ہیں اور آنے والے دن کو بھی کل کہتے ہیں اس لیے کیونکہ کل اور کل میں جو آج ہے وہ ایک کڑی ہے جو دونوں کو اپس میں جوڑ کر رکھتی ہےتو ہم اگر کبھی تنہائی میں کچھ پل نکال کر سوچیں کہ ہماری جتنی بھی زندگی گزری خواہ وہ 24 برس ہو 64 کی یا 84 برس ہو ہم یہ حیات اسی صورت میں گزار پاتے ہیں جب ہم اپنے گزرے برسوں اور شب و روز سے جڑے رہتے ہیںاگر لوگوں قوموں اور تہذیبوں سے ان کا ماضی چھین لیا جائے تو وہ شاید زیادہ عرصہ زندہ نہیں رہ پائیں گیان میں آگے بڑھنے کی چاہت ختم ہوجائے گی تگ و دو کا جوہر ان سے چھن جائے گا بالکل ایسے جیسے کسی وجود کو الزائمر کی بیماری لگتی ہے اور اس کی یادداشت کے خلیے بے جان ہونے لگتے ہیںآپ یہ سمجھیں کہ یہ بیماری اس سے اس کا ماضی چھین لیتی ہےاور وہ اسی کیفیت میں زیادہ زندگی نہیں جی سکے گا اور اگر جیے گا بھی تو حیات کے ان رنگوں ذائقوں اور کیفیتوں کے ریگستان میں جہاں موت کی ویرانی کے سوا کچھ نہیں بچتانہ رنگوں کے پھول کھلتے ہیں نہ ذائقوں کی خوشبو کا کوئی جھونکا آتا ہے اور نہ غم و خوشی کی کوئی فاختہ اڑتی ہے اور نہ آسمان کی نیلاہٹ کے گہرے رنگ میں کشش کی کوئی ناؤ چلتی ہےبس ایک بے رنگ اور بے ذائقہ حیاتہمارا آج کا سفر بھی سمندر کنارے اور ان پہاڑیوں کے جنگلات آبشاروں غاروں اور قدامت کی ان پگڈنڈیوں پر ہی ہے مگر اج ہمیں ڈاکٹر عبدالرؤف کی کراچی ریجن پر کی گئی تحقیق اور اس تحقیق پر پاؤلو بیگی کی تازہ تحقیق پر تفصیلی بات کرنی تھی لیکن جیسے ہی ہم سفر کرنے کی تیاری میں تھے تو ہمارے ساتھیوں میں سے کسی نے دو تین سوال کر ڈالے کہ کھیرتھر کے اس پہاڑی سلسلے پر ارتقا کا عمل کتنا قدیم ہوسکتا ہے اور ڈاکٹر عبدالرؤف سے پہلے بھی کراچی پر اس حوالے سے تحقیق ہوئی ہے یا نہیں مختلف زمانوں کے نام اور ان کی عمریںتصویر ایکس یہ سوالات اپنی جگہ پر اہم ہیں اور ان سوالات کا جواب ڈاکٹر صاحب کی رپورٹ اینشیئنٹ سیٹلمنٹس ان کراچی ریجن Ancient Settlements in Karachi Region میں ضرور موجود ہوگامگر میں یہاں ہربرٹ جارج ویلز Herbert George Wells کی مشہور تحقیقی کتاب دی اؤٹ لائن اف ہسٹری سے دو نقشے آپ کے سامنے پیش کررہا ہوں جو آج سے 25 اور 50 ہزار سال پہلے کے جغرافیائی حالات کو ظاہر کرتے ہیں50 ہزار سال پہلے کا نقشہ 50 ہزار برس پہلے والے نقشے کو دیکھیں گے تو آپ کو میدانی اور ریگستانی سندھ پورا پنجاب گنگا گھاٹی پانی کے نیچے نظر آئیں گے جبکہ سندھ کے مغربی اونچائی والے پہاڑی سلسلے اور بلوچستان آپ کو پانی سے آزاد نظر آئیں گےجبکہ 35\n",
      "سے 25 ہزار برس پہلے والے نقشے میں\n"
     ]
    }
   ],
   "source": [
    "# Store the words for sentence reconstruction\n",
    "words = cleaned_text_without_period.split()\n",
    "\n",
    "# Initialize a list to hold the detected sentences\n",
    "sentences = []\n",
    "\n",
    "# Process only the first chunk\n",
    "if chunks:  # Check if there are any chunks\n",
    "    chunk = chunks[0]  # Get the first chunk\n",
    "    inputs = tokenizer(chunk, truncation=True, max_length=512, return_tensors='pt')\n",
    "    \n",
    "    # Get the output logits from the BERT model\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "    # Apply a classification threshold for sentence boundary detection\n",
    "    sentence_end_threshold = 0.58    # Convert logits to probabilities (using sigmoid)\n",
    "    predictions = torch.sigmoid(logits)\n",
    "\n",
    "    # Get positions where tokens are predicted as sentence ends (based on threshold)\n",
    "    sentence_end_positions = predictions[:, :, 1] > sentence_end_threshold  \n",
    "    # Reconstruct sentences based on the detected sentence-end tokens\n",
    "    current_sentence = []\n",
    "\n",
    "    for i, word in enumerate(chunk.split()):  \n",
    "        current_sentence.append(word)\n",
    "        if sentence_end_positions[0][i]: \n",
    "            sentences.append(\" \".join(current_sentence))\n",
    "            current_sentence = []\n",
    "\n",
    "    # Append the final sentence if it wasn't completed\n",
    "    if current_sentence:\n",
    "        sentences.append(\" \".join(current_sentence))\n",
    "\n",
    "# Output the sentences detected in the first chunk\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### trying out 0.54, 0.55, 0.56."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1: اس سلسلے کی دیگر اقساط یہاں پڑھیےیہ کیسے ممکن ہے کہ کسی کا مستقبل ماضی کے بغیر ہو کیونکہ دن دن سے اور پل پل سے جڑا ہوتا ہےجس طرح ہم گزرے دن کو بھی کل کہتے ہیں اور آنے والے دن کو بھی کل کہتے ہیں اس لیے کیونکہ کل اور کل میں جو آج ہے وہ ایک کڑی ہے جو دونوں کو اپس میں جوڑ کر رکھتی ہےتو ہم اگر کبھی تنہائی میں کچھ پل نکال کر سوچیں کہ ہماری جتنی بھی زندگی گزری خواہ وہ 24 برس ہو 64 کی یا 84 برس ہو ہم یہ حیات اسی صورت میں گزار پاتے ہیں جب ہم اپنے گزرے برسوں اور شب و روز سے جڑے رہتے ہیںاگر لوگوں قوموں اور تہذیبوں سے ان کا ماضی چھین لیا جائے تو وہ شاید زیادہ عرصہ زندہ نہیں رہ پائیں گیان میں آگے بڑھنے کی چاہت ختم ہوجائے گی تگ و دو کا جوہر ان سے چھن جائے گا بالکل ایسے جیسے کسی وجود کو الزائمر کی بیماری لگتی ہے اور اس کی یادداشت کے خلیے بے جان ہونے لگتے ہیںآپ یہ سمجھیں کہ یہ بیماری اس سے اس کا ماضی چھین لیتی ہےاور وہ اسی کیفیت میں زیادہ زندگی نہیں جی سکے گا اور اگر جیے گا بھی تو حیات کے ان رنگوں ذائقوں اور کیفیتوں کے ریگستان میں جہاں موت کی ویرانی کے سوا کچھ نہیں بچتانہ رنگوں کے پھول کھلتے ہیں نہ ذائقوں کی خوشبو کا کوئی جھونکا آتا ہے اور نہ غم و خوشی کی کوئی فاختہ اڑتی ہے اور نہ آسمان کی نیلاہٹ کے گہرے رنگ میں کشش کی کوئی ناؤ چلتی ہےبس ایک بے رنگ اور بے ذائقہ حیاتہمارا آج کا سفر بھی سمندر کنارے اور ان پہاڑیوں کے جنگلات آبشاروں غاروں اور قدامت کی ان پگڈنڈیوں پر ہی ہے مگر اج ہمیں ڈاکٹر عبدالرؤف کی کراچی ریجن پر کی گئی تحقیق اور اس تحقیق پر پاؤلو بیگی کی تازہ تحقیق پر تفصیلی بات کرنی تھی لیکن جیسے ہی ہم سفر کرنے کی تیاری میں تھے تو ہمارے ساتھیوں میں سے کسی نے دو تین سوال کر ڈالے کہ کھیرتھر کے اس پہاڑی سلسلے پر ارتقا کا عمل کتنا قدیم ہوسکتا ہے اور ڈاکٹر عبدالرؤف سے پہلے بھی کراچی پر اس حوالے سے تحقیق ہوئی ہے یا نہیں مختلف زمانوں کے نام اور ان کی عمریںتصویر ایکس یہ سوالات اپنی جگہ پر اہم ہیں اور ان سوالات کا جواب ڈاکٹر صاحب کی رپورٹ اینشیئنٹ سیٹلمنٹس ان کراچی ریجن Ancient Settlements in Karachi Region میں ضرور موجود ہوگامگر میں یہاں ہربرٹ جارج ویلز Herbert George Wells کی مشہور تحقیقی کتاب دی اؤٹ لائن اف ہسٹری سے دو نقشے آپ کے سامنے پیش کررہا ہوں جو آج سے 25 اور 50 ہزار سال پہلے کے جغرافیائی حالات کو ظاہر کرتے ہیں50 ہزار سال پہلے کا نقشہ 50 ہزار برس پہلے والے نقشے کو دیکھیں گے تو آپ کو میدانی اور ریگستانی سندھ پورا پنجاب گنگا گھاٹی پانی کے نیچے نظر آئیں گے جبکہ سندھ کے مغربی اونچائی والے پہاڑی سلسلے اور بلوچستان آپ کو پانی سے آزاد نظر آئیں گےجبکہ 35\n",
      "sentence2: سے 25 ہزار برس پہلے والے نقشے میں\n"
     ]
    }
   ],
   "source": [
    "# Output the sentences in the desired format\n",
    "for idx, sentence in enumerate(sentences, start=1):\n",
    "    print(f\"sentence{idx}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 466\n"
     ]
    }
   ],
   "source": [
    "# Check the number of chunks\n",
    "num_chunks = len(chunks)\n",
    "print(f\"Number of chunks: {num_chunks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now doing the same for the rest of the chunks \n",
    "# Initialize a list to hold the detected sentences\n",
    "sentences = []\n",
    "\n",
    "# Process all chunks\n",
    "for chunk in chunks:\n",
    "    inputs = tokenizer(chunk, truncation=True, max_length=512, return_tensors='pt')\n",
    "    \n",
    "    # Get the output logits from the BERT model\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "    # Apply a classification threshold for sentence boundary detection\n",
    "    sentence_end_threshold = 0.54  # Adjust based on your use case\n",
    "\n",
    "    # Convert logits to probabilities (using sigmoid)\n",
    "    predictions = torch.sigmoid(logits)\n",
    "\n",
    "    # Get positions where tokens are predicted as sentence ends (based on threshold)\n",
    "    sentence_end_positions = predictions[:, :, 1] > sentence_end_threshold  \n",
    "\n",
    "    # Reconstruct sentences based on the detected sentence-end tokens\n",
    "    current_sentence = []\n",
    "\n",
    "    for i, word in enumerate(chunk.split()):  \n",
    "        current_sentence.append(word)\n",
    "        if sentence_end_positions[0][i]:  \n",
    "            sentences.append(\" \".join(current_sentence))\n",
    "            current_sentence = []\n",
    "\n",
    "    # Append the final sentence if it wasn't complete\n",
    "    if current_sentence:\n",
    "        sentences.append(\" \".join(current_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: اس سلسلے کی دیگر اقساط یہاں پڑھیےیہ کیسے ممکن ہے\n",
      "Sentence 2: کہ کسی کا مستقبل ماضی کے بغیر ہو\n",
      "Sentence 3: کیونکہ دن دن سے اور پل پل\n",
      "Sentence 4: سے جڑا ہوتا ہےجس طرح\n",
      "Sentence 5: ہم\n",
      "Sentence 6: گزرے دن کو بھی کل کہتے ہیں\n",
      "Sentence 7: اور آنے والے دن کو بھی کل\n",
      "Sentence 8: کہتے ہیں اس لیے کیونکہ\n",
      "Sentence 9: کل اور کل میں\n",
      "Sentence 10: جو\n"
     ]
    }
   ],
   "source": [
    "# Output the first few sentences detected in all chunks\n",
    "num_sentences_to_print = 10 \n",
    "\n",
    "# Print only the first few sentences\n",
    "for i, sentence in enumerate(sentences):\n",
    "    if i >= num_sentences_to_print:\n",
    "        break\n",
    "    print(f\"Sentence {i+1}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences detected: 24658\n"
     ]
    }
   ],
   "source": [
    "# Output the total number of sentences detected\n",
    "total_sentences = len(sentences)\n",
    "print(f\"Total number of sentences detected: {total_sentences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentences:\n",
      "1: اس سلسلے کی دیگر اقساط یہاں پڑھیے\n",
      "2: یہ کیسے ممکن ہے کہ کسی کا مستقبل ماضی کے بغیر ہو کیونکہ دن دن سے اور پل پل سے جڑا ہوتا ہے\n",
      "3: جس طرح ہم گزرے دن کو بھی کل کہتے ہیں اور آنے والے دن کو بھی کل کہتے ہیں اس لیے کیونکہ کل اور کل میں جو آج ہے وہ ایک کڑی ہے جو دونوں کو اپس میں جوڑ کر رکھتی ہے\n",
      "4: تو ہم اگر کبھی تنہائی میں کچھ پل نکال کر سوچیں کہ ہماری جتنی بھی زندگی گزری خواہ وہ 24 برس ہو 64 کی یا 84 برس ہو ہم یہ حیات اسی صورت میں گزار پاتے ہیں جب ہم اپنے گزرے برسوں اور شب و روز سے جڑے رہتے ہیں\n",
      "5: اگر لوگوں قوموں اور تہذیبوں سے ان کا ماضی چھین لیا جائے تو وہ شاید زیادہ عرصہ زندہ نہیں رہ پائیں گی\n",
      "6: ان میں آگے بڑھنے کی چاہت ختم ہوجائے گی تگ و دو کا جوہر ان سے چھن جائے گا بالکل ایسے جیسے کسی وجود کو الزائمر کی بیماری لگتی ہے اور اس کی یادداشت کے خلیے بے جان ہونے لگتے ہیں\n",
      "7: آپ یہ سمجھیں کہ یہ بیماری اس سے اس کا ماضی چھین لیتی ہے\n",
      "8: اور وہ اسی کیفیت میں زیادہ زندگی نہیں جی سکے گا اور اگر جیے گا بھی تو حیات کے ان رنگوں ذائقوں اور کیفیتوں کے ریگستان میں جہاں موت کی ویرانی کے سوا کچھ نہیں بچتا\n",
      "9: نہ رنگوں کے پھول کھلتے ہیں نہ ذائقوں کی خوشبو کا کوئی جھونکا آتا ہے اور نہ غم و خوشی کی کوئی فاختہ اڑتی ہے اور نہ آسمان کی نیلاہٹ کے گہرے رنگ میں کشش کی کوئی ناؤ چلتی ہے\n"
     ]
    }
   ],
   "source": [
    "# Function to extract original sentences\n",
    "def extract_original_sentences(cleaned_text):\n",
    "    # Split original text by punctuation (assuming '۔' is the sentence boundary marker in original text)\n",
    "    original_sentences = cleaned_text.split('۔')\n",
    "\n",
    "    # Filter out empty sentences caused by splitting\n",
    "    original_sentences = [sentence.strip() for sentence in original_sentences if sentence.strip()]\n",
    "    \n",
    "    return original_sentences\n",
    "\n",
    "# Extract the original sentences\n",
    "original_sentences = extract_original_sentences(cleaned_text)\n",
    "\n",
    "# Print a few original sentences for clarity\n",
    "print(\"Original Sentences:\")\n",
    "for i, sentence in enumerate(original_sentences):\n",
    "    if i < 9:  # Print only the first 5 sentences\n",
    "        print(f\"{i + 1}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Convert original and detected sentences to sets for comparison\n",
    "original_sentences_set = set(original_sentences)\n",
    "detected_sentences_set = set(sentences)\n",
    "\n",
    "# Calculate True Positives, False Positives, and False Negatives\n",
    "true_positives = detected_sentences_set.intersection(original_sentences_set)\n",
    "false_positives = detected_sentences_set - original_sentences_set\n",
    "false_negatives = original_sentences_set - detected_sentences_set\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = len(true_positives) / (len(true_positives) + len(false_positives)) if (len(true_positives) + len(false_positives)) > 0 else 0\n",
    "recall = len(true_positives) / (len(true_positives) + len(false_negatives)) if (len(true_positives) + len(false_negatives)) > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(chunk, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Get the output logits from the BERT model\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     11\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Apply a classification threshold for sentence boundary detection\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:1404\u001b[0m, in \u001b[0;36mXLMRobertaForTokenClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1398\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;124;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1402\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1404\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1416\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1418\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(sequence_output)\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:837\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    828\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    830\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m    831\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    832\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    835\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    836\u001b[0m )\n\u001b[1;32m--> 837\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    849\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    850\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:525\u001b[0m, in \u001b[0;36mXLMRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    514\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    515\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    516\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m         output_attentions,\n\u001b[0;32m    523\u001b[0m     )\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 525\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:414\u001b[0m, in \u001b[0;36mXLMRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    404\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    411\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    413\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:350\u001b[0m, in \u001b[0;36mXLMRobertaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    333\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    339\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    340\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    341\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[0;32m    342\u001b[0m         hidden_states,\n\u001b[0;32m    343\u001b[0m         attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m         output_attentions,\n\u001b[0;32m    349\u001b[0m     )\n\u001b[1;32m--> 350\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:299\u001b[0m, in \u001b[0;36mXLMRobertaSelfOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 299\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    301\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# using threshold = 0.55\n",
    "# Initialize a list to hold the detected sentences\n",
    "sentences = []\n",
    "\n",
    "# Process all chunks\n",
    "for chunk in chunks:\n",
    "    inputs = tokenizer(chunk, truncation=True, max_length=512, return_tensors='pt')\n",
    "    \n",
    "    # Get the output logits from the BERT model\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "    # Apply a classification threshold for sentence boundary detection\n",
    "    sentence_end_threshold = 0.55  # Adjust based on your use case\n",
    "\n",
    "    # Convert logits to probabilities (using sigmoid)\n",
    "    predictions = torch.sigmoid(logits)\n",
    "\n",
    "    # Get positions where tokens are predicted as sentence ends (based on threshold)\n",
    "    sentence_end_positions = predictions[:, :, 1] > sentence_end_threshold  \n",
    "\n",
    "    # Reconstruct sentences based on the detected sentence-end tokens\n",
    "    current_sentence = []\n",
    "\n",
    "    for i, word in enumerate(chunk.split()):  \n",
    "        current_sentence.append(word)\n",
    "        if sentence_end_positions[0][i]:  \n",
    "            sentences.append(\" \".join(current_sentence))\n",
    "            current_sentence = []\n",
    "\n",
    "    # Append the final sentence if it wasn't complete\n",
    "    if current_sentence:\n",
    "        sentences.append(\" \".join(current_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the first few sentences detected in all chunks\n",
    "num_sentences_to_print = 10 \n",
    "\n",
    "# Print only the first few sentences\n",
    "for i, sentence in enumerate(sentences):\n",
    "    if i >= num_sentences_to_print:\n",
    "        break\n",
    "    print(f\"Sentence {i+1}: {sentence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
