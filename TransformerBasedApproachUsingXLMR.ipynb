{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['title', 'text'],\n",
      "        num_rows: 144\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"KANZOO/scrapped_articles\")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the 'train' subset\n",
    "train_dataset = dataset['train']\n",
    "\n",
    "\n",
    "# Function to merge all text into one large dataset\n",
    "def merge_all_text(dataset):\n",
    "    combined_text = \"\"\n",
    "    for example in dataset['train']:\n",
    "        combined_text += example['text'] + \" \"  \n",
    "    return combined_text.strip()\n",
    "\n",
    "\n",
    "# Merge all text from the dataset\n",
    "combined_text = merge_all_text(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "اس سلسلے کی دیگر اقساط یہاں پڑھیے۔\n",
      "\n",
      "یہ کیسے ممکن ہے کہ کسی کا مستقبل ماضی کے بغیر ہو کیونکہ دن دن سے اور پل پل سے جڑا ہوتا ہے۔ جس طرح ہم گزرے دن کو بھی کل کہتے ہیں اور آنے والے دن کو بھی کل کہتے ہیں اس لیے کیونکہ کل اور کل میں جو آج ہے وہ ایک کڑی ہے جو دونوں کو اپس میں جوڑ کر رکھتی ہے۔ تو ہم اگر کبھی تنہائی میں کچھ پل نکال کر سوچیں کہ ہماری جتنی بھی زندگی گزری خواہ وہ 24 برس ہو 64 کی یا 84 برس ہو ہم یہ حیات اسی صورت میں گزار پاتے ہیں جب ہم اپنے گزرے برسوں اور شب و روز سے جڑے رہتے ہیں۔\n",
      "\n",
      "اگر لوگوں قوموں اور تہذیبوں سے ان کا ماضی چھین لیا جائے تو وہ شاید زیادہ عرصہ زندہ نہیں رہ پائیں گی۔ ان میں آگے بڑھنے کی چاہت ختم ہوجائے گی تگ و دو کا جوہر ان سے چھن جائے گا بالکل ایسے جیسے کسی وجود کو الزائمر کی بیماری لگتی ہے اور اس کی یادداشت کے خلیے بے جان ہونے لگتے ہیں۔ آپ یہ سمجھیں کہ یہ بیماری اس سے اس کا ماضی چھین لیتی ہے۔ اور وہ اسی کیفیت میں زیادہ زندگی نہیں جی سکے گا اور اگر جیے گا بھی تو حیات کے ان رنگوں ذائقوں اور کیفیتوں کے ریگستان میں جہاں موت کی ویرانی کے سوا کچھ نہیں بچتا۔ نہ رنگوں کے پھ\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Function to remove all punctuation except for Urdu period (۔)\n",
    "def remove_punctuation(text):\n",
    "    # Regex pattern to remove all punctuation except for \"۔\"\n",
    "    pattern = r'[^\\w\\s۔]'  # \\w matches word characters, \\s matches spaces, \"۔\" is kept\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# Remove all punctuation except for \"۔\"\n",
    "cleaned_text = remove_punctuation(combined_text)\n",
    "\n",
    "print(cleaned_text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split sentences based on \"۔\" and remove those with length <= 3\n",
    "def filter_short_sentences(text):\n",
    "    # Split the text by \"۔\"\n",
    "    sentences = text.split('۔')\n",
    "    # Filter out sentences with length <= 3\n",
    "    filtered_sentences = [s.strip() for s in sentences if len(s.strip()) > 3]\n",
    "    # Join the filtered sentences back with \"۔\" to get the cleaned text\n",
    "    cleaned_text = '۔'.join(filtered_sentences)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Example usage\n",
    "cleaned_text = filter_short_sentences(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No sentences of length 3 or less found.\n"
     ]
    }
   ],
   "source": [
    "# Function to verify there are no sentences with length 3 or less\n",
    "def check_short_sentences(text):\n",
    "    # Split the text by \"۔\"\n",
    "    sentences = text.split('۔')\n",
    "    # Find sentences with length <= 3\n",
    "    short_sentences = [s.strip() for s in sentences if len(s.strip()) <= 3]\n",
    "    \n",
    "    if short_sentences:\n",
    "        print(\"Found short sentences:\", short_sentences)\n",
    "    else:\n",
    "        print(\"No sentences of length 3 or less found.\")\n",
    "\n",
    "# Check the cleaned_text for any short sentences\n",
    "check_short_sentences(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sentence Count: 9227\n"
     ]
    }
   ],
   "source": [
    "# Function to count the number of sentences based on the period \"۔\"\n",
    "def count_sentences(text):\n",
    "    sentences = text.split('۔') \n",
    "    # Filter out empty strings resulting from splitting\n",
    "    return len([s for s in sentences if s.strip()])  \n",
    "\n",
    "# Get the sentences in the cleaned text\n",
    "sentences = count_sentences(cleaned_text) \n",
    "\n",
    "# Print the total sentence count\n",
    "print(\"Total Sentence Count:\", sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "اس سلسلے کی دیگر اقساط یہاں پڑھیےیہ کیسے ممکن ہے کہ کسی کا مستقبل ماضی کے بغیر ہو کیونکہ دن دن سے اور پل پل سے جڑا ہوتا ہےجس طرح ہم گزرے دن کو بھی کل کہتے ہیں اور آنے والے دن کو بھی کل کہتے ہیں اس لیے کیونکہ کل اور کل میں جو آج ہے وہ ایک کڑی ہے جو دونوں کو اپس میں جوڑ کر رکھتی ہےتو ہم اگر کبھی تنہائی میں کچھ پل نکال کر سوچیں کہ ہماری جتنی بھی زندگی گزری خواہ وہ 24 برس ہو 64 کی یا 84 برس ہو ہم یہ حیات اسی صورت میں گزار پاتے ہیں جب ہم اپنے گزرے برسوں اور شب و روز سے جڑے رہتے ہیںاگر لوگوں قوموں اور تہذیبوں سے ان کا ماضی چھین لیا جائے تو وہ شاید زیادہ عرصہ زندہ نہیں رہ پائیں گیان میں آگے بڑھنے کی چاہت ختم ہوجائے گی تگ و دو کا جوہر ان سے چھن جائے گا بالکل ایسے جیسے کسی وجود کو الزائمر کی بیماری لگتی ہے اور اس کی یادداشت کے خلیے بے جان ہونے لگتے ہیںآپ یہ سمجھیں کہ یہ بیماری اس سے اس کا ماضی چھین لیتی ہےاور وہ اسی کیفیت میں زیادہ زندگی نہیں جی سکے گا اور اگر جیے گا بھی تو حیات کے ان رنگوں ذائقوں اور کیفیتوں کے ریگستان میں جہاں موت کی ویرانی کے سوا کچھ نہیں بچتانہ رنگوں کے پھول کھلتے ہیں نہ ذائقوں کی خوشبو کا کوئی جھونکا آتا ہے اور نہ غم و خوشی کی کوئی فاختہ اڑتی ہے اور نہ آسمان کی نیلاہٹ کے گہرے رنگ میں کشش کی کوئی ناؤ چلتی ہےبس ایک بے رنگ اور بے ذائقہ حیاتہمارا آج کا سفر بھی سمندر کنارے اور ان پہاڑیوں کے جنگلات آبشاروں غاروں اور قدامت کی ان پگڈنڈیوں پر ہی ہے مگر اج ہمیں ڈاکٹر عبدالرؤف کی کراچی ریجن پر کی گئی تحقیق اور اس تحقیق پر پاؤلو بیگی کی تازہ تحقیق پر تفصیلی بات کرنی تھی لیکن جیسے ہی ہم سفر کرنے کی تیاری میں تھے تو ہمارے ساتھیوں میں سے کسی نے دو تین سوال کر ڈالے کہ کھیرتھر کے\n"
     ]
    }
   ],
   "source": [
    "# Function to remove the Urdu period \"۔\" from the text\n",
    "def remove_period(text):\n",
    "    cleaned_text_without_period = text.replace('۔', '')  \n",
    "    return cleaned_text_without_period\n",
    "\n",
    "cleaned_text_without_period = remove_period(cleaned_text)\n",
    "\n",
    "print(cleaned_text_without_period[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split text into chunks\n",
    "def split_into_chunks(text, max_length=512):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for word in words:\n",
    "        # Check if adding the next word would exceed the max length\n",
    "        if len(current_chunk) + len(word.split()) > max_length:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "        else:\n",
    "            current_chunk.append(word)\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Split the cleaned text\n",
    "chunks = split_into_chunks(cleaned_text_without_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\kanza nasim\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kanza Nasim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForTokenClassification\n",
    "import torch\n",
    "\n",
    "# 1. Load XLM-R tokenizer and model\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "model = XLMRobertaForTokenClassification.from_pretrained('xlm-roberta-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "اس سلسلے کی دیگر اقساط یہاں پڑھیےیہ کیسے ممکن ہے کہ کسی کا مستقبل ماضی کے بغیر ہو کیونکہ دن دن سے اور پل پل سے جڑا ہوتا ہےجس طرح ہم گزرے دن کو بھی کل کہتے ہیں اور آنے والے دن کو بھی کل کہتے ہیں اس لیے کیونکہ کل اور کل میں جو آج ہے وہ ایک کڑی ہے جو دونوں کو اپس میں جوڑ کر رکھتی ہےتو ہم اگر کبھی تنہائی میں کچھ پل نکال کر سوچیں کہ ہماری جتنی بھی زندگی گزری خواہ وہ 24 برس ہو 64 کی یا 84 برس ہو ہم یہ حیات اسی صورت میں گزار پاتے ہیں جب ہم اپنے گزرے برسوں اور شب و روز سے جڑے رہتے ہیںاگر لوگوں قوموں اور تہذیبوں سے ان کا ماضی چھین لیا جائے تو وہ شاید زیادہ عرصہ زندہ نہیں رہ پائیں گیان میں آگے بڑھنے کی چاہت ختم ہوجائے گی تگ و دو کا جوہر ان سے چھن جائے گا بالکل ایسے جیسے کسی وجود کو الزائمر کی بیماری لگتی ہے اور اس کی یادداشت کے خلیے بے جان ہونے لگتے ہیںآپ یہ سمجھیں کہ یہ بیماری اس سے اس کا ماضی چھین لیتی ہےاور وہ اسی کیفیت میں زیادہ زندگی نہیں جی سکے گا اور اگر جیے گا بھی تو حیات کے ان رنگوں ذائقوں اور کیفیتوں کے ریگستان میں جہاں موت کی ویرانی کے سوا کچھ نہیں بچتانہ رنگوں کے پھول کھلتے ہیں نہ ذائقوں کی خوشبو کا کوئی جھونکا آتا ہے اور نہ غم و خوشی کی کوئی فاختہ اڑتی ہے اور نہ آسمان کی نیلاہٹ کے گہرے رنگ میں کشش کی کوئی ناؤ چلتی ہےبس ایک بے رنگ اور بے ذائقہ حیاتہمارا آج کا سفر بھی سمندر کنارے اور ان پہاڑیوں کے جنگلات آبشاروں غاروں اور قدامت کی ان پگڈنڈیوں پر ہی ہے مگر اج ہمیں ڈاکٹر عبدالرؤف کی کراچی ریجن پر کی گئی تحقیق اور اس تحقیق پر پاؤلو بیگی کی تازہ تحقیق پر تفصیلی بات کرنی تھی لیکن جیسے ہی ہم سفر کرنے کی تیاری میں تھے تو ہمارے ساتھیوں میں سے کسی نے دو تین سوال کر ڈالے کہ کھیرتھر کے اس پہاڑی سلسلے پر ارتقا کا عمل کتنا قدیم ہوسکتا ہے اور ڈاکٹر عبدالرؤف سے پہلے بھی کراچی پر اس حوالے سے تحقیق ہوئی ہے یا نہیں مختلف زمانوں کے نام اور ان کی عمریںتصویر ایکس یہ سوالات اپنی جگہ پر اہم ہیں اور ان سوالات کا جواب ڈاکٹر صاحب کی رپورٹ اینشیئنٹ سیٹلمنٹس ان کراچی ریجن Ancient Settlements in Karachi Region میں ضرور موجود ہوگامگر میں یہاں ہربرٹ جارج ویلز Herbert George Wells کی مشہور تحقیقی کتاب دی اؤٹ لائن اف ہسٹری سے دو نقشے آپ کے سامنے پیش کررہا ہوں جو آج سے 25 اور 50 ہزار سال پہلے کے جغرافیائی حالات کو ظاہر کرتے ہیں50 ہزار سال پہلے کا نقشہ 50 ہزار برس پہلے والے نقشے کو دیکھیں گے تو آپ کو میدانی اور ریگستانی سندھ پورا پنجاب گنگا گھاٹی پانی کے نیچے نظر آئیں گے جبکہ سندھ کے مغربی اونچائی والے پہاڑی سلسلے اور بلوچستان آپ کو پانی سے آزاد نظر آئیں گےجبکہ 35\n",
      "سے 25 ہزار برس پہلے والے نقشے میں\n"
     ]
    }
   ],
   "source": [
    "# Store the words for sentence reconstruction\n",
    "words = cleaned_text_without_period.split()\n",
    "\n",
    "# Initialize a list to hold the detected sentences\n",
    "sentences = []\n",
    "\n",
    "# Process only the first chunk\n",
    "if chunks:  # Check if there are any chunks\n",
    "    chunk = chunks[0]  # Get the first chunk\n",
    "    inputs = tokenizer(chunk, truncation=True, max_length=512, return_tensors='pt')\n",
    "    \n",
    "    # Get the output logits from the BERT model\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "    # Apply a classification threshold for sentence boundary detection\n",
    "    sentence_end_threshold = 0.58    # Convert logits to probabilities (using sigmoid)\n",
    "    predictions = torch.sigmoid(logits)\n",
    "\n",
    "    # Get positions where tokens are predicted as sentence ends (based on threshold)\n",
    "    sentence_end_positions = predictions[:, :, 1] > sentence_end_threshold  \n",
    "    # Reconstruct sentences based on the detected sentence-end tokens\n",
    "    current_sentence = []\n",
    "\n",
    "    for i, word in enumerate(chunk.split()):  \n",
    "        current_sentence.append(word)\n",
    "        if sentence_end_positions[0][i]: \n",
    "            sentences.append(\" \".join(current_sentence))\n",
    "            current_sentence = []\n",
    "\n",
    "    # Append the final sentence if it wasn't completed\n",
    "    if current_sentence:\n",
    "        sentences.append(\" \".join(current_sentence))\n",
    "\n",
    "# Output the sentences detected in the first chunk\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1: اس سلسلے کی دیگر اقساط یہاں پڑھیےیہ کیسے ممکن ہے کہ کسی کا مستقبل ماضی کے بغیر ہو کیونکہ دن دن سے اور پل پل سے جڑا ہوتا ہےجس طرح ہم گزرے دن کو بھی کل کہتے ہیں اور آنے والے دن کو بھی کل کہتے ہیں اس لیے کیونکہ کل اور کل میں جو آج ہے وہ ایک کڑی ہے جو دونوں کو اپس میں جوڑ کر رکھتی ہےتو ہم اگر کبھی تنہائی میں کچھ پل نکال کر سوچیں کہ ہماری جتنی بھی زندگی گزری خواہ وہ 24 برس ہو 64 کی یا 84 برس ہو ہم یہ حیات اسی صورت میں گزار پاتے ہیں جب ہم اپنے گزرے برسوں اور شب و روز سے جڑے رہتے ہیںاگر لوگوں قوموں اور تہذیبوں سے ان کا ماضی چھین لیا جائے تو وہ شاید زیادہ عرصہ زندہ نہیں رہ پائیں گیان میں آگے بڑھنے کی چاہت ختم ہوجائے گی تگ و دو کا جوہر ان سے چھن جائے گا بالکل ایسے جیسے کسی وجود کو الزائمر کی بیماری لگتی ہے اور اس کی یادداشت کے خلیے بے جان ہونے لگتے ہیںآپ یہ سمجھیں کہ یہ بیماری اس سے اس کا ماضی چھین لیتی ہےاور وہ اسی کیفیت میں زیادہ زندگی نہیں جی سکے گا اور اگر جیے گا بھی تو حیات کے ان رنگوں ذائقوں اور کیفیتوں کے ریگستان میں جہاں موت کی ویرانی کے سوا کچھ نہیں بچتانہ رنگوں کے پھول کھلتے ہیں نہ ذائقوں کی خوشبو کا کوئی جھونکا آتا ہے اور نہ غم و خوشی کی کوئی فاختہ اڑتی ہے اور نہ آسمان کی نیلاہٹ کے گہرے رنگ میں کشش کی کوئی ناؤ چلتی ہےبس ایک بے رنگ اور بے ذائقہ حیاتہمارا آج کا سفر بھی سمندر کنارے اور ان پہاڑیوں کے جنگلات آبشاروں غاروں اور قدامت کی ان پگڈنڈیوں پر ہی ہے مگر اج ہمیں ڈاکٹر عبدالرؤف کی کراچی ریجن پر کی گئی تحقیق اور اس تحقیق پر پاؤلو بیگی کی تازہ تحقیق پر تفصیلی بات کرنی تھی لیکن جیسے ہی ہم سفر کرنے کی تیاری میں تھے تو ہمارے ساتھیوں میں سے کسی نے دو تین سوال کر ڈالے کہ کھیرتھر کے اس پہاڑی سلسلے پر ارتقا کا عمل کتنا قدیم ہوسکتا ہے اور ڈاکٹر عبدالرؤف سے پہلے بھی کراچی پر اس حوالے سے تحقیق ہوئی ہے یا نہیں مختلف زمانوں کے نام اور ان کی عمریںتصویر ایکس یہ سوالات اپنی جگہ پر اہم ہیں اور ان سوالات کا جواب ڈاکٹر صاحب کی رپورٹ اینشیئنٹ سیٹلمنٹس ان کراچی ریجن Ancient Settlements in Karachi Region میں ضرور موجود ہوگامگر میں یہاں ہربرٹ جارج ویلز Herbert George Wells کی مشہور تحقیقی کتاب دی اؤٹ لائن اف ہسٹری سے دو نقشے آپ کے سامنے پیش کررہا ہوں جو آج سے 25 اور 50 ہزار سال پہلے کے جغرافیائی حالات کو ظاہر کرتے ہیں50 ہزار سال پہلے کا نقشہ 50 ہزار برس پہلے والے نقشے کو دیکھیں گے تو آپ کو میدانی اور ریگستانی سندھ پورا پنجاب گنگا گھاٹی پانی کے نیچے نظر آئیں گے جبکہ سندھ کے مغربی اونچائی والے پہاڑی سلسلے اور بلوچستان آپ کو پانی سے آزاد نظر آئیں گےجبکہ 35\n",
      "sentence2: سے 25 ہزار برس پہلے والے نقشے میں\n"
     ]
    }
   ],
   "source": [
    "# Output the sentences in the desired format\n",
    "for idx, sentence in enumerate(sentences, start=1):\n",
    "    print(f\"sentence{idx}: {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### trying out 0.54, 0.55, 0.56."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 466\n"
     ]
    }
   ],
   "source": [
    "# Check the number of chunks\n",
    "num_chunks = len(chunks)\n",
    "print(f\"Number of chunks: {num_chunks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now doing the same for the rest of the chunks \n",
    "# Initialize a list to hold the detected sentences\n",
    "sentences = []\n",
    "\n",
    "# Process all chunks\n",
    "for chunk in chunks:\n",
    "    inputs = tokenizer(chunk, truncation=True, max_length=512, return_tensors='pt')\n",
    "    \n",
    "    # Get the output logits from the BERT model\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "    # Apply a classification threshold for sentence boundary detection\n",
    "    sentence_end_threshold = 0.54  \n",
    "\n",
    "    # Convert logits to probabilities (using sigmoid)\n",
    "    predictions = torch.sigmoid(logits)\n",
    "\n",
    "    # Get positions where tokens are predicted as sentence ends (based on threshold)\n",
    "    sentence_end_positions = predictions[:, :, 1] > sentence_end_threshold  \n",
    "\n",
    "    # Reconstruct sentences based on the detected sentence-end tokens\n",
    "    current_sentence = []\n",
    "\n",
    "    for i, word in enumerate(chunk.split()):  \n",
    "        current_sentence.append(word)\n",
    "        if sentence_end_positions[0][i]:  \n",
    "            sentences.append(\" \".join(current_sentence))\n",
    "            current_sentence = []\n",
    "\n",
    "    # Append the final sentence if it wasn't complete\n",
    "    if current_sentence:\n",
    "        sentences.append(\" \".join(current_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: اس سلسلے کی دیگر اقساط یہاں پڑھیےیہ کیسے ممکن ہے\n",
      "Sentence 2: کہ کسی کا مستقبل ماضی کے بغیر ہو\n",
      "Sentence 3: کیونکہ دن دن سے اور پل پل\n",
      "Sentence 4: سے جڑا ہوتا ہےجس طرح\n",
      "Sentence 5: ہم\n",
      "Sentence 6: گزرے دن کو بھی کل کہتے ہیں\n",
      "Sentence 7: اور آنے والے دن کو بھی کل\n",
      "Sentence 8: کہتے ہیں اس لیے کیونکہ\n",
      "Sentence 9: کل اور کل میں\n",
      "Sentence 10: جو\n"
     ]
    }
   ],
   "source": [
    "# Output the first few sentences detected in all chunks\n",
    "num_sentences_to_print = 10 \n",
    "\n",
    "# Print only the first few sentences\n",
    "for i, sentence in enumerate(sentences):\n",
    "    if i >= num_sentences_to_print:\n",
    "        break\n",
    "    print(f\"Sentence {i+1}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences detected: 24658\n"
     ]
    }
   ],
   "source": [
    "# Output the total number of sentences detected\n",
    "total_sentences = len(sentences)\n",
    "print(f\"Total number of sentences detected: {total_sentences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentences:\n",
      "1: اس سلسلے کی دیگر اقساط یہاں پڑھیے\n",
      "2: یہ کیسے ممکن ہے کہ کسی کا مستقبل ماضی کے بغیر ہو کیونکہ دن دن سے اور پل پل سے جڑا ہوتا ہے\n",
      "3: جس طرح ہم گزرے دن کو بھی کل کہتے ہیں اور آنے والے دن کو بھی کل کہتے ہیں اس لیے کیونکہ کل اور کل میں جو آج ہے وہ ایک کڑی ہے جو دونوں کو اپس میں جوڑ کر رکھتی ہے\n",
      "4: تو ہم اگر کبھی تنہائی میں کچھ پل نکال کر سوچیں کہ ہماری جتنی بھی زندگی گزری خواہ وہ 24 برس ہو 64 کی یا 84 برس ہو ہم یہ حیات اسی صورت میں گزار پاتے ہیں جب ہم اپنے گزرے برسوں اور شب و روز سے جڑے رہتے ہیں\n",
      "5: اگر لوگوں قوموں اور تہذیبوں سے ان کا ماضی چھین لیا جائے تو وہ شاید زیادہ عرصہ زندہ نہیں رہ پائیں گی\n",
      "6: ان میں آگے بڑھنے کی چاہت ختم ہوجائے گی تگ و دو کا جوہر ان سے چھن جائے گا بالکل ایسے جیسے کسی وجود کو الزائمر کی بیماری لگتی ہے اور اس کی یادداشت کے خلیے بے جان ہونے لگتے ہیں\n",
      "7: آپ یہ سمجھیں کہ یہ بیماری اس سے اس کا ماضی چھین لیتی ہے\n",
      "8: اور وہ اسی کیفیت میں زیادہ زندگی نہیں جی سکے گا اور اگر جیے گا بھی تو حیات کے ان رنگوں ذائقوں اور کیفیتوں کے ریگستان میں جہاں موت کی ویرانی کے سوا کچھ نہیں بچتا\n",
      "9: نہ رنگوں کے پھول کھلتے ہیں نہ ذائقوں کی خوشبو کا کوئی جھونکا آتا ہے اور نہ غم و خوشی کی کوئی فاختہ اڑتی ہے اور نہ آسمان کی نیلاہٹ کے گہرے رنگ میں کشش کی کوئی ناؤ چلتی ہے\n"
     ]
    }
   ],
   "source": [
    "# Function to extract original sentences\n",
    "def extract_original_sentences(cleaned_text):\n",
    "    # Split original text by punctuation (assuming '۔' is the sentence boundary marker in original text)\n",
    "    original_sentences = cleaned_text.split('۔')\n",
    "\n",
    "    # Filter out empty sentences caused by splitting\n",
    "    original_sentences = [sentence.strip() for sentence in original_sentences if sentence.strip()]\n",
    "    \n",
    "    return original_sentences\n",
    "\n",
    "# Extract the original sentences\n",
    "original_sentences = extract_original_sentences(cleaned_text)\n",
    "\n",
    "# Print a few original sentences for clarity\n",
    "print(\"Original Sentences:\")\n",
    "for i, sentence in enumerate(original_sentences):\n",
    "    if i < 9:  # Print only the first 5 sentences\n",
    "        print(f\"{i + 1}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Convert original and detected sentences to sets for comparison\n",
    "original_sentences_set = set(original_sentences)\n",
    "detected_sentences_set = set(sentences)\n",
    "\n",
    "# Calculate True Positives, False Positives, and False Negatives\n",
    "true_positives = detected_sentences_set.intersection(original_sentences_set)\n",
    "false_positives = detected_sentences_set - original_sentences_set\n",
    "false_negatives = original_sentences_set - detected_sentences_set\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = len(true_positives) / (len(true_positives) + len(false_positives)) if (len(true_positives) + len(false_positives)) > 0 else 0\n",
    "recall = len(true_positives) / (len(true_positives) + len(false_negatives)) if (len(true_positives) + len(false_negatives)) > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
